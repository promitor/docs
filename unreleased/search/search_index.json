{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>Promitor is an Azure Monitor scraper which makes the metrics available for metric systems such as Atlassian Statuspage, OpenTelemetry, Prometheus and StatsD.</p> <p></p>"},{"location":"#running-promitor-scraper","title":"Running Promitor Scraper","text":"<p>Running Promitor Scraper is super easy:</p> <pre><code>docker run -d -p 8999:80 --name promitor-agent-scraper \\\n                         --env PROMITOR_AUTH_APPID='&lt;azure-ad-app-id&gt;'   \\\n                         --env-file C:/Promitor/az-mon-auth.creds \\\n                         --volume C:/Promitor/metrics-declaration.yaml:/config/metrics-declaration.yaml \\\n                         --volume C:/Promitor/runtime.yaml:/config/runtime.yaml \\\n                         ghcr.io/tomkerkhove/promitor-agent-scraper:2.5.0\n</code></pre> <p>Docker image is available on GitHub Container Registry.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>Automatically scrapes Azure Monitor metrics (single and multi-dimensional) across various subscription &amp;  resource groups</li> <li>Automatically pushes metrics to systems such as Atlassian Statuspage, OpenTelemetry, Prometheus and StatsD</li> <li>Easy to declare metrics to scrape via metrics-as-code or automatically discover resources</li> <li>Built-in support for a variety of Azure services (overview)</li> <li>Easily deployable via Docker &amp; Kubernetes</li> <li>Sends telemetry to container logs &amp; Azure Application Insights</li> <li>Available for Linux &amp; Windows runtimes</li> <li>Support for all Azure clouds</li> </ul> <p>And there is more on the way - Check our backlog and vote for features!</p>"},{"location":"#support","title":"Support","text":"<p>Promitor is actively maintained and developed with best-effort support.</p> <p>We do welcome PRs that implement features from our backlog and are always happy to help you incorporate Promitor in your infrastructure, but do not provide 24/7 support. Are you having issues or feature requests?</p> <p>Feel free to let us know!</p> <p>Support Promitor </p>"},{"location":"#end-users","title":"End-users","text":"<p>We are proud to have the following end-users(s) running Promitor in production:</p> <p> </p> <p>Are you a Promitor user? Let us know and get listed!</p> <p>Learn more about how they are using Promitor:</p> <ul> <li>\"Monitor Azure Resources using Promitor\"  by ResDiary</li> </ul>"},{"location":"#thank-you","title":"Thank you","text":"<p>We'd like to thank the following service(s) for supporting our open-source initiative!</p> <ul> <li>Netlify allows us to provide previews of our documentation changes in our   pull requests that make it easier to review them.</li> </ul> <p> </p> <p>But they are not the only one we'd like to thank!</p> <p>For a full list of services, tooling &amp; NuGet packages that support us -  Have a look at our Thank you page!</p>"},{"location":"#license-information","title":"License Information","text":"<p>This is licensed under The MIT License (MIT). Which means that you can use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the web application. But you always need to state that Tom Kerkhove is the original author of this web application.</p>"},{"location":"faq/","title":"Frequently asked questions (FAQs)","text":"<p>Here are a list of questions you may have:</p> <ul> <li>Are multi-dimensional metrics supported?</li> <li>How does Promitor handle deleted resources?</li> <li>Is scraping multiple subscriptions supported?</li> <li>What Azure clouds are supported?</li> <li>Why does Azure Blob &amp; File Storage only report account-level information?</li> <li>Why does my multi-dimensional metric report label value <code>unknown</code> with Prometheus?</li> <li>What operating systems are supported?</li> </ul>"},{"location":"faq/#are-multi-dimensional-metrics-supported","title":"Are multi-dimensional metrics supported?","text":"<p>Yes, every scraper supports scraping multi-dimensional metrics except for Azure Storage queues.</p> <p>You can configure the dimension(s) you are interested in via <code>azureMetricConfiguration.dimensions</code>, for more information see our 'Metrics Declaration' page.</p> <p>However, you can only use it with metrics in Azure Monitor that support this, for a complete overview we recommend reading the official documentation.</p>"},{"location":"faq/#how-does-promitor-handle-deleted-resources","title":"How does Promitor handle deleted resources?","text":"<p>The approach depends if you are using declarative metrics or resource discovery but we highly recommend to  enable Prometheus metric timestamps in our runtime configuration   to indicate how old the metric is.</p>"},{"location":"faq/#when-using-declarative-metrics","title":"When using declarative metrics","text":"<p>Promitor will scrape all resources that are configured and report the metrics accordingly. If that resource is deleted,  we will still serve the metrics as long as we can until it is no longer available and exceptions will be thrown.</p> <p>We recommend to update the metrics declaration when a resource is deleted to avoid polluting logs.</p>"},{"location":"faq/#when-using-resource-discovery","title":"When using resource discovery","text":"<p>Promitor will automatically discover all matching resources which means that it will automatically scrape metrics for  new/removed resources.</p> <p>Removed resources will immediately stop being scraped by Promitor, but still be reported in Prometheus scrape endpoint.</p>"},{"location":"faq/#is-scraping-multiple-subscriptions-supported","title":"Is scraping multiple subscriptions supported?","text":"<p>No, we do not support scraping multiple subscriptions as of today as we consider that to be a security boundary.</p> <p>However, you can deploy multiple instances of Promitor that each scrape another subscription.</p> <p>We have it on our backlog to see if there is  enough demand for it, feel free to give a . If that is the case, we will reconsider this limitation.</p>"},{"location":"faq/#what-azure-clouds-are-supported","title":"What Azure clouds are supported?","text":"<p>We support <code>Global</code> (default), <code>China</code>, <code>UsGov</code>, <code>Germany</code> &amp; <code>Custom</code> Azure clouds.</p> <p>This can be configured in the metric configuration under <code>azureMetadata</code> and in resource discovery configuration under <code>azureLandscape</code></p> <p>For more information see our 'Metric Configuration' page and <code>Resource Discovery</code> page.</p>"},{"location":"faq/#why-does-azure-blob-file-storage-only-report-account-level-information","title":"Why does Azure Blob &amp; File Storage only report account-level information?","text":"<p>Azure Monitor currently only provides account-level metrics which we can serve.</p> <p>As part of #450 &amp;  #446 we plan to provide the capability to have more granular information.</p>"},{"location":"faq/#why-does-my-multi-dimensional-metric-report-label-value-unknown-with-prometheus","title":"Why does my multi-dimensional metric report label value <code>unknown</code> with Prometheus?","text":"<p>When Promitor is unable to find a metric for a multi-dimensional metric, it will report <code>unknown</code> for the dimension  label given it was not able to determine what the dimension value is due to the lack of metrics.</p> <p>You can read more about it in our Prometheus sink documentation.</p>"},{"location":"faq/#what-operating-systems-are-supported","title":"What operating systems are supported?","text":"<p>We support running on both Linux &amp; Windows platforms.</p>"},{"location":"how-it-works/","title":"How It Works","text":""},{"location":"how-it-works/#how-it-works","title":"How it works","text":"<p>Promitor is an Azure Monitor scraper which makes the metrics available to a variety of metric systems such as Atlassian Statuspage, OpenTelemetry, Prometheus and StatsD.</p> <p></p>"},{"location":"how-it-works/#scraping-azure-monitor-metrics","title":"Scraping Azure Monitor metrics","text":"<p>When you want to scrape resources, you can use Promitor Scraper which uses a metrics-as-code approach.</p> <p>By writing a metric declaration, you will define what Azure Monitor metrics to scrape for a set of Azure resources and  to what metric sink(s) they should be reported.</p> <p>Here's an overview of how it works:</p> <p></p>"},{"location":"how-it-works/#using-resource-discovery","title":"Using resource discovery","text":"<p>While Promitor Scraper uses a declarative approach for defining Azure resources to scrape; as of Promitor Scraper 2.0  you can integrate with Promitor Resource Discovery!</p> <p>With resource discovery, you can define resource discovery groups that represent Azure resources of a given type and  optionally define criteria for the resources to comply with.</p> <p>By doing this, you can change your metric declaration for Promitor Scraper so that, instead of using declared resources,  reference a resource discovery group which be used to determine what Azure resources it should scrape  metrics for.</p> <p>Behind the scenes, Promitor Resource Discovery integrates with Azure Resource Graph which will query your Azure landscape  to discover the corresponding resources.</p> <p>Here's an overview of how they work together:</p> <p></p> <p>You can easily start discovering resources automatically:</p> <ol> <li>Declare resource discovery groups (link)</li> <li>Deploy Promitor Resource Discovery (link)</li> <li>Configure Promitor Scraper to use resource discovery (link)</li> <li>Deploy Promitor Scraper (link)</li> </ol>"},{"location":"how-it-works/#what-components-do-agents-provide","title":"What components do agents provide?","text":"<p>Every Promitor agent provides a REST API which which you can integrate and uses background jobs to acquire the data  to reduce latency.</p> <p>Here's a detailed overview:</p> <p></p> <p>(*) Resources are still discovered synchronously but this will be implemented in Promitor Resource Discovery v0.2.</p> <p>\u2190 back</p>"},{"location":"tags/","title":"Tags","text":"<p>Following is a list of relevant tags:</p>"},{"location":"tags/#tag:api","title":"API","text":"<ul> <li>            Azure API Management          </li> <li>            Azure App Plan          </li> </ul>"},{"location":"tags/#tag:automation","title":"Automation","text":"<ul> <li>            Azure Automation account          </li> </ul>"},{"location":"tags/#tag:azure-firewall","title":"Azure Firewall","text":"<ul> <li>            Azure Firewall          </li> </ul>"},{"location":"tags/#tag:caching","title":"Caching","text":"<ul> <li>            Azure Cache for Redis          </li> <li>            Azure Cache for Redis Enterprise          </li> </ul>"},{"location":"tags/#tag:containers","title":"Containers","text":"<ul> <li>            Azure Container Instances          </li> <li>            Azure Container Registry          </li> <li>            Azure Kubernetes Service          </li> </ul>"},{"location":"tags/#tag:data","title":"Data","text":"<ul> <li>            Azure Blob Storage          </li> <li>            Azure Cache for Redis          </li> <li>            Azure Cache for Redis Enterprise          </li> <li>            Azure Cosmos DB          </li> <li>            Azure Data Explorer Cluster          </li> <li>            Azure Data Factory          </li> <li>            Azure Data Share          </li> <li>            Azure Database for MariaDB          </li> <li>            Azure Database for MySQL          </li> <li>            Azure Database for PostgreSQL          </li> <li>            Azure File Storage          </li> <li>            Azure Log Analytics          </li> <li>            Azure SQL Database          </li> <li>            Azure SQL Elastic Pool          </li> <li>            Azure SQL Managed Instance          </li> <li>            Azure SQL Server          </li> <li>            Azure Storage Account          </li> <li>            Azure Storage Queue          </li> <li>            Azure Synapse (Apache Spark pool)          </li> <li>            Azure Synapse (SQL pool)          </li> <li>            Azure Synapse (Workspace)          </li> </ul>"},{"location":"tags/#tag:iaas","title":"IaaS","text":"<ul> <li>            Azure Virtual Machine (VM)          </li> <li>            Azure Virtual Machine Scale Set (VMSS)          </li> </ul>"},{"location":"tags/#tag:integration","title":"Integration","text":"<ul> <li>            Azure API Management          </li> <li>            Azure Data Factory          </li> <li>            Azure Logic Apps          </li> <li>            Azure Service Bus Namespace          </li> </ul>"},{"location":"tags/#tag:iot","title":"IoT","text":"<ul> <li>            Azure IoT Hub          </li> <li>            Azure IoT Hub Device Provisioning Service (DPS)          </li> </ul>"},{"location":"tags/#tag:kubernetes","title":"Kubernetes","text":"<ul> <li>            Azure Kubernetes Service          </li> </ul>"},{"location":"tags/#tag:messaging","title":"Messaging","text":"<ul> <li>            Azure Event Hubs          </li> <li>            Azure Service Bus Namespace          </li> </ul>"},{"location":"tags/#tag:monitoring","title":"Monitoring","text":"<ul> <li>            Azure Application Insights          </li> <li>            Azure Monitor Autoscale          </li> </ul>"},{"location":"tags/#tag:networking","title":"Networking","text":"<ul> <li>            Azure Application Gateway          </li> <li>            Azure Express Route Circuit          </li> <li>            Azure Front Door          </li> <li>            Azure Load Balancer          </li> <li>            Azure Nat Gateways          </li> <li>            Azure Network Gateway          </li> <li>            Azure Network Interface          </li> <li>            Azure Public IP Address          </li> <li>            Azure Traffic Manager          </li> <li>            Azure Virtual Network          </li> </ul>"},{"location":"tags/#tag:open-source","title":"Open Source","text":"<ul> <li>            Azure Cache for Redis          </li> <li>            Azure Cache for Redis Enterprise          </li> <li>            Azure Cosmos DB          </li> <li>            Azure Database for MariaDB          </li> <li>            Azure Database for MySQL          </li> <li>            Azure Database for PostgreSQL          </li> <li>            Azure Event Hubs          </li> <li>            Azure Kubernetes Service          </li> </ul>"},{"location":"tags/#tag:paas","title":"PaaS","text":"<ul> <li>            Azure API Management          </li> <li>            Azure App Plan          </li> <li>            Azure Data Factory          </li> <li>            Azure Function App          </li> <li>            Azure IoT Hub          </li> <li>            Azure IoT Hub Device Provisioning Service (DPS)          </li> <li>            Azure Logic Apps          </li> <li>            Azure SQL Database          </li> <li>            Azure SQL Elastic Pool          </li> <li>            Azure Web App          </li> </ul>"},{"location":"tags/#tag:powerbi","title":"PowerBI","text":"<ul> <li>            Azure PowerBI Dedicated          </li> </ul>"},{"location":"tags/#tag:powerbi-embedded","title":"PowerBI Embedded","text":"<ul> <li>            Azure PowerBI Dedicated          </li> </ul>"},{"location":"tags/#tag:resource-discovery","title":"Resource Discovery","text":"<ul> <li>            Azure API Management          </li> <li>            Azure App Plan          </li> <li>            Azure Application Gateway          </li> <li>            Azure Application Insights          </li> <li>            Azure Automation account          </li> <li>            Azure Cache for Redis          </li> <li>            Azure Cache for Redis Enterprise          </li> <li>            Azure Container Instances          </li> <li>            Azure Container Registry          </li> <li>            Azure Content Delivery Network (CDN)          </li> <li>            Azure Cosmos DB          </li> <li>            Azure Data Explorer Cluster          </li> <li>            Azure Data Factory          </li> <li>            Azure Data Share          </li> <li>            Azure Database for MariaDB          </li> <li>            Azure Database for MySQL          </li> <li>            Azure Database for PostgreSQL          </li> <li>            Azure Event Hubs          </li> <li>            Azure Express Route Circuit          </li> <li>            Azure File Storage          </li> <li>            Azure Firewall          </li> <li>            Azure Front Door          </li> <li>            Azure Function App          </li> <li>            Azure IoT Hub          </li> <li>            Azure IoT Hub Device Provisioning Service (DPS)          </li> <li>            Azure Key Vault          </li> <li>            Azure Kubernetes Service          </li> <li>            Azure Load Balancer          </li> <li>            Azure Logic Apps          </li> <li>            Azure Monitor Autoscale          </li> <li>            Azure Nat Gateways          </li> <li>            Azure Network Gateway          </li> <li>            Azure Network Interface          </li> <li>            Azure PowerBI Dedicated          </li> <li>            Azure Public IP Address          </li> <li>            Azure SQL Database          </li> <li>            Azure SQL Elastic Pool          </li> <li>            Azure SQL Managed Instance          </li> <li>            Azure SQL Server          </li> <li>            Azure Service Bus Namespace          </li> <li>            Azure Storage Account          </li> <li>            Azure Synapse (Apache Spark pool)          </li> <li>            Azure Synapse (SQL pool)          </li> <li>            Azure Synapse (Workspace)          </li> <li>            Azure Traffic Manager          </li> <li>            Azure Virtual Machine (VM)          </li> <li>            Azure Virtual Machine Scale Set (VMSS)          </li> <li>            Azure Virtual Network          </li> <li>            Azure Web App          </li> </ul>"},{"location":"tags/#tag:sql","title":"SQL","text":"<ul> <li>            Azure Cosmos DB          </li> <li>            Azure Database for MySQL          </li> <li>            Azure Database for PostgreSQL          </li> <li>            Azure SQL Database          </li> <li>            Azure SQL Elastic Pool          </li> <li>            Azure SQL Managed Instance          </li> <li>            Azure SQL Server          </li> </ul>"},{"location":"tags/#tag:scraper","title":"Scraper","text":"<ul> <li>            Azure API Management          </li> <li>            Azure App Plan          </li> <li>            Azure Application Gateway          </li> <li>            Azure Application Insights          </li> <li>            Azure Automation account          </li> <li>            Azure Blob Storage          </li> <li>            Azure Cache for Redis          </li> <li>            Azure Cache for Redis Enterprise          </li> <li>            Azure Container Instances          </li> <li>            Azure Container Registry          </li> <li>            Azure Content Delivery Network (CDN)          </li> <li>            Azure Cosmos DB          </li> <li>            Azure Data Explorer Cluster          </li> <li>            Azure Data Factory          </li> <li>            Azure Data Share          </li> <li>            Azure Database for MariaDB          </li> <li>            Azure Database for MySQL          </li> <li>            Azure Database for PostgreSQL          </li> <li>            Azure Event Hubs          </li> <li>            Azure Express Route Circuit          </li> <li>            Azure File Storage          </li> <li>            Azure Firewall          </li> <li>            Azure Front Door          </li> <li>            Azure Function App          </li> <li>            Azure IoT Hub          </li> <li>            Azure IoT Hub Device Provisioning Service (DPS)          </li> <li>            Azure Key Vault          </li> <li>            Azure Kubernetes Service          </li> <li>            Azure Load Balancer          </li> <li>            Azure Log Analytics          </li> <li>            Azure Logic Apps          </li> <li>            Azure Monitor Autoscale          </li> <li>            Azure Nat Gateways          </li> <li>            Azure Network Gateway          </li> <li>            Azure Network Interface          </li> <li>            Azure PowerBI Dedicated          </li> <li>            Azure Public IP Address          </li> <li>            Azure SQL Database          </li> <li>            Azure SQL Elastic Pool          </li> <li>            Azure SQL Managed Instance          </li> <li>            Azure SQL Server          </li> <li>            Azure Service Bus Namespace          </li> <li>            Azure Storage Account          </li> <li>            Azure Storage Queue          </li> <li>            Azure Synapse (Apache Spark pool)          </li> <li>            Azure Synapse (SQL pool)          </li> <li>            Azure Synapse (Workspace)          </li> <li>            Azure Traffic Manager          </li> <li>            Azure Virtual Machine (VM)          </li> <li>            Azure Virtual Machine Scale Set (VMSS)          </li> <li>            Azure Virtual Network          </li> <li>            Azure Web App          </li> <li>            Generic          </li> </ul>"},{"location":"tags/#tag:security","title":"Security","text":"<ul> <li>            Azure Key Vault          </li> </ul>"},{"location":"tags/#tag:serverless","title":"Serverless","text":"<ul> <li>            Azure Function App          </li> </ul>"},{"location":"tags/#tag:storage","title":"Storage","text":"<ul> <li>            Azure Blob Storage          </li> <li>            Azure File Storage          </li> <li>            Azure Storage Account          </li> <li>            Azure Storage Queue          </li> </ul>"},{"location":"tags/#tag:synapse","title":"Synapse","text":"<ul> <li>            Azure Synapse (Apache Spark pool)          </li> <li>            Azure Synapse (SQL pool)          </li> <li>            Azure Synapse (Workspace)          </li> </ul>"},{"location":"tags/#tag:web","title":"Web","text":"<ul> <li>            Azure App Plan          </li> </ul>"},{"location":"thank-you/","title":"Thank you!","text":"<p>We'd like to thank the following service(s) for supporting our open-source initiative!</p>"},{"location":"thank-you/#automation","title":"Automation","text":"<p>Here is an overview of the services that are so kind to support us:</p> <ul> <li>Azure Pipelines allows us to build automated process for building our Docker   image and pushing it to Docker Hub, create GitHub release and more without manual   intervention.</li> </ul> <p></p> <ul> <li>CLA Assistant automates the process of signing our Contribution License   Agreement (CLA).</li> </ul> <p></p> <ul> <li>CloudFlare serves our documentation super fast via their fast global Content   Delivery Network.</li> </ul> <p></p> <ul> <li>Codefactor for continuously monitoring our code styling.</li> </ul> <p></p> <ul> <li>Microsoft for providing Azure credits for open-source projects. (Learn more)</li> </ul> <p></p> <ul> <li>Netlify allows us to provide previews of our documentation changes in our   pull requests that make it easier to review them.</li> </ul> <p></p> <ul> <li>Renovate saves us time and reduces risk by automating the tedious process   of updating dependencies.</li> </ul> <p></p> <ul> <li>Scarf for helping us host our container images reliably.</li> </ul> <p></p> <ul> <li>Snyk continuously monitors our documentation, application &amp; Docker image and   lets you quickly respond when new vulnerabilities are disclosed.</li> </ul> <p></p>"},{"location":"thank-you/#github-apps","title":"GitHub Apps","text":"<p>We are using the following GitHub Apps:</p> <ul> <li>Semantic Pull Requests - Ensure PRs are using a consistent approach.</li> <li>Task list completed -   Ensures all task lists in our PRs are completed.</li> <li>Triage New Issues - Automatically   tag new issues &amp; PRs with <code>triage</code> label.</li> <li>Request Info - Requests more info from   newly opened Pull Requests and Issues.</li> <li>YAMBURGER - Finds YAML syntax errors.</li> <li>Reminders - Set reminders on Issues and   Pull Requests.</li> <li>Check TODO - Check TODO allows you   to discover added/edited TODO items in your code, when a Pull Request is created/updated.</li> <li>ImgBot - Optimizing images across our   repo.</li> <li>Stale - Closes abandoned issues after a period   of inactivity.</li> <li>WIP - Do Not Merge \u2013 as a service.</li> </ul>"},{"location":"thank-you/#nuget-packages","title":"NuGet Packages","text":"<p>Here is an overview of the NuGet packages that we rely on:</p> <ul> <li>NetEscapades.Configuration.Yaml</li> <li>YAML configuration provider for .NET Core</li> <li>CronScheduler.AspNetCore</li> <li>Asp.Net Core 2.x Hosted or .Net Core 2.x Self-hosted Cron Scheduler</li> <li>Swashbuckle.AspNetCore</li> <li>Swagger tools for documenting API's built on ASP.NET Core</li> <li>Prometheus.Client</li> <li>.NET client for prometheus.io</li> <li>spectre.console - A library that makes it easier to create  beautiful console applications.</li> <li>Humanizer - Humanizer meets all your .NET needs for manipulating and  displaying strings, enums, dates, times, timespans, numbers and quantities</li> <li>YamlDotNet - .NET library for YAML</li> <li>Guard.NET - Library that facilitates   runtime checks of code and allows to define preconditions and invariants within   a method</li> <li>Cronos - Fully-featured .NET library for   working with Cron expressions. Built with time zones in mind and intuitively   handles daylight saving time transitions</li> <li>Bogus - A simple and sane data generator for   populating objects</li> <li>xUnit - Free, open source, community-focused   unit testing tool for the .NET</li> </ul>"},{"location":"deployment/","title":"Deployment","text":"<p>Here is an overview of the Promitor agents you can deploy:</p> <ul> <li>Deploying Promitor Scraper</li> <li>Deploying Promitor Resource Discovery</li> </ul>"},{"location":"deployment/#image-tagging-strategy","title":"Image Tagging Strategy","text":"<p>Depending on your scenario you might need a different update cadence for Docker dependencies.</p> <p>We provide a few options by offering multiple Docker tags:</p> <ul> <li>latest - Ideal for experimentation and proof-of-concepts, but not recommended   for running production workloads.</li> <li>{major}.{minor} - Representation of a specific feature set, but will be   updated with feature &amp; security patches.</li> <li>{major}.{minor}.{patch} - Run a specific version of the runtime. (Alternative could be to use image digest pinning)</li> </ul> <p></p> <p>All of the above tags are available for Linux. Every tag can be suffixed with  <code>-linux</code> or <code>-windows</code> to target a specific OS.</p> <p>You can also pin to a specific digest of an image to ensure that you are running the same image across your infrastructure. However, you will not receive security patches unless you use a tool like Renovate to keep them up-to-date.</p> <p>\u2190 back</p>"},{"location":"deployment/resource-discovery/docker/","title":"Docker","text":"<pre><code>\u276f docker run -d -p 9999:80 --name promitor-agent-resource-discovery   \\\n                         --env PROMITOR_AUTH_APPID='&lt;azure-ad-app-id&gt;'   \\\n                         --env-file C:/Promitor/promitor-discovery-auth.creds   \\\n                         --volume C:/Promitor/resource-discovery-declaration.yaml:/config/resource-discovery-declaration.yaml   \\\n                         --volume C:/Promitor/resource-discovery-runtime.yaml:/config/runtime.yaml   \\\n                         ghcr.io/tomkerkhove/promitor-agent-resource-discovery\n</code></pre>"},{"location":"deployment/resource-discovery/kubernetes/","title":"Kubernetes","text":"<p>We provide a Helm Chart which deploys all the required infrastructure on your Kubernetes cluster.</p>"},{"location":"deployment/resource-discovery/kubernetes/#getting-the-helm-chart","title":"Getting the Helm Chart","text":"<p>Install the Promitor Chart repository:</p> <pre><code>\u276f helm repo add promitor https://charts.promitor.io/\n</code></pre> <p>Refresh your local Chart repositories:</p> <pre><code>\u276f helm repo update\n</code></pre> <p>If all goes well you should be able to list all Promitor charts:</p> <pre><code>\u276f helm search hub promitor\nURL                                                     CHART VERSION           APP VERSION     DESCRIPTION\nhttps://hub.helm.sh/charts/promitor/promitor-ag...      2.0.0-preview-3         2.0.0-preview-3 Promitor, bringing Azure Monitor metrics where ...\n</code></pre>"},{"location":"deployment/resource-discovery/kubernetes/#using-our-helm-chart","title":"Using our Helm Chart","text":"<p>You can easily install our Resource Discovery Agent as following:</p> <pre><code>\u276f helm install promitor-agent-resource-discovery promitor/promitor-agent-resource-discovery \\\n               --set azureAuthentication.appId='&lt;azure-ad-app-id&gt;' \\\n               --set azureAuthentication.appKey='&lt;azure-ad-app-key&gt;' \\\n               --values /path/to/helm-configuration.yaml\n</code></pre> <p>Next to Azure authentication, a resource discovery declaration  must be provided through <code>--values</code>.</p> <p>Here is an example of resource discovery declaration which you can pass:</p> <pre><code>azureLandscape:\n  cloud: Global\n  tenantId: e0372f7f-a362-47fb-9631-74a5c4ba8bbf\n  subscriptionIds:\n  - 0329dd2a-59dc-4493-aa54-cb01cb027dc2\nresourceDiscoveryGroups:\n- name: api-gateways\n  type: ApiManagement\n</code></pre> <p>Our Helm chart provides a variety of configuration options which you can explore in  our full values file. to see all configurable values.</p>"},{"location":"deployment/resource-discovery/kubernetes/#sample-configuration","title":"Sample configuration","text":"<p>Want to get started easily? Here's a sample configuration to spin up the Resource Discovery agent which will be publicly  exposed outside of the cluster on promitor-resource-discovery-sample.westeurope.cloudapp.azure.com:8889/api/docs/index.html.</p> <pre><code>azureAuthentication:\n  appId: 67882a00-21d3-4ee7-b32a-430ea0768cd3\n  appKey: &lt;hidden&gt;\nazureLandscape:\n  cloud: Global\n  tenantId: e0372f7f-a362-47fb-9631-74a5c4ba8bbf\n  subscriptionIds:\n  - 0329dd2a-59dc-4493-aa54-cb01cb027dc2\n  - 0f9d7fea-99e8-4768-8672-06a28514f77e\nresourceDiscoveryGroups:\n- name: service-bus-landscape\n  type: ServiceBusQueue\n- name: api-gateways\n  type: ApiManagement\n- name: app-plan-landscape\n  type: AppPlan\n- name: container-instances\n  type: ContainerInstance\n- name: container-registry-landscape\n  type: ContainerRegistry\n- name: cosmos-accounts\n  type: CosmosDb\n- name: dps\n  type: DeviceProvisioningService\n- name: event-hubs-landscape\n  type: EventHubs\nservice:\n  loadBalancer:\n    dnsPrefix: promitor-resource-discovery-sample\n    enabled: true\ntelemetry:\n  defaultLogLevel: information\n</code></pre> <p>You can easily deploy it by passing the file through <code>--values</code> during installation.</p> <p>\u2190 back</p>"},{"location":"deployment/scraper/","title":"Deploying Promitor Scraper","text":"<p>Here is an overview of how you can deploy Promitor on your infrastructure, we support both Linux and Windows.</p> <p>You can learn more about our Helm chart on artifacthub.io.</p> <p>For more information about advanced configuration, read our documentation here.</p>"},{"location":"deployment/scraper/docker/","title":"Docker","text":"<pre><code>\u276f docker run -d -p 8999:80 --name promitor-agent-scraper \\\n                           --env PROMITOR_AUTH_APPID='&lt;azure-ad-app-id&gt;' \\\n                           --env-file C:/Promitor/az-mon-auth.creds \\\n                           --volume C:/Promitor/metrics-declaration.yaml:/config/metrics-declaration.yaml \\\n                           --volume C:/Promitor/runtime.yaml:/config/runtime.yaml \\\n                           ghcr.io/tomkerkhove/promitor-agent-scraper\n</code></pre>"},{"location":"deployment/scraper/kubernetes/","title":"Kubernetes","text":""},{"location":"deployment/scraper/kubernetes/#kubernetes","title":"Kubernetes","text":"<p>We provide a Helm Chart which deploys all the required infrastructure on your Kubernetes cluster.</p>"},{"location":"deployment/scraper/kubernetes/#getting-the-helm-chart","title":"Getting the Helm Chart","text":"<p>Install the Promitor Chart repository:</p> <pre><code>\u276f helm repo add promitor https://charts.promitor.io/\n</code></pre> <p>Refresh your local Chart repositories:</p> <pre><code>\u276f helm repo update\n</code></pre> <p>If all goes well you should be able to list all Promitor charts:</p> <pre><code>\u276f helm search hub promitor\nURL                                                     CHART VERSION   APP VERSION     DESCRIPTION\nhttps://hub.helm.sh/charts/promitor/promitor-ag...      1.6.0           1.6.1           A Helm chart to deploy Promitor, an Azure Monit...\n</code></pre>"},{"location":"deployment/scraper/kubernetes/#using-our-helm-chart","title":"Using our Helm Chart","text":"<p>To use this, you will need to provide parameters via <code>--set</code> or <code>--values</code>. Included here are the values that correspond with the local environment variables. In addition to these, you will need a metric declaration file as described in Metric Declaration.</p> <pre><code>azureMetadata:\n  tenantId: \"&lt;azure-tenant-id&gt;\"\n  subscriptionId: \"&lt;azure-subscription-id&gt;\"\n\nruntime:\n  metricSinks:\n    atlassianStatuspage:\n      enabled: true\n      pageId: \"ABC\"\n      systemMetricMapping:\n      - id: nfkgnrwpn545\n        promitorMetricName: promitor_demo_appplan_percentage_cpu\n    openTelemetryCollector:\n      collectorUri: http://&lt;dns&gt;:4317\n    prometheusScrapingEndpoint:\n      enabled: true\n      baseUriPath: /metrics\n      enableMetricTimestamps: True\n    statsd:\n      enabled: true\n      host: graphite\n      port: 8125\n      metricPrefix: poc.promitor.\n  telemetry:\n    applicationInsights:\n      enabled: True\n      key: \"&lt;azure-app-insights-key&gt;\"\n\nmetrics:\n  - name: promitor_demo_servicebusqueue_queue_size\n    description: \"Amount of active messages of the 'orders' queue (determined with ServiceBusQueue provider)\"\n    resourceType: ServiceBusQueue\n    namespace: promitor-messaging\n    queueName: orders\n    azureMetricConfiguration:\n      metricName: ActiveMessages\n      aggregation:\n        type: Average\n</code></pre> <p>Check the full values file to see all configurable values.</p> <p>If you have a <code>metric-declaration.yaml</code> file, you can create a basic deployment with this command:</p> <pre><code>\u276f helm install promitor-agent-scraper promitor/promitor-agent-scraper \\\n               --set azureAuthentication.appId='&lt;azure-ad-app-id&gt;' \\\n               --set azureAuthentication.appKey='&lt;azure-ad-app-key&gt;' \\\n               --values /path/to/helm-configuration.yaml\n</code></pre> <p>\u2190 back</p>"},{"location":"operations/","title":"Operating Promitor","text":"<p>Here is an overview of how you can operate Promitor.</p> <ul> <li>Health<ul> <li>Consuming the health endpoint</li> </ul> </li> <li>Discovery<ul> <li>Subscription</li> <li>Resource Groups</li> </ul> </li> <li>Performance<ul> <li>Scraping Prometheus endpoint</li> <li>Scraping Azure Monitor</li> </ul> </li> <li>System<ul> <li>Consuming the System endpoint</li> <li>Exploring our REST APIs</li> </ul> </li> <li>Integrations<ul> <li>Azure Resource Manager API - Consumption &amp; Throttling</li> <li>Azure Resource Graph</li> <li>Azure Monitor</li> </ul> </li> </ul>"},{"location":"operations/discovery/","title":"Discovery","text":"<p>Promitor Resource Discovery provides a way to discover the resources for our Scraper agent to dynamically scrape resources.</p> <p>Next to that, it provides a variety of system metrics that provides information concerning your Azure landscape.</p>"},{"location":"operations/discovery/#subscription","title":"Subscription","text":"<p>Our <code>promitor_azure_landscape_subscription_info</code> metrics provides an overview of all the Azure subscriptions that  Promitor is able to discover in your Azure Landscape.</p> <p>It provides the following tags with more information:</p> <ul> <li><code>tenant_id</code> - Id of the Azure tenant</li> <li><code>subscription_name</code> - Name of the Azure subscription</li> <li><code>subscription_id</code> - Id of the Azure subscription</li> <li><code>state</code> - Indication of the state of the subscription (docs)</li> <li><code>spending_limit</code> - Indication whether or not there is a spending limit</li> <li><code>quota_id</code> - Id of the Azure subscription used to manage quotas</li> <li><code>authorization</code> - Type of authorization that is being used</li> </ul> <pre><code># HELP promitor_azure_landscape_subscription_info Provides information concerning the Azure subscriptions in the landscape that Promitor has access to.\n# TYPE promitor_azure_landscape_subscription_info gauge\npromitor_azure_landscape_subscription_info{tenant_id=\"e0372f7f-a362-47fb-9631-74a5c4ba8bbf\",subscription_name=\"Windows Azure MSDN - Visual Studio Ultimate\",subscription_id=\"0329dd2a-59dc-4493-aa54-cb01cb027dc2\",state=\"Enabled\",spending_limit=\"On\",quota_id=\"MSDN_2014-09-01\",authorization=\"RoleBased\"} 1 1628779903451\npromitor_azure_landscape_subscription_info{tenant_id=\"e0372f7f-a362-47fb-9631-74a5c4ba8bbf\",subscription_name=\"Visual Studio Enterprise\",subscription_id=\"0f9d7fea-99e8-4768-8672-06a28514f77e\",state=\"Enabled\",spending_limit=\"Off\",quota_id=\"Sponsored_2016-01-01\",authorization=\"RoleBased\"} 1 1628779903451\n</code></pre>"},{"location":"operations/discovery/#resource-groups","title":"Resource Groups","text":"<p>Our <code>promitor_azure_landscape_resource_group_info</code> metrics provides an overview of all the Azure resource groups that  Promitor is able to discover in your Azure Landscape across all your subscriptions.</p> <p>It provides the following tags with more information:</p> <ul> <li><code>tenant_id</code> - Id of the Azure tenant</li> <li><code>subscription_id</code> - Id of the Azure subscription</li> <li><code>resource_group_name</code> - Name of the Azure resource group</li> <li><code>region</code> - Region in which the resource group is located</li> <li><code>provisioning_state</code> - State of the resource group</li> <li><code>managed_by</code> - Id of the Azure resource managing this resource group, for example an Azure Kubernetes Service cluster.</li> </ul> <pre><code># HELP promitor_azure_landscape_resource_group_info Provides information concerning the Azure resource groups in the landscape that Promitor has access to.\n# TYPE promitor_azure_landscape_resource_group_info gauge\npromitor_azure_landscape_resource_group_info{tenant_id=\"e0372f7f-a362-47fb-9631-74a5c4ba8bbf\",subscription_id=\"0f9d7fea-99e8-4768-8672-06a28514f77e\",resource_group_name=\"NetworkWatcherRG\",region=\"westeurope\",provisioning_state=\"Succeeded\",managed_by=\"n/a\"} 1 1628779903423\npromitor_azure_landscape_resource_group_info{tenant_id=\"e0372f7f-a362-47fb-9631-74a5c4ba8bbf\",subscription_id=\"0f9d7fea-99e8-4768-8672-06a28514f77e\",resource_group_name=\"promitor-testing-resource-discovery-eu\",region=\"westeurope\",provisioning_state=\"Succeeded\",managed_by=\"n/a\"} 1 1628779903423\npromitor_azure_landscape_resource_group_info{tenant_id=\"e0372f7f-a362-47fb-9631-74a5c4ba8bbf\",subscription_id=\"0f9d7fea-99e8-4768-8672-06a28514f77e\",resource_group_name=\"MC_keda-demos_keda-demos_westeurope\",region=\"westeurope\",provisioning_state=\"Succeeded\",managed_by=\"/subscriptions/0f9d7fea-99e8-4768-8672-06a28514f77e/resourcegroups/keda-demos/providers/Microsoft.ContainerService/managedClusters/keda-demos\"} 1 1628779903423\n</code></pre>"},{"location":"operations/health/","title":"Health","text":"<p>Promitor provides a basic health endpoint that indicates the state of the scraper.</p> <p>Health endpoints can be useful for monitoring the scraper, running sanity tests after deployments or use it for sending liveness / health probes.</p>"},{"location":"operations/health/#consuming-the-health-endpoint","title":"Consuming the health endpoint","text":"<p>You can check the status with a simple <code>GET</code>:</p> <pre><code>\u276f curl -i -X GET \"http://&lt;uri&gt;/api/v1/health\"\n</code></pre> <p>Health is currently indicated via the HTTP response status:</p> <ul> <li><code>200 OK</code> - The scraper is healthy</li> <li><code>503 Service Unavailable</code> - The scraper is unhealthy</li> </ul> <p>The endpoint provides more details on integration with following dependencies:</p> <ul> <li>Promitor Resource Discovery (when configured)</li> </ul>"},{"location":"operations/integrations/","title":"Integrations","text":""},{"location":"operations/integrations/#azure-resource-manager-api-consumption-throttling","title":"Azure Resource Manager API - Consumption &amp; Throttling","text":"<p>Promitor exposes runtime metrics to provide insights on the API consumption of Azure Resource Manager API:</p> <ul> <li> <p><code>promitor_ratelimit_arm</code> - Indication how many calls are still available before   Azure Resource Manager is going to throttle us. Metric provides following labels:</p> <ul> <li><code>tenant_id</code> - Id of the tenant that is being interacted with</li> <li><code>subscription_id</code> - Id of the subscription that is being interacted with</li> <li><code>app_id</code> - Id of the application that is being used to interact with API</li> </ul> </li> <li> <p><code>promitor_ratelimit_arm_throttled</code> - Indication whether or not we are being throttled by Azure Resource Manager  (ARM). Metric provides following labels:</p> <ul> <li><code>tenant_id</code> - Id of the tenant that is being interacted with</li> <li><code>subscription_id</code> - Id of the subscription that is being interacted with</li> <li><code>app_id</code> - Id of the application that is being used to interact with API</li> </ul> </li> </ul> <pre><code># HELP promitor_ratelimit_arm Indication how many calls are still available before Azure Resource Manager (ARM) is going to throttle us.\n# TYPE promitor_ratelimit_arm gauge\npromitor_ratelimit_arm{tenant_id=\"e0372f7f-a362-47fb-9631-74a5c4ba8bbf\",subscription_id=\"0329dd2a-59dc-4493-aa54-cb01cb027dc2\",app_id=\"ceb249a3-44ce-4c90-8863-6776336f5b7e\"} 11995 1629719527020\npromitor_ratelimit_arm{tenant_id=\"e0372f7f-a362-47fb-9631-74a5c4ba8bbf\",subscription_id=\"0f9d7fea-99e8-4768-8672-06a28514f77e\",app_id=\"ceb249a3-44ce-4c90-8863-6776336f5b7e\"} 11989 1629719532626\n# HELP promitor_ratelimit_arm_throttled Indication concerning Azure Resource Manager are being throttled. (1 = yes, 0 = no).\n# TYPE promitor_ratelimit_arm_throttled gauge\npromitor_ratelimit_arm_throttled{tenant_id=\"e0372f7f-a362-47fb-9631-74a5c4ba8bbf\",subscription_id=\"0329dd2a-59dc-4493-aa54-cb01cb027dc2\",app_id=\"ceb249a3-44ce-4c90-8863-6776336f5b7e\"} 0 1629719527020\npromitor_ratelimit_arm_throttled{tenant_id=\"e0372f7f-a362-47fb-9631-74a5c4ba8bbf\",subscription_id=\"0f9d7fea-99e8-4768-8672-06a28514f77e\",app_id=\"ceb249a3-44ce-4c90-8863-6776336f5b7e\"} 0 1629719532626\n</code></pre> <p>You can read more about the Azure Resource Manager limitations on docs.microsoft.com.</p>"},{"location":"operations/integrations/#azure-resource-graph","title":"Azure Resource Graph","text":"<p>Promitor exposes runtime metrics to provide insights on the API consumption of Azure Resource Graph:</p> <ul> <li> <p><code>promitor_ratelimit_resource_graph_remaining</code> - Indication how many calls are still available before   Azure Resource Manager is going to throttle us. Metric provides following labels:</p> <ul> <li><code>tenant_id</code> - Id of the tenant that is being interacted with</li> <li><code>cloud</code> - Name of the cloud</li> <li><code>auth_mode</code> - Authentication mode to authenticate with</li> <li><code>app_id</code> - Id of the application that is being used to interact with</li> </ul> </li> <li> <p><code>promitor_ratelimit_resource_graph_throttled</code> - Indication whether or not we are being throttled by Azure Resource  Graph. Metric provides following labels:</p> <ul> <li><code>tenant_id</code> - Id of the tenant that is being interacted with</li> <li><code>cloud</code> - Name of the cloud</li> <li><code>auth_mode</code> - Authentication mode to authenticate with</li> <li><code>app_id</code> - Id of the application that is being used to interact with</li> </ul> </li> </ul> <pre><code># HELP promitor_ratelimit_resource_graph_remaining Indication how many calls are still available before Azure Resource Graph is going to throttle us.\n# TYPE promitor_ratelimit_resource_graph_remaining gauge\npromitor_ratelimit_resource_graph_remaining{tenant_id=\"e0372f7f-a362-47fb-9631-74a5c4ba8bbf\",cloud=\"Global\",auth_mode=\"ServicePrincipal\",app_id=\"67882a00-21d3-4ee7-b32a-430ea0768cd3\"} 9 1629719863738\n# HELP promitor_ratelimit_resource_graph_throttled Indication concerning Azure Resource Graph are being throttled. (1 = yes, 0 = no).\n# TYPE promitor_ratelimit_resource_graph_throttled gauge\npromitor_ratelimit_resource_graph_throttled{tenant_id=\"e0372f7f-a362-47fb-9631-74a5c4ba8bbf\",cloud=\"Global\",auth_mode=\"ServicePrincipal\",app_id=\"67882a00-21d3-4ee7-b32a-430ea0768cd3\"} 0 1629719863738\n</code></pre> <p>You can read more about the Azure Resource Graph throttling on docs.microsoft.com.</p>"},{"location":"operations/integrations/#azure-monitor","title":"Azure Monitor","text":"<p>Promitor interacts with Azure Monitor API to scrape all the required metrics.</p> <p>During troubleshooting it can be interesting to gain insights on what the API returns, for which you can opt-in.</p> <p>You can opt-in for it by configuring the runtime telemetry.</p> <p>\u2190 back</p>"},{"location":"operations/performance/","title":"Performance","text":"<p>You can easily monitor the performance of Promitor through the following Prometheus metrics:</p> <ul> <li><code>promitor_runtime_dotnet_collection_count_total</code> - Provides information related to garbage collection count per generation</li> <li><code>promitor_runtime_dotnet_totalmemory</code> - Provides information related to total known allocated memory</li> <li><code>promitor_runtime_process_cpu_seconds_total</code> - Provides information related to total user &amp; system CPU time spent in seconds</li> <li><code>promitor_runtime_process_virtual_bytes</code> - Provides information related to virtual memory size</li> <li><code>promitor_runtime_process_working_set</code> - Provides information related to process working set</li> <li><code>promitor_runtime_process_private_bytes</code> - Provides information related to process private memory size</li> <li><code>promitor_runtime_process_num_threads</code> - Provides information related to total number of threads</li> <li><code>promitor_runtime_process_processid</code> - Provides information related to process ID</li> <li><code>promitor_runtime_process_start_time_seconds</code> - Provides information related to the start time of the process since  unix epoch in seconds</li> <li><code>promitor_runtime_http_request_duration_seconds</code> - Provides information related to the performance of HTTP routes and outcomes</li> </ul> <pre><code># HELP promitor_runtime_http_request_duration_seconds duration histogram of http responses labeled with: status_code, method, path\n# TYPE promitor_runtime_http_request_duration_seconds histogram\npromitor_runtime_http_request_duration_seconds_bucket{status_code=\"200\",method=\"GET\",path=\"/scrape\",le=\"0.005\"} 30\npromitor_runtime_http_request_duration_seconds_bucket{status_code=\"200\",method=\"GET\",path=\"/scrape\",le=\"0.01\"} 31\npromitor_runtime_http_request_duration_seconds_bucket{status_code=\"200\",method=\"GET\",path=\"/scrape\",le=\"0.025\"} 31\npromitor_runtime_http_request_duration_seconds_bucket{status_code=\"200\",method=\"GET\",path=\"/scrape\",le=\"0.05\"} 32\npromitor_runtime_http_request_duration_seconds_bucket{status_code=\"200\",method=\"GET\",path=\"/scrape\",le=\"0.075\"} 33\npromitor_runtime_http_request_duration_seconds_bucket{status_code=\"200\",method=\"GET\",path=\"/scrape\",le=\"0.1\"} 33\npromitor_runtime_http_request_duration_seconds_bucket{status_code=\"200\",method=\"GET\",path=\"/scrape\",le=\"0.25\"} 34\npromitor_runtime_http_request_duration_seconds_bucket{status_code=\"200\",method=\"GET\",path=\"/scrape\",le=\"0.5\"} 34\npromitor_runtime_http_request_duration_seconds_bucket{status_code=\"200\",method=\"GET\",path=\"/scrape\",le=\"0.75\"} 34\npromitor_runtime_http_request_duration_seconds_bucket{status_code=\"200\",method=\"GET\",path=\"/scrape\",le=\"1\"} 34\npromitor_runtime_http_request_duration_seconds_bucket{status_code=\"200\",method=\"GET\",path=\"/scrape\",le=\"2.5\"} 34\npromitor_runtime_http_request_duration_seconds_bucket{status_code=\"200\",method=\"GET\",path=\"/scrape\",le=\"5\"} 34\npromitor_runtime_http_request_duration_seconds_bucket{status_code=\"200\",method=\"GET\",path=\"/scrape\",le=\"7.5\"} 34\npromitor_runtime_http_request_duration_seconds_bucket{status_code=\"200\",method=\"GET\",path=\"/scrape\",le=\"10\"} 34\npromitor_runtime_http_request_duration_seconds_bucket{status_code=\"200\",method=\"GET\",path=\"/scrape\",le=\"+Inf\"} 34\npromitor_runtime_http_request_duration_seconds_sum{status_code=\"200\",method=\"GET\",path=\"/scrape\"} 0.27116070000000003\npromitor_runtime_http_request_duration_seconds_count{status_code=\"200\",method=\"GET\",path=\"/scrape\"} 34\n</code></pre>"},{"location":"operations/performance/#scraping-prometheus-endpoint","title":"Scraping Prometheus endpoint","text":"<p>Every Promitor agent supports exposing Prometheus metrics:</p> <ul> <li>Resource Discovery agent - Exposed on <code>/metrics</code> endpoint</li> <li>Scraper agent - Exposed through Prometheus metric sink (docs)</li> </ul>"},{"location":"operations/performance/#scraping-azure-monitor","title":"Scraping Azure Monitor","text":"<p>You can easily monitor the performance of Promitor Scraper agent integrating with Azure Monitor  through the following Prometheus metrics:</p> <ul> <li><code>promitor_scrape_error</code> - Provides indication of all configured metrics that were unable to be scraped in Azure Monitor</li> </ul> <pre><code># HELP promitor_scrape_error Provides an indication that the scraping of the resource has failed\n# TYPE promitor_scrape_error gauge\npromitor_scrape_error{metric_name=\"promitor_demo_app_insights_dependency_duration_200_OK\",resource_group=\"docker-hub-metrics\",resource_name=\"Microsoft.Insights/Components/docker-hub-metrics\",resource_type=\"Generic\",subscription_id=\"0f9d7fea-99e8-4768-8672-06a28514f77e\",tenant_id=\"e0372f7f-a362-47fb-9631-74a5c4ba8bbf\"} 1 1623691623231\n</code></pre> <ul> <li><code>promitor_scrape_success</code> - Provides indication of all configured metrics that were successfully scraped and reported in the configured metric sinks</li> </ul> <pre><code># HELP promitor_scrape_success Provides an indication that the scraping of the resource was successful\n# TYPE promitor_scrape_success gauge\npromitor_scrape_success{metric_name=\"promitor_demo_automation_update_deployment_machine_runs\",resource_group=\"promitor-sources\",resource_name=\"promitor-sandbox\",resource_type=\"AutomationAccount\",subscription_id=\"0f9d7fea-99e8-4768-8672-06a28514f77e\",tenant_id=\"e0372f7f-a362-47fb-9631-74a5c4ba8bbf\"} 1 1623691626335\n</code></pre>"},{"location":"operations/system/","title":"System","text":"<p>Promitor provides a basic system endpoint that provides information about itself such as its version.</p>"},{"location":"operations/system/#consuming-the-system-endpoint","title":"Consuming the System endpoint","text":"<p>You can check the status with a simple <code>GET</code>:</p> <pre><code>\u276f curl -i -X GET \"http://&lt;uri&gt;/api/v1/system\"\n</code></pre>"},{"location":"operations/system/#exploring-our-rest-apis","title":"Exploring our REST APIs","text":"<p>We provide API documentation to make it easier for you to consume our REST APIs them:</p> <ul> <li>OpenAPI 3.0 format <ul> <li>You can explore it with OpenAPI UI on <code>/api/docs</code></li> <li>You can find the raw documentation on <code>/api/v1/docs.json</code></li> </ul> </li> <li>Swagger 2.0 format <ul> <li>You can explore it with Swagger UI on <code>/swagger</code></li> <li>You can find the raw documentation on <code>/swagger/v1/swagger.json</code></li> </ul> </li> </ul>"},{"location":"resource-discovery/declaring-resource-discovery-groups/","title":"Declaring resource discovery groups","text":"<p>Promitor Resource Discovery allows you to declare the Azure landscape to explore and define resource discovery groups  in YAML.</p> <p>Resource discovery groups represent a group of Azure resources of a given type that can be scraped by Promitor Scraper  and supports an extensive list of supported services.</p> <p>As part of the resource discovery group declaration, you can choose to filter resources by adding inclusion criteria  that resources must comply with based on:</p> <ul> <li>Subscription - Defines a subset of subscriptions defined in the Azure landscape</li> <li>Resource Group - Defines a list of resource groups which contains the resources.</li> <li>Tags - Defines a list of Azure tags  with which the resources have to be annotated.</li> <li>Regions - Defines a list of Azure regions in which the regions the resources are located.</li> </ul> <p>Here is an example of a full declaration using a custom cloud:</p> <pre><code>version: v1\nazureLandscape:\n  tenantId: e0372f7f-a362-47fb-9631-74a5c4ba8bbf\n  subscriptions:\n  - SUBSCRIPTON-ID-ABC\n  - SUBSCRIPTON-ID-DEF\n  - SUBSCRIPTON-ID-GHI\n  cloud: Custom\n  endpoints:\n    authenticationEndpoint: https://custom-authentication-endpoint\n    managementEndpoint: https://custom-management-endpoint\n    resourceManagerEndpoint: https://custom-resource-manager-endpoint\n    graphEndpoint: https://custom-graph-endpoint\n    storageEndpointSuffix: custom-storage-endpoint-suffix\n    keyVaultSuffix: custom-key-vault-suffix\nresourceDiscoveryGroups:\n- name: container-registry-landscape\n  type: ContainerRegistry\n- name: filtered-logic-apps-landscape\n  type: LogicApp\n  criteria:\n    include:\n      subscriptions:\n      - SUBSCRIPTON-ID-ABC\n      - SUBSCRIPTON-ID-GHI\n      resourceGroups:\n      - promitor-resource-group-1\n      - promitor-resource-group-2\n      tags:\n        app: promitor-1|promitor-2\n        region: europe\n      regions:\n      - northeurope\n      - westeurope\n</code></pre>"},{"location":"resource-discovery/declaring-resource-discovery-groups/#specification","title":"Specification","text":"<p>As Promitor evolves we need to change the structure of our resource discovery declaration.</p> <p><code>version: {version}</code> - Version of declaration that is used. Allowed values are <code>v1</code>. (Required)</p>"},{"location":"resource-discovery/declaring-resource-discovery-groups/#azure-landscape","title":"Azure Landscape","text":"<ul> <li><code>azureLandscape.tenantId</code> - The id of the Azure tenant that will be queried. (Required)</li> <li><code>azureLandscape.subscriptions</code> - List of Azure subscriptions in the Azure tenant to discover resources in. (Required)</li> <li><code>azureLandscape.cloud</code> - The name of the Azure cloud to use. Options are <code>Global</code>  (default), <code>China</code>, <code>UsGov</code>, <code>Germany</code>, &amp; <code>Custom</code>.</li> <li><code>azureLandscape.endpoints</code> - Required when <code>azureLandscape.cloud</code> is set to <code>Custom</code>. Defines the custom endpoints to use:<ul> <li><code>authenticationEndpoint</code> - The custom authentication endpoint.</li> <li><code>managementEndpoint</code> - The custom service management endpoint.</li> <li><code>resourceManagerEndpoint</code> - The custom Azure ARM resource management endpoint.</li> <li><code>graphEndpoint</code> - The custom Active Directory graph endpoint.</li> <li><code>storageEndpointSuffix</code> - The custom storage service url suffix.</li> <li><code>keyVaultSuffix</code> - The custom Key Vault service url suffix.</li> </ul> </li> </ul>"},{"location":"resource-discovery/declaring-resource-discovery-groups/#resource-discovery-groups","title":"Resource Discovery Groups","text":"<p>Every resource discovery group that is being declared needs to define the following fields:</p> <ul> <li><code>name</code> - Name of the resource discovery group which will be used in metrics declaration of Promitor Scraper. (Required)</li> <li><code>type</code> - Type of Azure resources that must be discovered, see \"Supported Azure Services\" for a full list of supported types. (Required)</li> <li><code>criteria</code> - Criteria to fine-tune discovered resource.</li> </ul>"},{"location":"resource-discovery/declaring-resource-discovery-groups/#criteria","title":"Criteria","text":"<p>As of now, we only allow to define criteria that resources have to meet before they are included in the resource  discovery group:</p> <ul> <li><code>subscriptions</code> - A list of subscription(s) in which the resource is allowed to be located.</li> <li><code>resourceGroups</code> - A list of resource group(s) in which the resource is allowed to be located.</li> <li><code>tags</code> - A list of Azure tags  and the expected values (exact or regular expression) with which the resources have to be annotated. (Uses <code>or</code>)</li> <li><code>regions</code> - A list of Azure region(s) in which the resource is allowed to be located.</li> </ul>"},{"location":"resource-discovery/overview/","title":"Overview","text":"<p>Resource discovery allows you to define criteria to automatically discover resources in your Azure tenant and scrape metrics for all of the Azure resources that are found.</p>"},{"location":"resource-discovery/overview/#how-it-works","title":"How it works","text":"<p>While Promitor Scraper uses a declarative approach for defining Azure resources to scrape; as of Promitor Scraper 2.0 you can integrate with Promitor Resource Discovery!</p> <p>With resource discovery, you can define resource discovery groups that represent Azure resources of a given type and optionally define criteria for the resources to comply with.</p> <p>By doing this, you can change your metric declaration for Promitor Scraper so that, instead of using declared resources, reference a resource discovery group which be used to determine what Azure resources it should scrape metrics for.</p> <p>Behind the scenes, Promitor Resource Discovery integrates with Azure Resource Graph which will query your Azure landscape to discover the corresponding resources.</p> <p>Here's an overview of how they work together:</p> <p></p>"},{"location":"resource-discovery/runtime-configuration/","title":"Runtime Configuration","text":"<p>This article covers an overview of all the knobs that you can tweak to align the Resource Discovery runtime with your needs.</p> <p>Promitor Resource Discovery runtime is configured by mounting the configuration to a volume.</p> <p>Depending on the operating system, it need to be available on :</p> <ul> <li><code>/config/runtime.yaml</code> for Linux</li> <li><code>c:/config/runtime.yaml</code> for Windows</li> </ul> <p>We provide the capability to override te runtime YAML via environment variables, if you have the need for it.</p> <p>Here is a complete example of the runtime YAML:</p> <pre><code>authentication:\n  # Options are ServicePrincipal, SystemAssignedManagedIdentity, UserAssignedManagedIdentity, SdkDefault.\n  mode: ServicePrincipal # Optional. Default: ServicePrincipal.\n  identityId: xxxx-xxxx-xxxx # Optional.\nserver:\n  httpPort: 80 # Optional. Default: 80\ncache:\n  enabled: true # Optional. Default: true\n  durationInMinutes: 5 # Optional. Default: 5\ntelemetry:\n  applicationInsights:\n    instrumentationKey: ABC # Optional. Note: Required to be specified when turned on\n    isEnabled: false # Optional. Default: false\n    verbosity: trace # Optional. Default: N/A\n  containerLogs:\n    isEnabled: true # Optional. Default: true\n    verbosity: trace # Optional. Default: N/A\n  defaultVerbosity: error # Optional. Default: error\n</code></pre>"},{"location":"resource-discovery/runtime-configuration/#authentication","title":"Authentication","text":"<p>The Promitor runtime allows you to use various ways to authenticate to Azure:</p> <ul> <li><code>authentication.mode</code> - Defines authentication mode to use. Options are <code>ServicePrincipal</code>,  <code>SystemAssignedManagedIdentity</code>, <code>UserAssignedManagedIdentity</code>, <code>SdkDefault</code> . (defaults to service principle)</li> <li><code>authentication.identityId</code> - Id of the Azure AD entity to authenticate with when integrating with Microsoft Azure.  Required when using <code>ServicePrincipal</code>.</li> </ul> <p>Example:</p> <pre><code>authentication:\n  # Options are ServicePrincipal, SystemAssignedManagedIdentity, UserAssignedManagedIdentity, SdkDefault.\n  mode: ServicePrincipal # Optional. Default: ServicePrincipal.\n  identityId: xxxx-xxxx-xxxx # Optional.\n</code></pre>"},{"location":"resource-discovery/runtime-configuration/#runtime","title":"Runtime","text":"<p>The Promitor runtime is flexible and allows you to configure it to meet your needs:</p> <ul> <li><code>server.httpPort</code> - Defines the port to serve HTTP traffic (default 80)</li> </ul> <p>Example:</p> <pre><code>server:\n  httpPort: 80 # Optional. Default: 80\n</code></pre>"},{"location":"resource-discovery/runtime-configuration/#cache","title":"Cache","text":"<p>The Promitor runtime allows you to cache discovered resources to optimize for performance and avoid hitting Azure throttling.</p> <p>You can configure how the cache should behave:</p> <ul> <li><code>cache.enabled</code> - Indication whether or not discovered resources should be cached in-memory. (default true)</li> <li><code>cache.durationInMinutes</code> - Amount of minutes to cache discovered resources. (default 5)</li> </ul> <p>Example:</p> <pre><code>cache:\n  enabled: true # Optional. Default: true\n  durationInMinutes: 5 # Optional. Default: 5\n</code></pre>"},{"location":"resource-discovery/runtime-configuration/#telemetry","title":"Telemetry","text":"<p>We provide insights in how our runtime is doing and is written to one or more sinks.</p> <p>You can determine what telemetry sinks you want and what the default verbosity should be via the runtime YAML.</p> <p>General telemetry information can be configured:</p> <ul> <li><code>telemetry.defaultVerbosity</code>- Defines the default minimum log level that should   be logged if a sink does not provide one. Allowed values are <code>Trace</code>, <code>Debug</code>,   <code>Information</code>, <code>Warning</code>, <code>Error</code>, <code>Critical</code>, <code>None</code> ordered from most to least   verbose. (Default: <code>Error</code>)</li> </ul> <p>To learn more about the configured sinks and their configuration, see \"Telemetry Sinks\".</p> <p>Example:</p> <pre><code>telemetry:\n  applicationInsights:\n    # [...]\n  containerLogs:\n    # [...]\n  defaultVerbosity: error # Optional. Default: error\n</code></pre>"},{"location":"resource-discovery/runtime-configuration/#telemetry-sinks","title":"Telemetry Sinks","text":"<p>Promitor provides the telemetry, but it's up to you to choose where you want to send it to.</p> <p>We currently support the following sinks:</p> <ul> <li>Container Logs (stdout/stderr)</li> <li>Azure Application Insights</li> </ul>"},{"location":"resource-discovery/runtime-configuration/#container-logs","title":"Container Logs","text":"<p>Promitor can send telemetry to <code>stdout</code>/<code>stderr</code>.</p> <p>In order to enable use this sink, the following configuration needs to be provided:</p> <ul> <li><code>telemetry.containerLogs.isEnabled</code> - Determines if the sink is used or not.   (Default: <code>true</code>)</li> <li><code>telemetry.containerLogs.verbosity</code> - Verbosity to use for this sink, if not   specified then the <code>telemetry.defaultVerbosity</code> will be used. (Optional)</li> </ul> <p>Example:</p> <pre><code>telemetry:\n  containerLogs:\n    isEnabled: true # Optional. Default: true\n    verbosity: trace # Optional. Default: N/A\n  defaultVerbosity: error # Optional. Default: error\n</code></pre>"},{"location":"resource-discovery/runtime-configuration/#azure-application-insights","title":"Azure Application Insights","text":"<p>Promitor can send telemetry to Azure Application Insights when there is a need to.</p> <p>It currently supports:</p> <ul> <li>Traces  </li> <li>Exceptions</li> </ul> <p>In order to enable use this sink, the following configuration needs to be provided:</p> <ul> <li><code>telemetry.applicationInsights.isEnabled</code> - Determines if the sink is used or not.   (Default: <code>true</code>)</li> <li><code>telemetry.applicationInsights.verbosity</code> - Verbosity to use for this sink, if   not specified then the <code>telemetry.defaultVerbosity</code> will be used. (Optional)</li> <li><code>telemetry.applicationInsights.instrumentationKey</code> - Defines the instrumentation   key to use when sending telemetry to Azure Application Insights</li> </ul> <p>Example:</p> <pre><code>telemetry:\n  applicationInsights:\n    instrumentationKey: ABC # Optional. Note: Required to be specified when turned on\n    isEnabled: false # Optional. Default: false\n    verbosity: trace # Optional. Default: N/A\n  containerLogs:\n    isEnabled: true # Optional. Default: true\n    verbosity: trace # Optional. Default: N/A\n  defaultVerbosity: error # Optional. Default: error\n</code></pre>"},{"location":"resource-discovery/runtime-configuration/#overriding-configuration-with-environment-variables","title":"Overriding configuration with environment variables","text":"<p>In certain scenarios you'd like to override what was configured in the runtime YAML. Therefore we provide the capability to override them via environment variables.</p> <p>Every environment variable should be prefixed with <code>PROMITOR_YAML_OVERRIDE_</code> followed by the YAML hierarchy where every level is replaced with <code>__</code> rather than a tab. Environment variables are not case sensitive.</p> <p>Our runtime configuration API endpoint allows you to verify if it was overriden and returns what will be used to run Promitor.</p> <p> Depending on the configuration that is changed it may be required to restart Promitor, for example changing the HTTP port.</p>"},{"location":"resource-discovery/runtime-configuration/#example","title":"Example","text":"<p>Let's say we want to override the following HTTP port:</p> <pre><code>server:\n  httpPort: 80\n</code></pre> <p>An environment variable called <code>PROMITOR_YAML_OVERRIDE_server__httpPort</code> can be provided which specifies the new port.</p> <p>\u2190 back</p>"},{"location":"scraping/batch-scraping/","title":"Using Batch Scraping with Azure Monitor API (Experimental)","text":"<p>Using batch scraping mode, Promitor will fetch resource metrics in batches by using the Azure Monitor data-plane API instead of Azure Resource Manager (ARM) to remove throttling.</p> <p>\u26a0\ufe0f The Azure Monitor data-plane API is not free, learn more in the official pricing documentation.</p> <p>Promitor deployments are able to monitor a greater set of unique resources and metrics, in part because its requests  go through dedicated APIs that allow for much greater throughput. However, there are important factors to consider(like cost) when deploying Promitor this way. </p> <p></p>"},{"location":"scraping/batch-scraping/#why-do-batch-scraping","title":"Why Do Batch Scraping?","text":"<p>The \"traditional\" scraping path goes through Azure Resource Management API, which enforces strict rate limits unsuitable for the throughput needed to monitor large number of resources or metrics. Dedicated APIs for batch scraping aren't subject to the same ARM rate limiting mechanis, and thus allow for much greater throughput. </p> <p>Additionally, there may be performance benefits associated with an overall lower number of networks requests. Though this benefit is only hypothetical for now.</p>"},{"location":"scraping/batch-scraping/#limitations","title":"Limitations","text":"<p>At the present moment, batch scraping can only target resources within the same region. Follow this issue for support across multiple regions</p> <p>Additionally, batch scraping does not work for LogAnalytics resources. Follow this issue for  suppor status. </p>"},{"location":"scraping/batch-scraping/#cost-considerations","title":"Cost Considerations","text":"<p>Under batch scraping mode, all declared metrics will be fetched through requests to Azure Monitor API. Billing for the API is calculated based on the number of requests.  </p> <p>Query Costs for metrics and logs are laid out here, under <code>Platform and custom metric queries (preview)</code> section. </p> <p>To estimate amount of Azure Monitor API requests(queries) a Promitor deployment will make for a length of time <code>L</code>, one can use the formula </p> \\[ \\small {\\# of requests} = \\text{number of resources} \\times \\text{number of metrics} \\times \\left(\\frac{L}{\\text{scrape interval * batch size}}\\right) \\] <p>Consider an example deployment that monitors 10 metrics across the same set of 100 resources, with a scrape interval of 5 minutes and configured max batch size of 20. In a given day roughly 100 * 10 * (1440/(5 * 20)) = 14400 requests will be made. The cost for that deployment can then be calculated using Azure Monitor's pricing chart</p>"},{"location":"scraping/batch-scraping/#how-are-batches-built","title":"How Are Batches Built","text":"<p>Batches are constructed using multiple constraints, such as the Azure Monitor metric within a batch must be the same. An important and configurable parameter is the max batch size. Azure Monitor currently(as of Oct 2024) imposes a max batch size of 50 per request, but users are free to impose an even lower limit. </p>"},{"location":"scraping/batch-scraping/#runtime-configuration","title":"Runtime Configuration","text":"<p>See Runtime Configuration page</p>"},{"location":"scraping/labels/","title":"Metric Labelling","text":"<p>Here is an overview of how we label metrics.</p> <p>There are a couple of scenarios where labels are being added:</p> <ul> <li>Built-in labels</li> <li>Metric dimension labels</li> <li>Scaler-specific labels</li> <li>Bring-your-own labels</li> </ul> <p>In case of duplicate label names the above priority will be used.</p>"},{"location":"scraping/labels/#built-in-labels","title":"Built-in labels","text":"<p>Every metric that is being reported in the scraping endpoint comes with the following built-in labels:</p> <ul> <li><code>resource_uri</code> - Full resource URI of the instance. (ie <code>subscriptions/xxx/resourceGroups/yyy/providers/Microsoft.ServiceBus/namespaces/promitor</code>)</li> <li><code>subscription_id</code> - Id of the subscription.</li> <li><code>resource_group</code> - Name of the resource group.</li> <li><code>instance_name</code> - Name of the instance, if applicable.</li> </ul>"},{"location":"scraping/labels/#metric-dimension-labels","title":"Metric dimension labels","text":"<p>Metrics support specifying one or more dimension(s) which will be scraped in Azure Monitor.</p> <p>Every metric value will be reported under the configured metric name, but labels for the dimensions and their respective values will be added.</p>"},{"location":"scraping/labels/#scraper-specific-labels","title":"Scraper-specific labels","text":"<p>Every scraper can provide additional labels to provide more information.</p> <p>Currently we support this for:</p> <ul> <li>Azure API Management</li> <li>Azure Function App</li> <li>Azure Service Bus</li> <li>Azure SQL Database</li> <li>Azure Storage Queue</li> <li>Azure Web App</li> </ul> <p>For more information, we recommend reading the scraper-specific documentation.</p>"},{"location":"scraping/labels/#custom-labels","title":"Custom Labels","text":"<p>As of v1.0, you can define your own labels by configuring them for a specific metric.</p> <p>For more information, see \"Metrics\".</p>"},{"location":"scraping/overview/","title":"Metrics Declaration","text":"<p>All the Azure Monitor metrics that need to be scraped are consolidated in one YAML file which is referred to as the metric declaration.</p> <p>This declaration defines the overall Azure metadata and all the metrics you want to expose.</p> <p>Every metric describes the Azure Monitor metric that it represents and what Azure resources that should be scraped.  It allows you to statically declaring the resources to scrape and/or use automatic resource discovery.</p>"},{"location":"scraping/overview/#supported-azure-services","title":"Supported Azure Services","text":"<p>Generic Azure Resource allows you to scrape every Azure service supported by Azure Monitor.</p> <p>We also provide a simplified way to scrape the following Azure resources:</p> <ul> <li>Azure API Management</li> <li>Azure Application Gateway</li> <li>Azure Application Insights</li> <li>Azure App Plan</li> <li>Azure Cache for Redis</li> <li>Azure Cache for Redis Enterprise</li> <li>Azure Content Delivery Network (CDN)</li> <li>Azure Container Instances</li> <li>Azure Container Registry</li> <li>Azure Cosmos DB</li> <li>Azure Data Factory</li> <li>Azure Data Share</li> <li>Azure Database for PostgreSQL</li> <li>Azure Database for MariaDB</li> <li>Azure Database for MySQL</li> <li>Azure Event Hubs</li> <li>Azure Express Route Circuit</li> <li>Azure Front Door</li> <li>Azure Function App</li> <li>Azure IoT Hub</li> <li>Azure IoT Hub Device Provisioning Service (DPS)</li> <li>Azure Key Vault</li> <li>Azure Kubernetes Service</li> <li>Azure Load Balancer</li> <li>Azure Logic Apps</li> <li>Azure Monitor Autoscale</li> <li>Azure Network Gateway</li> <li>Azure Network Interface</li> <li>Azure Service Bus Namespace</li> <li>Azure SQL Database</li> <li>Azure SQL Elastic Pool</li> <li>Azure SQL Managed Instance</li> <li>Azure SQL Server</li> <li>Azure Storage (Account)</li> <li>Azure Storage (Blob)</li> <li>Azure Storage (Files)</li> <li>Azure Storage (Queue)</li> <li>Azure Synapse (Apache Spark pool)</li> <li>Azure Synapse (SQL pool)</li> <li>Azure Synapse (Workspace)</li> <li>Azure Virtual Machine</li> <li>Azure Virtual Machine Scale Set (VMSS)</li> <li>Azure Virtual Network</li> <li>Azure Web App</li> </ul> <p>Want to help out? Create an issue and contribute a new scraper.</p>"},{"location":"scraping/overview/#general-declaration","title":"General Declaration","text":"<p>As Promitor evolves we need to change the structure of our metrics declaration.</p> <p><code>version: {version}</code> - Version of declaration that is used. Allowed values are <code>v1</code>. (Required)</p>"},{"location":"scraping/overview/#azure","title":"Azure","text":"<ul> <li><code>azureMetadata.tenantId</code> - The id of the Azure tenant that will be queried.</li> <li><code>azureMetadata.subscriptionId</code> - The id of the default subscription to query.</li> <li><code>azureMetadata.resourceGroupName</code> - The name of the default resource group to query.</li> <li><code>azureMetadata.cloud</code> - The name of the Azure cloud to use. Options are <code>Global</code>  (default), <code>China</code>, <code>UsGov</code>, <code>Germany</code>, &amp; <code>Custom</code>.</li> <li><code>azureMetadata.endpoints</code> - Required when <code>azureMetadata.cloud</code> is set to <code>Custom</code>. Defines the custom endpoints to use:<ul> <li><code>authenticationEndpoint</code> - The custom authentication endpoint.</li> <li><code>managementEndpoint</code> - The custom service management endpoint.</li> <li><code>resourceManagerEndpoint</code> - The custom Azure ARM resource management endpoint.</li> <li><code>graphEndpoint</code> - The custom Active Directory graph endpoint.</li> <li><code>storageEndpointSuffix</code> - The custom storage service url suffix.</li> <li><code>keyVaultSuffix</code> - The custom Key Vault service url suffix.</li> <li><code>metricsQueryAudience</code> - The custom audiences available for metrics query.</li> <li><code>metricsClientAudience</code> - The custom audiences available for metrics client.</li> <li><code>logAnalyticsEndpoint</code> - The custom log analytics endpoint. (Required only if Azure Log Analytics resource is configured for scraping)</li> </ul> </li> </ul>"},{"location":"scraping/overview/#metric-defaults","title":"Metric Defaults","text":"<ul> <li><code>metricDefaults.aggregation.interval</code> - The default interval which defines over   what period measurements of a metric should be aggregated.   a cron that fits your needs.</li> <li><code>metricDefaults.limit</code> - The default maximum amount of resources to scrape when using dimensions   or filters.</li> <li><code>metricDefaults.labels</code> - The default labels that will be applied to all metrics. (starting as of v2.3)</li> <li><code>metricDefaults.scraping.schedule</code> - A cron expression that controls   the frequency of which all the configured metrics will be scraped from Azure Monitor.   You can use crontab-generator.org to generate   a cron that fits your needs. (Required)</li> </ul>"},{"location":"scraping/overview/#metrics","title":"Metrics","text":"<p>Every metric that is being declared needs to define the following fields:</p> <ul> <li><code>name</code> - Name of the metric that will be reported.</li> <li><code>description</code> - Description for the metric that will be reported.</li> <li><code>resourceType</code> - Defines what type of resource needs to be queried.</li> <li><code>azureMetricConfiguration.metricName</code> - The name of the metric in Azure Monitor   to query</li> <li><code>azureMetricConfiguration.aggregation.type</code> - The aggregation that needs to be   used when querying Azure Monitor</li> <li><code>azureMetricConfiguration.aggregation.interval</code> - Overrides the default aggregation   interval defined in <code>metricDefaults.aggregation.interval</code> with a new interval</li> <li><code>resources</code> - An array of one or more resources to get metrics for. The fields   required vary depending on the <code>resourceType</code> being created, and are documented   for each resource.</li> <li><code>azureMetricConfiguration.limit</code> - The maximum amount of resources to scrape when using dimensions   or filters.</li> <li><code>resourceDiscoveryGroups</code> An array of one or more resource discovery groups that will be used to automatically  discover all resources through Promitor Resource Discovery. For every found resource, it will get the metrics and   report them. Learn more on resource discovery, in our documentation</li> </ul> <p>All resources provide the capability to override the default Azure metadata:</p> <ul> <li><code>subscriptionId</code> - Changes the subscription id to which the resource belongs. (Overrides <code>azureMetadata.subscriptionId</code>)</li> <li><code>resourceGroupName</code> - Changes the resource group that contains resource. (Overrides <code>azureMetadata.resourceGroupName</code>)</li> </ul> <p>Additionally, the following fields are optional:</p> <ul> <li><code>azureMetricConfiguration.dimensions</code> - A list of dimensions that should    be used to scrape a multi-dimensional metric in Azure Monitor.</li> <li>\u261d Promitor simply acts as a proxy and will not validate if the given dimensions are supported or      not, we recommend verifying that they are in the      official documentation</li> <li><code>labels</code> - Defines a set of custom labels to include for a given metric.</li> <li><code>scraping.schedule</code> - A scraping schedule for the individual metric; overrides   the the one specified in <code>metricDefaults</code></li> </ul>"},{"location":"scraping/overview/#example","title":"Example","text":"<p>Here is an example of how you can scrape two Azure Service Bus queues in different resource groups, one in the <code>promitor</code> resource group and one on the <code>promitor-dev</code> resource group. This example also shows custom cloud endpoints configuration:</p> <pre><code>version: v1\nazureMetadata:\n  tenantId: xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\n  subscriptionId: yyyyyyyy-yyyy-yyyy-yyyy-yyyyyyyyyyyy\n  resourceGroupName: promitor\n  cloud: Custom\n  endpoints:\n    authenticationEndpoint: https://custom.auth.endpoint.com\n    managementEndpoint: https://custom.svc.management.endpoint.com\n    resourceManagerEndpoint: https://custom.resource.management.endpoint.com\n    graphEndpoint: https://custom.graph.endpoint.com\n    storageEndpointSuffix: custom.windows.net\n    keyVaultSuffix: custom.vault.azure.net\n    metricsQueryAudience: https://custom.metric.query.endpoint.com\n    metricsClientAudience: https://custom.metric.client.endpoint.com\nmetricDefaults:\n  aggregation:\n    interval: 00:05:00\n  limit: 10\n  labels:\n    geo: china\n    environment: dev\n  scraping:\n    # Every minute\n    schedule: \"0 * * ? * *\"\nmetrics:\n  - name: azure_service_bus_active_messages\n    description: \"The number of active messages on a service bus queue.\"\n    resourceType: ServiceBusNamespace\n    labels:\n      app: promitor\n      tier: messaging\n    scraping:\n      # Every 2 minutes\n      schedule: \"0 */2 * ? * *\"\n    azureMetricConfiguration:\n      metricName: ActiveMessages\n      limit: 5\n      # Deprecated, please use 'dimensions' instead\n      dimension:\n        name: &lt;dimension-name&gt;\n      dimensions:\n        - name: &lt;first-dimension-name&gt;\n        - name: &lt;second-dimension-name&gt;\n      aggregation:\n        type: Total\n        interval: 00:15:00\n    resources: # Optional, required when no resource discovery is configured\n      - namespace: promitor-messaging\n        queueName: orders\n      - namespace: promitor-messaging-dev\n        resourceGroupName: promitor-dev\n        subscriptionId: ABC\n    resourceDiscoveryGroups: # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery)\n    - name: service-bus-landscape\n</code></pre> <p>\u2190 back</p>"},{"location":"scraping/runtime-configuration/","title":"Runtime Configuration","text":"<p>This article covers an overview of all the knobs that you can tweak to align the Scraper runtime with your needs.</p> <p>Promitor Scraper runtime is configured by mounting the configuration to a volume.</p> <p>Depending on the operating system, it need to be available on :</p> <ul> <li><code>/config/runtime.yaml</code> for Linux</li> <li><code>c:/config/runtime.yaml</code> for Windows</li> </ul> <p>We provide the capability to override te runtime YAML via environment variables, if you have the need for it.</p> <p>Here is a complete example of the runtime YAML:</p> <pre><code>authentication:\n  # Options are ServicePrincipal, SystemAssignedManagedIdentity, UserAssignedManagedIdentity, SdkDefault.\n  mode: ServicePrincipal # Optional. Default: ServicePrincipal.\n  identityId: xxxx-xxxx-xxxx # Optional.\nserver:\n  httpPort: 80 # Optional. Default: 80\nmetricSinks:\n  atlassianStatuspage:\n    pageId: XXX          # Mandatory\n    systemMetricMapping: # Mandatory to have at least one mapping\n    - id: ABC\n      promitorMetricName: promitor_demo_appplan_percentage_cpu\n  openTelemetryCollector:\n    collectorUri: http://&lt;dns&gt;:4317\n  prometheusScrapingEndpoint:\n    metricUnavailableValue: NaN # Optional. Default: NaN\n    enableMetricTimestamps: false # Optional. Default: true\n    baseUriPath: /metrics # Optional. Default: /metrics\n    labels:\n      transformation: None # Optional. Default: None.\n  statsd:\n    host: graphite\n    port: 8125 # Optional. Default: 8125\n    metricPrefix: promitor. # Optional. Default: None\nmetricsConfiguration:\n  absolutePath: /config/metrics-declaration.yaml # Optional. Default: /config/metrics-declaration.yaml\nazureMonitor:\n  logging:\n    informationLevel: Basic # Optional. Default: Basic\n    isEnabled: false # Optional. Default: false\n  integration:\n    useAzureMonitorSdk: true # Optional. Default: true\n    history:\n      startingFromInHours: 24 # Optional. Default: 12\ntelemetry:\n  applicationInsights:\n    instrumentationKey: ABC # Optional. Note: Required to be specified when turned on\n    isEnabled: false # Optional. Default: false\n    verbosity: trace # Optional. Default: N/A\n  containerLogs:\n    isEnabled: true # Optional. Default: true\n    verbosity: trace # Optional. Default: N/A\n  defaultVerbosity: error # Optional. Default: error\nresourceDiscovery:\n  host: promitor.agents.resourcediscovery # Optional. DNS name of Promitor Resource Discovery agent\n  enabled: true # Optional. Indication whether or not resource discovery is enabled through the Promitor Resource Discovery agent.\n  port: 88 # Optional. Port of Promitor Resource Discovery agent\n</code></pre>"},{"location":"scraping/runtime-configuration/#authentication","title":"Authentication","text":"<p>The Promitor runtime allows you to use various ways to authenticate to Azure:</p> <ul> <li><code>authentication.mode</code> - Defines authentication mode to use. Options are <code>ServicePrincipal</code>,  <code>SystemAssignedManagedIdentity</code>, <code>UserAssignedManagedIdentity</code>, <code>SdkDefault</code>. (defaults to service principle)</li> <li><code>authentication.identityId</code> - Id of the Azure AD entity to authenticate with when integrating with Microsoft Azure.  Required when using <code>ServicePrincipal</code>.</li> </ul> <p>Example:</p> <pre><code>authentication:\n  # Options are ServicePrincipal, SystemAssignedManagedIdentity, UserAssignedManagedIdentity, SdkDefault.\n  mode: ServicePrincipal # Optional. Default: ServicePrincipal.\n  identityId: xxxx-xxxx-xxxx # Optional.\n</code></pre>"},{"location":"scraping/runtime-configuration/#runtime","title":"Runtime","text":"<p>The Promitor runtime is flexible and allows you to configure it to meet your needs:</p> <ul> <li><code>server.httpPort</code> - Defines the port to serve HTTP traffic (default 80)</li> </ul> <p>Example:</p> <pre><code>server:\n  httpPort: 80 # Optional. Default: 80\n</code></pre>"},{"location":"scraping/runtime-configuration/#metric-sinks","title":"Metric Sinks","text":"<p>Promitor automatically scrapes Azure Monitor and makes the information available by providing the metric information to the configured sinks.</p> <p>As of today, we support the follow sinks:</p> <ul> <li>Atlassian Statuspage</li> <li>OpenTelemetry Collector</li> <li>Prometheus Scraping Endpoint</li> <li>StatsD</li> </ul>"},{"location":"scraping/runtime-configuration/#atlassian-statuspage","title":"Atlassian Statuspage","text":"<p>In order to expose an Atlassian Statuspage endpoint, you'll need to configure the sink:</p> <ul> <li><code>atlassianStatuspage.pageId</code> - Defines the id of the Atlassian Statuspage to report to.</li> <li><code>atlassianStatuspage.systemMetricMapping</code> - Defines a mapping of the scraped metric by Promitor and to which  Atlassian Statuspage system metric it should be reported to. Here's what we expect:<ul> <li><code>id</code> - Id of the Atlassian Statuspage system metric</li> <li><code>promitorMetricName</code> - Name of the Promitor metric which needs to be reported</li> </ul> </li> </ul> <p>Next to that, <code>PROMITOR_ATLASSIAN_STATUSPAGE_APIKEY</code> environment variable is required which contains the API Key  for Atlassian Statuspage.</p> <pre><code>metricSinks:\n  atlassianStatuspage:\n    pageId: XXX          # Mandatory\n    systemMetricMapping: # Mandatory to have at least one mapping\n    - id: ABC\n      promitorMetricName: promitor_demo_appplan_percentage_cpu\n</code></pre> <p> As of today, metric labels, resource discovery and multi-resource scraping are not supported.</p> <p>This is because Promitor will report the different resource metrics to the same Atlassian metric which will mix metrics which becomes confusing.</p>"},{"location":"scraping/runtime-configuration/#opentelemetry-collector","title":"OpenTelemetry Collector","text":"<p>In order to push metrics to an OpenTelemetry Collector, you'll need to configure the sink:</p> <ul> <li><code>openTelemetryCollector.collectorUri</code> - Uri of the OpenTelemetry Collector.</li> </ul> <pre><code>openTelemetryCollector:\n  collectorUri: http://&lt;dns&gt;:4317\n</code></pre>"},{"location":"scraping/runtime-configuration/#prometheus-scraping-endpoint","title":"Prometheus Scraping Endpoint","text":"<p>In order to expose a Prometheus Scraping endpoint, you'll need to configure the sink:</p> <ul> <li><code>prometheusScrapingEndpoint.metricUnavailableValue</code> - Defines the value that will be reported   if a metric is unavailable. (Default: <code>NaN</code>)</li> <li><code>prometheusScrapingEndpoint.enableMetricTimestamps</code> - Defines whether or not a timestamp should   be included when the value was scraped on Azure Monitor. Supported values are   <code>True</code> to opt-in &amp; <code>False</code> to opt-out. (Default: <code>true</code>)</li> <li><code>prometheusScrapingEndpoint.baseUriPath</code> - Controls the path where the scraping   endpoint for Prometheus is being exposed.  (Default: <code>/metrics</code>)</li> <li><code>prometheusScrapingEndpoint.labels.transformation</code> - Controls how label values are reported to Prometheus by using  transformation. Options are <code>None</code> &amp; <code>Lowercase</code>.  (Default: <code>None</code>)</li> </ul> <pre><code>metricSinks:\n  prometheusScrapingEndpoint:\n    metricUnavailableValue: NaN # Optional. Default: NaN\n    enableMetricTimestamps: false # Optional. Default: true\n    baseUriPath: /metrics # Optional. Default: /metrics\n    labels:\n      transformation: None # Optional. Default: None.\n</code></pre>"},{"location":"scraping/runtime-configuration/#what-happens-when-metrics-are-unavailable-for-multi-dimensional-metrics","title":"What happens when metrics are unavailable for multi-dimensional metrics?","text":"<p>Promitor allows you to use one or more dimension(s) in metrics so that it will report all values.</p> <p>For example, when scraping an Azure Event Hub namespace you can report the same metric for every entity inside the namespace.</p> <p>When Promitor reports the metric it will always add a label which clarifies the subresource. However, when it cannot find  a metric for that dimension it will keep on reporting the metric, but with value <code>unknown</code> given it cannot determine   the name of the dimension.</p>"},{"location":"scraping/runtime-configuration/#statsd","title":"StatsD","text":"<p>In order to push metrics to a StatsD server, you'll need to configure the sink:</p> <ul> <li><code>metricSinks.statsd.host</code> - DNS name or IP address of StatsD server.</li> <li><code>metricSinks.statsd.host</code> - Port (UDP) address of StatsD server. (Default: <code>8125</code>)</li> <li><code>metricSinks.statsd.metricPrefix</code> - Prefix that will be added to every metric  defined in the metric declaration.</li> </ul> <pre><code>metricSinks:\n  statsd:\n    host: graphite\n    port: 8125\n    metricPrefix: promitor.\n</code></pre> <p> As of today, metric labels are not supported.</p> <p>Unfortunately, this is not supported in the specification.</p>"},{"location":"scraping/runtime-configuration/#using-resource-discovery","title":"Using resource discovery","text":"<p>Resource discovery can be used by integrating with Promitor Resource Discovery which allows you to scrape metrics by using  discovery groups.</p> <p>In order to enable this, resource discovery must be configured first:</p> <ul> <li><code>resourceDiscovery.enabled</code> - Indication whether or not resource discovery is enabled through the  Promitor Resource Discovery agent.</li> <li><code>resourceDiscovery.host</code> - DNS name of Promitor Resource Discovery agent.</li> <li><code>resourceDiscovery.port</code> - Port of Promitor Resource Discovery agent.</li> </ul> <pre><code>resourceDiscovery:\n  host: promitor.agents.resourcediscovery\n  enabled: true\n  port: 88 # Optional. Default: 80\n</code></pre> <p>To learn more about how Promitor Scraper and Promitor Resource Discovery work together, read our documentation.</p>"},{"location":"scraping/runtime-configuration/#metric-configuration","title":"Metric Configuration","text":"<p>Promitor will scrape the Azure Monitor metrics that are configured via a metric declaration YAML.</p> <p>The behavior of this is configurable:</p> <ul> <li><code>metricsConfiguration.absolutePath</code> - Defines the location of the YAML file that declares what Azure Monitor metrics to scrape. (Default: <code>/config/metrics-declaration.yaml</code>)</li> </ul> <p>Example:</p> <pre><code>metricsConfiguration:\n  absolutePath: /config/metrics-declaration.yaml # Optional. Default: /config/metrics-declaration.yaml\n</code></pre>"},{"location":"scraping/runtime-configuration/#telemetry","title":"Telemetry","text":"<p>We provide insights in how our runtime is doing and is written to one or more sinks.</p> <p>You can determine what telemetry sinks you want and what the default verbosity should be via the runtime YAML.</p> <p>General telemetry information can be configured:</p> <ul> <li><code>telemetry.defaultVerbosity</code>- Defines the default minimum log level that should   be logged if a sink does not provide one. Allowed values are <code>Trace</code>, <code>Debug</code>,   <code>Information</code>, <code>Warning</code>, <code>Error</code>, <code>Critical</code>, <code>None</code> ordered from most to least   verbose. (Default: <code>Error</code>)</li> </ul> <p>To learn more about the configured sinks and their configuration, see \"Telemetry Sinks\".</p> <p>Example:</p> <pre><code>telemetry:\n  applicationInsights:\n    # [...]\n  containerLogs:\n    # [...]\n  defaultVerbosity: error # Optional. Default: error\n</code></pre>"},{"location":"scraping/runtime-configuration/#telemetry-sinks","title":"Telemetry Sinks","text":"<p>Promitor provides the telemetry, but it's up to you to choose where you want to send it to.</p> <p>We currently support the following sinks:</p> <ul> <li>Container Logs (stdout/stderr)</li> <li>Azure Application Insights</li> </ul>"},{"location":"scraping/runtime-configuration/#container-logs","title":"Container Logs","text":"<p>Promitor can send telemetry to <code>stdout</code>/<code>stderr</code>.</p> <p>In order to enable use this sink, the following configuration needs to be provided:</p> <ul> <li><code>telemetry.containerLogs.isEnabled</code> - Determines if the sink is used or not.   (Default: <code>true</code>)</li> <li><code>telemetry.containerLogs.verbosity</code> - Verbosity to use for this sink, if not   specified then the <code>telemetry.defaultVerbosity</code> will be used. (Optional)</li> </ul> <p>Example:</p> <pre><code>telemetry:\n  containerLogs:\n    isEnabled: true # Optional. Default: true\n    verbosity: trace # Optional. Default: N/A\n  defaultVerbosity: error # Optional. Default: error\n</code></pre>"},{"location":"scraping/runtime-configuration/#azure-application-insights","title":"Azure Application Insights","text":"<p>Promitor can send telemetry to Azure Application Insights when there is a need to.</p> <p>It currently supports:</p> <ul> <li>Traces  </li> <li>Exceptions</li> </ul> <p>In order to enable use this sink, the following configuration needs to be provided:</p> <ul> <li><code>telemetry.applicationInsights.isEnabled</code> - Determines if the sink is used or not.   (Default: <code>true</code>)</li> <li><code>telemetry.applicationInsights.verbosity</code> - Verbosity to use for this sink, if   not specified then the <code>telemetry.defaultVerbosity</code> will be used. (Optional)</li> <li><code>telemetry.applicationInsights.instrumentationKey</code> - Defines the instrumentation   key to use when sending telemetry to Azure Application Insights</li> </ul> <p>Example:</p> <pre><code>telemetry:\n  applicationInsights:\n    instrumentationKey: ABC # Optional. Note: Required to be specified when turned on\n    isEnabled: false # Optional. Default: false\n    verbosity: trace # Optional. Default: N/A\n  containerLogs:\n    isEnabled: true # Optional. Default: true\n    verbosity: trace # Optional. Default: N/A\n  defaultVerbosity: error # Optional. Default: error\n</code></pre>"},{"location":"scraping/runtime-configuration/#azure-monitor","title":"Azure Monitor","text":"<p>Promitor interacts with Azure Monitor API to scrape all the required metrics.</p> <p>During troubleshooting it can be interesting to gain insights on what the API returns, for which you can opt-in.</p> <p>The behavior of this can be configured to fit your needs:</p> <ul> <li><code>azureMonitor.logging.informationLevel</code> - Defines granularity of information that should be reported. Available  options are <code>Basic</code>, <code>Headers</code>, <code>Body</code> &amp; <code>BodyAndHeaders</code>. (Default: <code>Basic</code>)</li> <li><code>azureMonitor.logging.isEnabled</code> - Defines whether or not information concerning the integration with Azure Monitor  API. (Default: <code>false</code>)</li> <li><code>azureMonitor.integration.history.startingFromInHours</code> - Defines the amount of hours Promitor will use to define the starting point of the time window used for metric queries.</li> <li>As an example, the default is 12 hours which means Promitor will fetch all metrics between now - 12 hours and now to find a matching metric. Typically this window can be very small but Promitor provides a margin by default to prevent problems for long aggregation periods. (Default: <code>12</code>)</li> <li><code>azureMonitor.integration.useAzureMonitorSdk</code> - In the newest release of Promitor, integration with Azure Monitor will use Azure.Monitor package under Azure SDK for .NET by default. This migration was needed because the original SDK has been deprecated since 2022. </li> <li><code>azureMonitor.integration.metricsBatching.enabled</code> - whether to scrape metrics batch scraping mode (Default: <code>False</code>) </li> <li><code>azureMonitor.integration.metricsBatching.azureRegion</code> - Azure region of batch scrape resource targets. This is required for batch scraping to work</li> <li><code>azureMonitor.integration.metricsBatching.maxBatchSize</code> - Max number of resources allowed in a batch. Azure's limit is 50 but user can set it lower(Default: <code>50</code>) </li> </ul> <p>Example:</p> <pre><code>azureMonitor:\n  logging:\n    informationLevel: Basic # Optional. Default: Basic\n    isEnabled: false # Optional. Default: false\n  integration:\n    metricsBatching:\n      enabled: true \n      maxBatchSize: 25 \n      azureRegion: eastus\n    useAzureMonitorSdk: true # Optional. Default: true\n    history:\n      startingFromInHours: 24 # Optional. Default: 12\n</code></pre> <p>Note: All telemetry is emitted as <code>trace</code> so you have to make sure <code>telemetry</code> is configured correctly.</p>"},{"location":"scraping/runtime-configuration/#overriding-configuration-with-environment-variables","title":"Overriding configuration with environment variables","text":"<p>In certain scenarios you'd like to override what was configured in the runtime YAML. Therefore we provide the capability to override them via environment variables.</p> <p>Every environment variable should be prefixed with <code>PROMITOR_YAML_OVERRIDE_</code> followed by the YAML hierarchy where every level is replaced with <code>__</code> rather than a tab. Environment variables are not case sensitive.</p> <p>Our runtime configuration API endpoint allows you to verify if it was overriden and returns what will be used to run Promitor.</p> <p> Depending on the configuration that is changed it may be required to restart Promitor, for example changing the HTTP port.</p>"},{"location":"scraping/runtime-configuration/#example","title":"Example","text":"<p>Let's say we want to override the following HTTP port:</p> <pre><code>server:\n  httpPort: 80\n</code></pre> <p>An environment variable called <code>PROMITOR_YAML_OVERRIDE_server__httpPort</code> can be provided which specifies the new port.</p> <p>\u2190 back</p>"},{"location":"scraping/providers/api-management/","title":"Azure API Management","text":"<p>You can scrape an Azure API Management via the <code>ApiManagement</code>  resource type.</p> <p>When using declared resources, the following fields need to be provided:</p> <ul> <li><code>instanceName</code> - The name of the Azure API Management instance.</li> <li><code>locationName</code> - The name of the regional deployment of the gateway. (optional)</li> </ul> <p>All supported metrics are documented in the official Azure Monitor documentation.</p>","tags":["Scraper","Resource Discovery","API","Integration","PaaS"]},{"location":"scraping/providers/api-management/#multi-region-support","title":"Multi-region support","text":"<p>Azure API Management instances can be deployed to multiple regions across the world.</p> <p>Promitor supports different scenarios:</p> <ol> <li>Report metrics for metrics for all locations (default)</li> <li>Scope metric to a single region by configuring <code>locationName</code>.</li> <li>Report metrics but split it across all regions by using the <code>Location</code> dimension.</li> </ol> <p>The following scraper-specific metric label will be added for scenario 2 &amp; 3:</p> <ul> <li><code>location</code> - Name of the location</li> </ul>","tags":["Scraper","Resource Discovery","API","Integration","PaaS"]},{"location":"scraping/providers/api-management/#example","title":"Example","text":"<p>Here is an example configuration:</p> <pre><code>name: promitor_demo_azureapimanagement_capacity\ndescription: \"The amount of capacity used an Azure API Management instance.\"\nresourceType: ApiManagement\nazureMetricConfiguration:\n  metricName: Capacity\n  aggregation:\n    type: Average\nresources: # Optional, required when no resource discovery is configured\n- instanceName: promitor-api-gateway\nresourceDiscoveryGroups: # Optional, requires Promitor Resource Discovery agent (https://docs.promitor.io/latest/how-it-works#using-resource-discovery)\n- name: api-management-landscape\n</code></pre>","tags":["Scraper","Resource Discovery","API","Integration","PaaS"]},{"location":"scraping/providers/app-plan/","title":"Azure App Plan","text":"<p>You can declare to scrape an Azure App Plan via the <code>AppPlan</code> resource type.</p> <p>When using declared resources, the following fields need to be provided:</p> <ul> <li><code>appPlanName</code> - The name of the Azure App Plan</li> </ul> <p>All supported metrics are documented in the official Azure Monitor documentation.</p>","tags":["Scraper","Resource Discovery","PaaS","Web","API"]},{"location":"scraping/providers/app-plan/#example","title":"Example","text":"<p>Here is an example configuration:</p> <pre><code>name: azure_app_plan_percentage_memory\ndescription: \"Average percentage of memory usage on an Azure App Plan\"\nresourceType: AppPlan\nazureMetricConfiguration:\n  metricName: MemoryPercentage\n  aggregation:\n    type: Average\nresources: # Optional, required when no resource discovery is configured\n- appPlanName: promitor-app-plan\nresourceDiscoveryGroups: # Optional, requires Promitor Resource Discovery agent (https://docs.promitor.io/latest/how-it-works#using-resource-discovery)\n- name: app-plans-landscape\n</code></pre>","tags":["Scraper","Resource Discovery","PaaS","Web","API"]},{"location":"scraping/providers/application-gateway/","title":"Azure Application Gateway","text":"<p>You can declare to scrape an Azure Application Gateway via the <code>ApplicationGateway</code> resource type.</p> <p>When using declared resources, the following fields need to be provided:</p> <ul> <li><code>applicationGatewayName</code> - The name of the Azure Application Gateway</li> </ul> <p>All supported metrics are documented in the official Azure Monitor documentation.</p>","tags":["Scraper","Resource Discovery","Networking"]},{"location":"scraping/providers/application-gateway/#example","title":"Example","text":"<p>Here is an example configuration:</p> <pre><code>name: azure_application_gateway_milli_total_time\ndescription: \"Average milliseconds of total time on an Azure application gateway\"\nresourceType: ApplicationGateway\nazureMetricConfiguration:\n  metricName: ApplicationGatewayTotalTime\n  aggregation:\n    type: Average\nresources: # Optional, required when no resource discovery is configured\n- applicationGatewayName: promitor-application-gateway-1\n- applicationGatewayName: promitor-application-gateway-2\nresourceDiscoveryGroups: # Optional, requires Promitor Resource Discovery agent (https://docs.promitor.io/latest/how-it-works#using-resource-discovery)\n- name: application-gateway-landscape\n</code></pre>","tags":["Scraper","Resource Discovery","Networking"]},{"location":"scraping/providers/application-insights/","title":"Azure Application Insights","text":"<p>You can declare to scrape an Azure Application Insights via the <code>ApplicationInsights</code> resource type.</p> <p>When using declared resources, the following fields need to be provided:</p> <ul> <li><code>name</code> - The name of the Azure Application Insights</li> </ul> <p>All supported metrics are documented in the official Azure Monitor documentation.</p>","tags":["Scraper","Resource Discovery","Monitoring"]},{"location":"scraping/providers/application-insights/#example","title":"Example","text":"<p>Here is an example configuration:</p> <pre><code>name: azure_application_insights_exceptions\ndescription: \"Average amount of server exceptions in Azure Application Insights\"\nresourceType: ApplicationInsights\nazureMetricConfiguration:\n  metricName: exceptions/server\n  aggregation:\n    type: Average\nresources: # Optional, required when no resource discovery is configured\n- name: promitor-application-gateway-1\n- name: promitor-application-gateway-2\nresourceDiscoveryGroups: # Optional, requires Promitor Resource Discovery agent (https://docs.promitor.io/latest/how-it-works#using-resource-discovery)\n- name: application-insights-landscape\n</code></pre>","tags":["Scraper","Resource Discovery","Monitoring"]},{"location":"scraping/providers/automation-account/","title":"Azure Automation account","text":"<p>You can scrape an Azure Automation account via the <code>AutomationAccount</code>  resource type.</p> <p>When using declared resources, the following fields need to be provided:</p> <ul> <li><code>accountName</code> - The name of the Azure Automation account.</li> <li><code>runbookName</code> - The name of the runbook. (optional and only supported on limited metrics)</li> </ul> <p>All supported metrics are documented in the official Azure Monitor documentation.</p> <p>The following scraper-specific metric label will be added :</p> <ul> <li><code>runbook_name</code> - Name of the runbook</li> </ul>","tags":["Scraper","Resource Discovery","Automation"]},{"location":"scraping/providers/automation-account/#example","title":"Example","text":"<p>Here is an example configuration:</p> <pre><code>name: promitor_demo_automation_job_count\ndescription: \"Amount of jobs per Azure Automation account &amp; job\"\nresourceType: AutomationAccount\nazureMetricConfiguration:\n  metricName: TotalJob\n  aggregation:\n    type: Total\nresources: # Optional, required when no resource discovery is configured\n- resourceGroupName: promitor-sources\n  accountName: promitor-sandbox\n  runbookName: Example # Optional, currently only supported for 'TotalJob' metric\nresourceDiscoveryGroups: # Optional, requires Promitor Resource Discovery agent (https://docs.promitor.io/latest/how-it-works#using-resource-discovery)\n- name: automation-accounts\n</code></pre>","tags":["Scraper","Resource Discovery","Automation"]},{"location":"scraping/providers/azure-firewall/","title":"Azure Firewall","text":"<p>You can scrape an Azure Firewall via the <code>AzureFirewall</code>  resource type.</p> <p>When using declared resources, the following fields need to be provided:</p> <ul> <li><code>azureFirewallName</code> - The name of the Azure Firewall.</li> </ul> <p>All supported metrics are documented in the official Azure Monitor documentation.</p>","tags":["Scraper","Resource Discovery","Azure Firewall"]},{"location":"scraping/providers/azure-firewall/#example","title":"Example","text":"<p>Here is an example configuration:</p> <pre><code>name: azure_firewall_application_rule_hits\ndescription: number of times Application rules were hit \nresourceType: AzureFirewall\nazureMetricConfiguration:\n  metricName: ApplicationRuleHit\n  aggregation:\n    type: Count\n  dimension:\n    name: Status\nresourceDiscoveryGroups:\n  - name: azure-firewalls\n</code></pre>","tags":["Scraper","Resource Discovery","Azure Firewall"]},{"location":"scraping/providers/blob-storage/","title":"Azure Blob Storage","text":"<p>You can declare to scrape an Azure Queue via the <code>BlobStorage</code> resource type.</p> <p>The following fields need to be provided:</p> <ul> <li><code>accountName</code> - The name of the Azure Storage account</li> </ul> <p>All supported metrics are documented in the official Azure Monitor documentation.</p>","tags":["Scraper","Data","Storage"]},{"location":"scraping/providers/blob-storage/#example","title":"Example","text":"<p>Here is an example configuration:</p> <pre><code>name: azure_storage_blobs_capacity\ndescription: \"The average capacity used by blobs in the storage account\"\nresourceType: BlobStorage\nazureMetricConfiguration:\n  metricName: BlobCapacity\n  aggregation:\n    type: Average\nresources: # Optional, required when no resource discovery is configured\n- accountName: promitor-1\n- accountName: promitor-2\n</code></pre>","tags":["Scraper","Data","Storage"]},{"location":"scraping/providers/cdn/","title":"Azure Content Delivery Network (CDN)","text":"<p>You can declare to scrape an Azure CDN via the <code>Cdn</code> resource type.</p> <p>When using declared resources, the following fields need to be provided:</p> <ul> <li><code>cdnName</code> - The name of the Azure CDN resource</li> </ul> <p>All supported metrics are documented in the official Azure Monitor documentation.</p> <p>\ud83d\udea8 The availability of metrics depends on the SKU of the Azure CDN resource.</p>","tags":["Scraper","Resource Discovery"]},{"location":"scraping/providers/cdn/#example","title":"Example","text":"<p>Here is an example configuration:</p> <pre><code>name: azure_cdn_requests\ndescription: \"Amount of requests sent to Azure CDN\"\nresourceType: Cdn\nazureMetricConfiguration:\n  metricName: RequestCount\n  aggregation:\n    type: Total\nresources: # Optional, required when no resource discovery is configured\n- cdnName: promitor-cdn-1\n- cdnName: promitor-cdn-2\nresourceDiscoveryGroups: # Optional, requires Promitor Resource Discovery agent (https://docs.promitor.io/latest/how-it-works#using-resource-discovery)\n- name: cdn-landscape\n</code></pre>","tags":["Scraper","Resource Discovery"]},{"location":"scraping/providers/container-instances/","title":"Azure Container Instances","text":"<p>You can declare to scrape an Azure Container Instances via the <code>ContainerInstance</code> resource type.</p> <p>When using declared resources, the following fields need to be provided:</p> <ul> <li><code>containerGroup</code> - The name of the container group</li> </ul> <p>All supported metrics are documented in the official Azure Monitor documentation.</p>","tags":["Scraper","Resource Discovery","Containers"]},{"location":"scraping/providers/container-instances/#example","title":"Example","text":"<p>Here is an example configuration:</p> <pre><code>name: azure_container_instance_cpu_usage\ndescription: \"Average cpu usage of our 'promitor-container-instance' container instance\"\nresourceType: ContainerInstance\nazureMetricConfiguration:\n  metricName: CpuUsage\n  aggregation:\n    type: Average\nresources: # Optional, required when no resource discovery is configured\n- containerGroup: promitor-container-instance-1\n- containerGroup: promitor-container-instance-2\nresourceDiscoveryGroups: # Optional, requires Promitor Resource Discovery agent (https://docs.promitor.io/latest/how-it-works#using-resource-discovery)\n- name: container-instances-landscape\n</code></pre>","tags":["Scraper","Resource Discovery","Containers"]},{"location":"scraping/providers/container-registry/","title":"Azure Container Registry","text":"<p>You can declare to scrape an Azure Container Registry via the <code>ContainerRegistry</code> resource type.</p> <p>When using declared resources, the following fields need to be provided:</p> <ul> <li><code>registryName</code> - The name of the registry</li> </ul> <p>All supported metrics are documented in the official Azure Monitor documentation.</p>","tags":["Scraper","Resource Discovery","Containers"]},{"location":"scraping/providers/container-registry/#example","title":"Example","text":"<p>Here is an example configuration:</p> <pre><code>name: azure_container_registry_total_pull_count\ndescription: \"Amount of images that were pulled from the container registry\"\nresourceType: ContainerRegistry\nazureMetricConfiguration:\n  metricName: TotalPullCount\n  aggregation:\n    type: Average\nresources: # Optional, required when no resource discovery is configured\n- registryName: promitor-1\n- registryName: promitor-2\nresourceDiscoveryGroups: # Optional, requires Promitor Resource Discovery agent (https://docs.promitor.io/latest/how-it-works#using-resource-discovery)\n- name: container-registry-landscape\n</code></pre>","tags":["Scraper","Resource Discovery","Containers"]},{"location":"scraping/providers/cosmos-db/","title":"Azure Cosmos DB","text":"<p>You can declare to scrape Cosmos Db via the <code>CosmosDb</code> resource type.</p> <p>When using declared resources, the following fields need to be provided:</p> <ul> <li><code>dbName</code>- The name of the Cosmos Db to be scraped</li> </ul> <p>All supported metrics are documented in the official Azure Monitor documentation.</p>","tags":["Scraper","Resource Discovery","SQL","Data","Open Source"]},{"location":"scraping/providers/cosmos-db/#example","title":"Example","text":"<p>Here is an example configuration:</p> <pre><code>name: azure_cosmos_db_total_requests\ndescription: \"Demo cosmos query\"\nresourceType: CosmosDb\nazureMetricConfiguration:\n  metricName: TotalRequests\n  aggregation:\n    type: Count\nresources: # Optional, required when no resource discovery is configured\n- dbName: cosmos-database-1\n- dbName: cosmos-database-2\nresourceDiscoveryGroups: # Optional, requires Promitor Resource Discovery agent (https://docs.promitor.io/latest/how-it-works#using-resource-discovery)\n- name: cosmos-db-landscape\n</code></pre>","tags":["Scraper","Resource Discovery","SQL","Data","Open Source"]},{"location":"scraping/providers/data-explorer-clusters/","title":"Azure Data Explorer Clusters","text":"<p>You can declare to scrape an Azure Data Explorer Cluster via the <code>DataExplorerCluster</code> resource type.</p> <p>When using declared resources, the following fields need to be provided:</p> <ul> <li><code>clusterName</code> - The name of the Azure Data Explorer Cluster</li> </ul> <p>All supported metrics are documented in the official Azure Monitor documentation.</p>","tags":["Scraper","Resource Discovery","Data"]},{"location":"scraping/providers/data-explorer-clusters/#example","title":"Example","text":"<p>Here is an example configuration:</p> <pre><code>name: azure_data_explorer_cluster\ndescription: \"CPU usage of Azure Data Explorer cluster\"\nresourceType: DataExplorerCluster\nazureMetricConfiguration:\n  metricName: CPU\n  aggregation:\n    type: Average\nresources: # Optional, required when no resource discovery is configured\n- clusterName: promitor-data-explorer-cluster-1\n- clusterName: promitor-data-explorer-cluster-2\nresourceDiscoveryGroups: # Optional, requires Promitor Resource Discovery agent (https://docs.promitor.io/latest/how-it-works#using-resource-discovery)\n- name: data-explorer-cluster-landscape\n</code></pre>","tags":["Scraper","Resource Discovery","Data"]},{"location":"scraping/providers/data-factory/","title":"Azure Data Factory","text":"<p>You can declare to scrape an Azure Data Factory resource via the <code>DataFactory</code> resource type.</p> <p>When using declared resources, the following fields need to be provided:</p> <ul> <li><code>factoryName</code> - The name of the Azure Data Factory resource</li> <li><code>pipelineName</code> - The name of the data pipeline (optional)</li> </ul> <p>All supported metrics are documented in the official Azure Monitor documentation.</p> <p>The following scraper-specific metric label will be added:</p> <ul> <li><code>pipeline_name</code> - Name of the data pipeline.</li> </ul>","tags":["Scraper","Resource Discovery","Data","Integration","PaaS"]},{"location":"scraping/providers/data-factory/#example","title":"Example","text":"<p>Here is an example configuration:</p> <pre><code>- name: azure_data_factory_pipeline_run_successful\n  description: \"Amount of successful runs for 'data-pipeline-example' pipline in Azure Data Factory\"\n  resourceType: DataFactory\n  azureMetricConfiguration:\n    metricName: PipelineSucceededRuns\n    aggregation:\n      type: Total\n  resources: # Optional, required when no resource discovery is configured\n  - factoryName: promitor-data-factory\n    pipelineName: data-pipeline-example\n  resourceDiscoveryGroups: # Optional, requires Promitor Resource Discovery agent (https://docs.promitor.io/latest/how-it-works#using-resource-discovery)\n  - name: data-factory-landscape\n</code></pre>","tags":["Scraper","Resource Discovery","Data","Integration","PaaS"]},{"location":"scraping/providers/data-share/","title":"Azure Data Share","text":"<p>You can declare to scrape an Azure Data Share resource via the <code>DataShare</code> resource type.</p> <p>When using declared resources, the following fields need to be provided:</p> <ul> <li><code>accountName</code> - The name of the Azure Data Share account</li> <li><code>shareName</code> - The name of the share (optional)</li> </ul> <p>All supported metrics are documented in the official Azure Monitor documentation.</p> <p>The following scraper-specific metric label will be added:</p> <ul> <li><code>share_name</code> - Name of the share.</li> </ul>","tags":["Scraper","Resource Discovery","Data"]},{"location":"scraping/providers/data-share/#example","title":"Example","text":"<p>Here is an example configuration:</p> <pre><code>- name: promitor_demo_data_share_received\n  description: \"Amount of shares received from other parties per Azure Data Share account\"\n  resourceType: DataShare\n  azureMetricConfiguration:\n    metricName: ShareSubscriptionCount\n    aggregation:\n      type: Maximum\n  resources: # Optional, required when no resource discovery is configured\n  - accountName: promitor-data-share\n    shareName: Promitor\n  resourceDiscoveryGroups: # Optional, requires Promitor Resource Discovery agent (https://docs.promitor.io/latest/how-it-works#using-resource-discovery)\n  - name: data-share-landscape\n</code></pre>","tags":["Scraper","Resource Discovery","Data"]},{"location":"scraping/providers/event-hubs/","title":"Azure Event Hubs","text":"<p>You can declare to scrape an Azure Event Hubs Queue via the <code>EventHubs</code> resource type.</p> <p>When using declared resources, the following fields need to be provided:</p> <ul> <li><code>namespace</code> - The name of the Azure Event Hubs namespace.</li> <li><code>topicName</code> - The name of the topic. (optional)</li> </ul> <p>All supported metrics are documented in the official Azure Monitor documentation.</p> <p>The following scraper-specific metric label will be added:</p> <ul> <li><code>entity_name</code> - Name of the topic</li> </ul>","tags":["Scraper","Resource Discovery","Messaging","Open Source"]},{"location":"scraping/providers/event-hubs/#limitations","title":"Limitations","text":"<ul> <li>As of today, it is not supported to combine <code>topicName</code> with <code>EntityPath</code> as a dimension.</li> </ul>","tags":["Scraper","Resource Discovery","Messaging","Open Source"]},{"location":"scraping/providers/event-hubs/#example","title":"Example","text":"<p>Here is an example configuration:</p> <pre><code>name: azure_event_hubs_incoming_messages\ndescription: \"The number of incoming messages on an Azure Event Hubs topic\"\nresourceType: EventHubs\nazureMetricConfiguration:\n  metricName: IncomingMessages\n  aggregation:\n    type: Total\nresources: # Optional, required when no resource discovery is configured\n- namespace: promitor-streaming\n  topicName: orders\n- namespace: promitor-messaging\n  topicName: sales\nresourceDiscoveryGroups: # Optional, requires Promitor Resource Discovery agent (https://docs.promitor.io/latest/how-it-works#using-resource-discovery)\n- name: event-hubs-landscape\n</code></pre>","tags":["Scraper","Resource Discovery","Messaging","Open Source"]},{"location":"scraping/providers/express-route-circuit/","title":"Azure Express Route Circuit","text":"<p>You can declare to scrape an Azure Express Route Circuit (without Peerings) via the <code>ExpressRouteCircuit</code> resource type.</p> <p>When using declared resources, the following fields need to be provided:</p> <ul> <li><code>expressRouteCircuitName</code> - The name of the Azure Express Route circuit</li> </ul> <p>All supported metrics are documented in the official Azure Monitor documentation.</p>","tags":["Scraper","Resource Discovery","Networking"]},{"location":"scraping/providers/express-route-circuit/#example","title":"Example","text":"<p>Here is an example configuration:</p> <pre><code>name: azure_express_route_percentage_arp_availability\ndescription: \"Average percentage of arp availability on an Azure express route circuit\"\nresourceType: ExpressRouteCircuit\nazureMetricConfiguration:\n  metricName: ArpAvailability\n  aggregation:\n    type: Average\nresources: # Optional, required when no resource discovery is configured\n- expressRouteCircuitName: promitor-express-route-circuit-1\n- expressRouteCircuitName: promitor-express-route-circuit-2\nresourceDiscoveryGroups: # Optional, requires Promitor Resource Discovery agent (https://docs.promitor.io/latest/how-it-works#using-resource-discovery)\n- name: express-route-circuit-landscape\n</code></pre>","tags":["Scraper","Resource Discovery","Networking"]},{"location":"scraping/providers/file-storage/","title":"Azure File Storage","text":"<p>You can declare to scrape an Azure Queue via the <code>FileStorage</code> resource type.</p> <p>The following fields need to be provided:</p> <ul> <li><code>accountName</code> - The name of the Azure Storage account</li> </ul> <p>All supported metrics are documented in the official Azure Monitor documentation.</p>","tags":["Scraper","Resource Discovery","Data","Storage"]},{"location":"scraping/providers/file-storage/#example","title":"Example","text":"<p>Here is an example configuration:</p> <pre><code>name: azure_storage_files_capacity\ndescription: \"The average capacity used by files in the storage account\"\nresourceType: FileStorage\nazureMetricConfiguration:\n  metricName: FileCapacity\n  aggregation:\n    type: Average\nresources: # Optional, required when no resource discovery is configured\n- accountName: promitor-1\n- accountName: promitor-2\n</code></pre>","tags":["Scraper","Resource Discovery","Data","Storage"]},{"location":"scraping/providers/front-door/","title":"Azure Front Door","text":"<p>You can declare to scrape an Azure Front Door via the <code>FrontDoor</code> resource type.</p> <p>When using declared resources, the following fields need to be provided:</p> <ul> <li><code>name</code> - The name of the Azure Front Door</li> </ul> <p>All supported metrics are documented in the official Azure Monitor documentation.</p>","tags":["Scraper","Resource Discovery","Networking"]},{"location":"scraping/providers/front-door/#example","title":"Example","text":"<p>Here is an example configuration:</p> <pre><code>name: promitor_demo_frontdoor_backend_health\ndescription: \"Health percentage for backends in Azure Front Door\"\nresourceType: FrontDoor\nazureMetricConfiguration:\n  metricName: BackendHealthPercentage\n  aggregation:\n    type: Average\nresources: # Optional, required when no resource discovery is configured\n- name: promitor-landscape\nresourceDiscoveryGroups: # Optional, requires Promitor Resource Discovery agent (https://docs.promitor.io/latest/how-it-works#using-resource-discovery)\n- name: front-door-landscape\n</code></pre>","tags":["Scraper","Resource Discovery","Networking"]},{"location":"scraping/providers/function-app/","title":"Azure Function App","text":"<p>You can declare to scrape an Azure Function App via the <code>FunctionApp</code> resource type.</p> <p>When using declared resources, the following fields need to be provided:</p> <ul> <li><code>functionAppName</code> - The name of the Azure Function App</li> <li><code>slotName</code> - The name of the deployment slot (optional)</li> </ul> <p>All supported metrics are documented in the official Azure Monitor documentation:</p> <ul> <li>Microsoft.Web/sites</li> <li>Microsoft.Web/sites/slots</li> </ul> <p>The following scraper-specific metric label will be added:</p> <ul> <li><code>slot_name</code> - Name of the deployment slot. If none is specified, <code>production</code> will be used.</li> </ul>","tags":["Scraper","Resource Discovery","Serverless","PaaS"]},{"location":"scraping/providers/function-app/#example","title":"Example","text":"<p>Here is an example configuration:</p> <pre><code>name: azure_function_requests\ndescription: \"Amount of requests for an Azure Function App\"\nresourceType: FunctionApp\nazureMetricConfiguration:\n  metricName: Requests\n  aggregation:\n    type: Total\nresources: # Optional, required when no resource discovery is configured\n- functionAppName: promitor-function-app\nresourceDiscoveryGroups: # Optional, requires Promitor Resource Discovery agent (https://docs.promitor.io/latest/how-it-works#using-resource-discovery)\n- name: function-app-landscape\n</code></pre>","tags":["Scraper","Resource Discovery","Serverless","PaaS"]},{"location":"scraping/providers/generic-azure-resource/","title":"Generic Azure Resource","text":"<p>You can declare to scrape a generic Azure resource via the <code>Generic</code> resource type.</p> <p>Promitor simplifies defining resource URIs by using the subscription &amp; resource group defined in <code>azureMetadata</code> so that your configuration is small &amp; readable.</p> <p>Mandatory fields :</p> <ul> <li><code>resourceUri</code> - The uri of the Azure resource to scrape.</li> </ul> <p>Optional fields :</p> <ul> <li><code>resourceGroupName</code> - the resource group for this resource. It overrides the one defined in <code>azureMetadata</code>.</li> <li><code>subscriptionId</code> - the subscription ID for this resource. It overrides the one defined in <code>azureMetadata</code>.</li> <li><code>filter</code> - The filter to use to have fine-grained metrics. Example: <code>EntityName eq 'orders'</code>.    See Azure Monitor REST API Filter Syntax.</li> </ul>","tags":["Scraper"]},{"location":"scraping/providers/generic-azure-resource/#example","title":"Example","text":"<p>Here is an example configuration:</p> <pre><code>name: azure_service_bus_active_messages\ndescription: \"Amount of active messages of the 'myqueue' queue (determined with Generic provider)\"\nresourceType: Generic\nazureMetricConfiguration:\n  metricName: ActiveMessages\n  aggregation:\n    type: Total\nresources:\n# Will scrape subscriptions/&lt;sub&gt;/resourceGroups/&lt;rg&gt;/providers/Microsoft.ServiceBus/namespaces/my-promitor-messaging\n# Where &lt;sub&gt; &amp; &lt;rg&gt; are coming from azureMetadata\n- resourceUri: Microsoft.ServiceBus/namespaces/my-promitor-messaging\n  filter: EntityName eq 'orders'\n# Will scrape subscriptions/&lt;sub&gt;/resourceGroups/&lt;rg&gt;/providers/Microsoft.ServiceBus/namespaces/my-other-promitor-messaging\n# Where &lt;sub&gt; &amp; &lt;rg&gt; are coming from the definition of this resource.\n- resourceUri: Microsoft.ServiceBus/namespaces/my-other-promitor-messaging\n  subscriptionId: example-subscription\n  resourceGroupName: example-resource-group\n</code></pre>","tags":["Scraper"]},{"location":"scraping/providers/iot-hub-device-provisioning-service/","title":"Azure IoT Hub Device Provisioning Service (DPS)","text":"<p>You can declare to scrape an Azure IoT Hub Device Provisioning Service (DPS) via the <code>DeviceProvisioningService</code> resource type.</p> <p>When using declared resources, the following fields need to be provided:</p> <ul> <li><code>deviceProvisioningServiceName</code> - The name of the Azure IoT Hub Device Provisioning Service (DPS)</li> </ul> <p>All supported metrics are documented in the official Azure Monitor documentation.</p>","tags":["Scraper","Resource Discovery","IoT","PaaS"]},{"location":"scraping/providers/iot-hub-device-provisioning-service/#example","title":"Example","text":"<p>Here is an example configuration:</p> <pre><code>name: azure_dps_attestation_attempts\ndescription: \"The number of device attestations attempted\"\nresourceType: DeviceProvisioningService\nazureMetricConfiguration:\n  metricName: AttestationAttempts\n  aggregation:\n    type: Total\nresources: # Optional, required when no resource discovery is configured\n- deviceProvisioningServiceName: promitor-1\n- deviceProvisioningServiceName: promitor-2\nresourceDiscoveryGroups: # Optional, requires Promitor Resource Discovery agent (https://docs.promitor.io/latest/how-it-works#using-resource-discovery)\n- name: iot-hub-dps-landscape\n</code></pre>","tags":["Scraper","Resource Discovery","IoT","PaaS"]},{"location":"scraping/providers/iot-hub/","title":"Azure IoT Hub","text":"<p>You can declare to scrape an Azure IoT Hub via the <code>IoTHub</code> resource type.</p> <p>When using declared resources, the following fields need to be provided:</p> <ul> <li><code>ioTHubName</code> - The name of the Azure IoT Hub</li> </ul> <p>All supported metrics are documented in the official Azure Monitor documentation.</p>","tags":["Scraper","Resource Discovery","IoT","PaaS"]},{"location":"scraping/providers/iot-hub/#example","title":"Example","text":"<p>Here is an example configuration:</p> <pre><code>name: azure_iot_hub_total_devices\ndescription: \"The number of devices registered to your IoT hub\"\nresourceType: IoTHub\nazureMetricConfiguration:\n  metricName: devices.totalDevices\n  aggregation:\n    type: Total\nresources: # Optional, required when no resource discovery is configured\n- ioTHubName: promitor-1\n- ioTHubName: promitor-2\nresourceDiscoveryGroups: # Optional, requires Promitor Resource Discovery agent (https://docs.promitor.io/latest/how-it-works#using-resource-discovery)\n- name: iot-hub-landscape\n</code></pre>","tags":["Scraper","Resource Discovery","IoT","PaaS"]},{"location":"scraping/providers/key-vault/","title":"Azure Key Vault","text":"<p>You can declare to scrape an Azure Key Vault via the <code>KeyVault</code> resource type.</p> <p>When using declared resources, the following fields need to be provided:</p> <ul> <li><code>vaultName</code> - The name of the Azure Key Vault</li> </ul> <p>All supported metrics are documented in the official Azure Monitor documentation.</p>","tags":["Scraper","Resource Discovery","Security"]},{"location":"scraping/providers/key-vault/#example","title":"Example","text":"<p>Here is an example configuration:</p> <pre><code>name: azure_key_vault_api_latency\ndescription: \"The overall latency of service api requests\"\nresourceType: KeyVault\nazureMetricConfiguration:\n  metricName: ServiceApiLatency\n  aggregation:\n    type: Average\nresources: # Optional, required when no resource discovery is configured\n- vaultName: promitor-1\n- vaultName: promitor-2\nresourceDiscoveryGroups: # Optional, requires Promitor Resource Discovery agent (https://docs.promitor.io/latest/how-it-works#using-resource-discovery)\n- name: key-vault-landscape\n</code></pre>","tags":["Scraper","Resource Discovery","Security"]},{"location":"scraping/providers/kubernetes/","title":"Azure Kubernetes Service","text":"<p>You can declare to scrape an Azure Kubernetes Service (AKS) via the <code>KubernetesService</code> resource type.</p> <p>When using declared resources, the following fields need to be provided:</p> <ul> <li><code>clusterName</code> - The name of the Azure Kubernetes Service</li> </ul> <p>All supported metrics are documented in the official Azure Monitor documentation.</p>","tags":["Scraper","Resource Discovery","Containers","Kubernetes","Open Source"]},{"location":"scraping/providers/kubernetes/#example","title":"Example","text":"<p>Here is an example configuration:</p> <pre><code>name: azure_kubernetes_available_cpu_cores\ndescription: \"Available CPU cores in cluster\"\nresourceType: KubernetesService\nazureMetricConfiguration:\n  metricName: kube_node_status_allocatable_cpu_cores\n  aggregation:\n    type: Average\nresources: # Optional, required when no resource discovery is configured\n- clusterName: promitor-aks\nresourceDiscoveryGroups: # Optional, requires Promitor Resource Discovery agent (https://docs.promitor.io/latest/how-it-works#using-resource-discovery)\n- name: kubernetes-service-landscape\n</code></pre>","tags":["Scraper","Resource Discovery","Containers","Kubernetes","Open Source"]},{"location":"scraping/providers/load-balancer/","title":"Azure Load Balancer","text":"<p>You can declare to scrape an Azure Load Balancer via the <code>LoadBalancer</code> resource type.</p> <p>When using declared resources, the following fields need to be provided:</p> <ul> <li><code>loadBalancerName</code> - The name of the Azure Load Balancer resource</li> </ul> <p>All supported metrics are documented in the official Azure Monitor documentation.</p>","tags":["Scraper","Resource Discovery","Networking"]},{"location":"scraping/providers/load-balancer/#example","title":"Example","text":"<p>Here is an example configuration:</p> <pre><code>name: azure_load_balancer_traffic_bytes\ndescription: \"Average amount of bytes sent through an Azure Load Balancer\"\nresourceType: LoadBalancer\nazureMetricConfiguration:\n  metricName: ByteCount\n  aggregation:\n    type: Average\nresources: # Optional, required when no resource discovery is configured\n- loadBalancerName: promitor-load-balancer-1\n- loadBalancerName: promitor-load-balancer-2\nresourceDiscoveryGroups: # Optional, requires Promitor Resource Discovery agent (https://docs.promitor.io/latest/how-it-works#using-resource-discovery)\n- name: load-balancer-landscape\n</code></pre>","tags":["Scraper","Resource Discovery","Networking"]},{"location":"scraping/providers/log-analytics/","title":"Azure Log Analytics","text":"<p>You can declare to scrape an Azure Log Analytics via the <code>LogAnalytics</code> resource type.</p> <p>The following fields need to be provided:</p> <ul> <li><code>workspaceName</code> - The name of the Azure Log Analytics</li> <li><code>workspaceId</code> - The workspace ID of the Azure Log Analytics resource</li> </ul> <p>The Azure Log Analytics scraper is configured differently compare to others Azure resources. Ensure that <code>logAnalyticsConfiguration</code> is configured instead of <code>azureMetricConfiguration</code>:</p> <ul> <li><code>logAnalyticsConfiguration.query</code> - The query used to query value from logAnalytics<ul> <li>the result of the query need to be 1 row only (use <code>take 1</code>)</li> <li>the result of the query need to have 1 column named 'result' only (use <code>project result</code>)</li> </ul> </li> <li><code>logAnalyticsConfiguration.aggregation.interval</code> - The aggregation that needs to be   used when querying Log Analytics. If you don't set this, it will get the value from metricDefaults</li> </ul>","tags":["Scraper","Data"]},{"location":"scraping/providers/log-analytics/#example","title":"Example","text":"<p>Here is an example configuration:</p> <pre><code>name: azure_logs_analytics\ndescription: \"Get number of error from SparkLoggingEvent\"\nresourceType: LogAnalytics \nlogAnalyticsConfiguration:\n  query: SparkLoggingEvent_CL | where Level == \"ERROR\" | summarize result = count() | take 1 | project result\n  aggregation:\n    interval: 10:00:00:00\nresources:\n  - workspaceId: 0202fe93-55de-4c08-ae83-b5e4a3b6bed6\n    workspaceName: afs-log-analytics\n</code></pre>","tags":["Scraper","Data"]},{"location":"scraping/providers/logic-apps/","title":"Azure Logic Apps","text":"<p>You can declare to scrape an Azure Logic App via the <code>LogicApp</code> resource type.</p> <p>When using declared resources, the following fields need to be provided:</p> <ul> <li><code>workflowName</code> - The name of the Azure Logic App</li> </ul> <p>All supported metrics are documented in the official Azure Monitor documentation.</p>","tags":["Scraper","Resource Discovery","Integration","PaaS"]},{"location":"scraping/providers/logic-apps/#example","title":"Example","text":"<p>Here is an example configuration:</p> <pre><code>name: azure_logic_apps_failed_run\ndescription: \"Total amount of failed runs for Azure Logic Apps\"\nresourceType: LogicApp\nazureMetricConfiguration:\n  metricName: RunsFailed\n  aggregation:\n    type: Total\nresources: # Optional, required when no resource discovery is configured\n- workflowName: promitor-workflow-1\n- workflowName: promitor-workflow-2\nresourceDiscoveryGroups: # Optional, requires Promitor Resource Discovery agent (https://docs.promitor.io/latest/how-it-works#using-resource-discovery)\n- name: logic-apps-landscape\n</code></pre>","tags":["Scraper","Resource Discovery","Integration","PaaS"]},{"location":"scraping/providers/maria-db/","title":"Azure Database for MariaDB","text":"<p>You can declare to scrape an Azure Database for MariaDB via the <code>MariaDb</code> resource type.</p> <p>When using declared resources, the following fields need to be provided:</p> <ul> <li><code>serverName</code> - The name of the Azure Database for MariaDB server</li> </ul> <p>All supported metrics are documented in the official Azure Monitor documentation.</p>","tags":["Scraper","Resource Discovery","Data","Open Source"]},{"location":"scraping/providers/maria-db/#example","title":"Example","text":"<p>Here is an example configuration:</p> <pre><code>name: azure_db_mariadb_percentage_cpu\ndescription: \"Average percentage cpu usage on an Azure Database for MariaDB\"\nresourceType: MariaDb\nazureMetricConfiguration:\n  metricName: cpu_percent\n  aggregation:\n    type: Average\nresources: # Optional, required when no resource discovery is configured\n- serverName: promitor-maria-db-1\n- serverName: promitor-maria-db-2\nresourceDiscoveryGroups: # Optional, requires Promitor Resource Discovery agent (https://docs.promitor.io/latest/how-it-works#using-resource-discovery)\n- name: maria-db-landscape\n</code></pre>","tags":["Scraper","Resource Discovery","Data","Open Source"]},{"location":"scraping/providers/monitor-autoscale/","title":"Azure Monitor Autoscale","text":"<p>You can declare to scrape an Azure Monitor Autoscale via the <code>MonitorAutoscale</code> resource type.</p> <p>When using declared resources, the following fields need to be provided:</p> <ul> <li><code>autoscaleSettingsName</code> - The name of the Azure Monitor Autoscale settings</li> </ul> <p>All supported metrics are documented in the official Azure Monitor documentation.</p>","tags":["Scraper","Resource Discovery","Monitoring"]},{"location":"scraping/providers/monitor-autoscale/#example","title":"Example","text":"<p>Here is an example configuration:</p> <pre><code>- name: promitor_demo_appplan_autoscale_observed_capacity\n  description: \"Average amount of current instances for an Azure App Plan with Azure Monitor Autoscale\"\n  resourceType: MonitorAutoscale\n  labels:\n    app: promitor\n  azureMetricConfiguration:\n    metricName: ObservedCapacity\n    aggregation:\n      type: Average\n  resources: # Optional, required when no resource discovery is configured\n  - autoscaleSettingsName: app-service-autoscaling-rules\n  resourceDiscoveryGroups: # Optional, requires Promitor Resource Discovery agent (https://docs.promitor.io/latest/how-it-works#using-resource-discovery)\n  - name: autoscaling-rules\n</code></pre>","tags":["Scraper","Resource Discovery","Monitoring"]},{"location":"scraping/providers/mysql/","title":"Azure Database for MySQL","text":"<p>You can declare to scrape an Azure Database for MySQL server via the <code>MySql</code> resource type.</p> <p>When using declared resources, the following fields need to be provided:</p> <ul> <li><code>serverName</code> - The name of the MySQL server</li> <li><code>type</code> - The type of MySQL server. (optional)</li> <li>Allowed values are <code>Simple</code> (default) &amp; <code>Flexible</code></li> </ul> <p>All supported metrics are documented in the official Azure Monitor documentation:</p> <ul> <li>Simple servers</li> <li>Flexible servers</li> </ul>","tags":["Scraper","Resource Discovery","SQL","Data","Open Source"]},{"location":"scraping/providers/mysql/#limitations","title":"Limitations","text":"<ul> <li>Resource discovery will discover all types of servers and thus the used metrics should match all of the types.</li> <li>You can use tags to define which resources to include, if you need filtering capabilities.</li> </ul>","tags":["Scraper","Resource Discovery","SQL","Data","Open Source"]},{"location":"scraping/providers/mysql/#example","title":"Example","text":"<p>Here is an example configuration:</p> <pre><code>name: azure_my_sql_cpu_percent\ndescription: \"The CPU percentage on the server\"\nresourceType: MySql\nscraping:\n  schedule: \"0 */2 * ? * *\"\nazureMetricConfiguration:\n  metricName: cpu_percent\n  aggregation:\n    type: Average\n    interval: 00:01:00\nresources: # Optional, required when no resource discovery is configured\n- serverName: Promitor-1\n- serverName: Promitor-2\n  type: Flexible\nresourceDiscoveryGroups: # Optional, requires Promitor Resource Discovery agent (https://docs.promitor.io/latest/how-it-works#using-resource-discovery)\n- name: mysql-database-landscape\n</code></pre>","tags":["Scraper","Resource Discovery","SQL","Data","Open Source"]},{"location":"scraping/providers/nat-gateway/","title":"Azure NAT Gateways","text":"<p>You can declare to scrape an Azure NAT Gateway via the <code>NatGateway</code> resource type.</p> <p>When using declared resources, the following fields need to be provided:</p> <ul> <li><code>natGatewayName</code> - The name of the Azure NAT Gateway</li> </ul> <p>All supported metrics are documented in the official Azure Monitor documentation.</p>","tags":["Scraper","Resource Discovery","Networking"]},{"location":"scraping/providers/nat-gateway/#example","title":"Example","text":"<p>Here is an example configuration:</p> <pre><code>name: azure_nat_gateway_datapath_availability\ndescription: \"DatapathAvailability usage of Azure nat gateway\"\nresourceType: NatGateway\nazureMetricConfiguration:\n  metricName: DatapathAvailability\n  aggregation:\n    type: Average\nresources: # Optional, required when no resource discovery is configured\n- natGatewayName: promitor-nat-gateway-1\n- natGatewayName: promitor-nat-gateway-2\nresourceDiscoveryGroups: # Optional, requires Promitor Resource Discovery agent (https://docs.promitor.io/latest/how-it-works#using-resource-discovery)\n- name: nat-gateways\n</code></pre>","tags":["Scraper","Resource Discovery","Networking"]},{"location":"scraping/providers/network-gateway/","title":"Azure Network Gateway","text":"<p>You can declare to scrape an Azure Network Gateway via the <code>NetworkGateway</code> resource type.</p> <p>When using declared resources, the following fields need to be provided:</p> <ul> <li><code>networkGatewayName</code> - The name of the Azure Network Gateway</li> </ul> <p>All supported metrics are documented in the official Azure Monitor documentation.</p>","tags":["Scraper","Resource Discovery","Networking"]},{"location":"scraping/providers/network-gateway/#example","title":"Example","text":"<p>Here is an example configuration:</p> <pre><code>name: azure_network_gateway_packages\ndescription: \"Average packages on an Azure network gateway\"\nresourceType: NetworkGateway\nazureMetricConfiguration:\n  metricName: ExpressRouteGatewayPacketsPerSecond\n  aggregation:\n    type: Average\nresources: # Optional, required when no resource discovery is configured\n- networkGatewayName: promitor-network-gateway-1\n- networkGatewayName: promitor-network-gateway-2\nresourceDiscoveryGroups: # Optional, requires Promitor Resource Discovery agent (https://docs.promitor.io/latest/how-it-works#using-resource-discovery)\n- name: network-gateway-landscape\n</code></pre>","tags":["Scraper","Resource Discovery","Networking"]},{"location":"scraping/providers/network-interface/","title":"Azure Network Interface","text":"<p>You can declare to scrape an Azure Network Interface via the <code>NetworkInterface</code> resource type.</p> <p>When using declared resources, the following fields need to be provided:</p> <ul> <li><code>networkInterfaceName</code> - The name of the network interface</li> </ul> <p>All supported metrics are documented in the official Azure Monitor documentation.</p>","tags":["Scraper","Resource Discovery","Networking"]},{"location":"scraping/providers/network-interface/#example","title":"Example","text":"<p>Here is an example configuration:</p> <pre><code>name: azure_network_interface_bytes_received_rate\ndescription: \"Number of bytes the Network Interface sent\"\nresourceType: NetworkInterface\nazureMetricConfiguration:\n  metricName: BytesReceivedRate\n  aggregation:\n    type: Average\nresources: # Optional, required when no resource discovery is configured\n- networkInterfaceName: promitor-network-interface-1\n- networkInterfaceName: promitor-network-interface-2\nresourceDiscoveryGroups: # Optional, requires Promitor Resource Discovery agent (https://docs.promitor.io/latest/how-it-works#using-resource-discovery)\n- name: network-interfaces-landscape\n</code></pre>","tags":["Scraper","Resource Discovery","Networking"]},{"location":"scraping/providers/postgresql/","title":"Azure Database for PostgreSQL","text":"<p>You can declare to scrape an Azure Database for PostgreSQL server via the <code>PostgreSql</code> resource type.</p> <p>When using declared resources, the following fields need to be provided:</p> <ul> <li><code>serverName</code> - The name of the PostgreSQL server</li> <li><code>type</code> - The type of PostgreSQL server. (optional)</li> <li>Allowed values are <code>Simple</code> (default), <code>Flexible</code> &amp; <code>Hyperscale</code>.</li> </ul> <p>All supported metrics are documented in the official Azure Monitor documentation:</p> <ul> <li>Simple servers</li> <li>Flexible servers</li> <li>Hyperscale servers</li> </ul>","tags":["Scraper","Resource Discovery","SQL","Data","Open Source"]},{"location":"scraping/providers/postgresql/#limitations","title":"Limitations","text":"<ul> <li>Resource discovery will discover all types of servers and thus the used metrics should match all of the types.</li> <li>You can use tags to define which resources to include, if you need filtering capabilities.</li> </ul>","tags":["Scraper","Resource Discovery","SQL","Data","Open Source"]},{"location":"scraping/providers/postgresql/#example","title":"Example","text":"<p>Here is an example configuration:</p> <pre><code>name: azure_postgre_sql_cpu_percent\ndescription: \"The CPU percentage on the server\"\nresourceType: PostgreSql\nscraping:\n  schedule: \"0 */2 * ? * *\"\nazureMetricConfiguration:\n  metricName: cpu_percent\n  aggregation:\n    type: Average\n    interval: 00:01:00\nresources: # Optional, required when no resource discovery is configured\n- serverName: Promitor-1\n- serverName: Promitor-2\n  type: Flexible\nresourceDiscoveryGroups: # Optional, requires Promitor Resource Discovery agent (https://docs.promitor.io/latest/how-it-works#using-resource-discovery)\n- name: postgres-database-landscape\n</code></pre>","tags":["Scraper","Resource Discovery","SQL","Data","Open Source"]},{"location":"scraping/providers/powerbi-dedicated/","title":"Azure PowerBI Dedicated","text":"<p>You can declare to scrape a Azure PowerBI Dedicated capacity via the <code>PowerBiDedicated</code> resource type.</p> <p>When using declared resources, the following fields need to be provided:</p> <ul> <li><code>capacityName</code> - The name of the PowerBI Dedicated capacity</li> </ul> <p>All supported metrics are documented in the official Azure Monitor documentation.</p>","tags":["Scraper","Resource Discovery","PowerBI","PowerBI Embedded"]},{"location":"scraping/providers/powerbi-dedicated/#example","title":"Example","text":"<p>Here is an example configuration:</p> <pre><code>  - name: azure_powerbi_dedicated_cpu_usage\n    description: percentage of cpu used by powerbi dedicated\n    resourceType: PowerBiDedicated\n    azureMetricConfiguration:\n        metricName: cpu_metric\n        aggregation:\n            type: Average\n    resourceDiscoveryGroups: # Optional, requires Promitor Resource Discovery agent (https://docs.promitor.io/latest/how-it-works#using-resource-discovery)\n        - name: powerbi-dedicated\n</code></pre>","tags":["Scraper","Resource Discovery","PowerBI","PowerBI Embedded"]},{"location":"scraping/providers/public-ip-address/","title":"Azure Public IP Address","text":"<p>You can declare to scrape a Public IP Address via the <code>PublicIpAddress</code> resource type.</p> <p>When using declared resources, the following fields need to be provided:</p> <ul> <li><code>publicIpAddressName</code> - The name of the Public IP Address.</li> </ul> <p>All supported metrics are documented in the official Azure Monitor documentation.</p>","tags":["Scraper","Resource Discovery","Networking"]},{"location":"scraping/providers/public-ip-address/#example","title":"Example","text":"<p>Here is an example configuration:</p> <pre><code>name: azure_public_ip_address_under_ddos_attack\ndescription: \"Public IP Address under DDoS attack or not\"\nresourceType: PublicIpAddress\nazureMetricConfiguration:\n  metricName: IfUnderDDoSAttack\n  aggregation:\n    type: Maximum\nresources: # Optional, required when no resource discovery is configured\n- publicIpAddressName: promitor-load-balancer-public-ip\n- publicIpAddressName: promitor-nat-gateway-public-ip\nresourceDiscoveryGroups: # Optional, requires Promitor Resource Discovery agent (https://docs.promitor.io/latest/how-it-works#using-resource-discovery)\n- name: public-ip-addresses\n</code></pre>","tags":["Scraper","Resource Discovery","Networking"]},{"location":"scraping/providers/redis-cache/","title":"Azure Cache for Redis","text":"<p>You can declare to scrape an Azure Cache for Redis via the <code>RedisCache</code> resource type.</p> <p>When using declared resources, the following fields need to be provided:</p> <ul> <li><code>cacheName</code> - The name of the Redis Cache instance</li> </ul> <p>All supported metrics are documented in the official Azure Monitor documentation.</p> <p>You can find more documentation on each metric in the Azure Cache for Redis monitoring documentation.</p>","tags":["Scraper","Resource Discovery","Data","Caching","Open Source"]},{"location":"scraping/providers/redis-cache/#example","title":"Example","text":"<p>Here is an example configuration:</p> <pre><code>name: azure_redis_cache_cache_hits\ndescription: \"The number of successful key lookups during the specified reporting interval. This maps to keyspace_hits from the Redis INFO command.\"\nresourceType: RedisCache\nscraping:\n  schedule: \"0 */2 * ? * *\"\nazureMetricConfiguration:\n  metricName: CacheHits\n  aggregation:\n    type: Total\n    interval: 00:01:00\nresources: # Optional, required when no resource discovery is configured\n- cacheName: Promitor-1\n- cacheName: Promitor-2\nresourceDiscoveryGroups: # Optional, requires Promitor Resource Discovery agent (https://docs.promitor.io/latest/how-it-works#using-resource-discovery)\n- name: redis-cache-landscape\n</code></pre>","tags":["Scraper","Resource Discovery","Data","Caching","Open Source"]},{"location":"scraping/providers/redis-enterprise-cache/","title":"Azure Cache for Redis Enterprise","text":"<p>You can declare to scrape an Azure Cache for Redis Enterprise via the <code>RedisEnterpriseCache</code> resource type.</p> <p>When using declared resources, the following fields need to be provided:</p> <ul> <li><code>cacheName</code> - The name of the Azure Cache for Redis Enterprise resource</li> </ul> <p>All supported metrics are documented in the official Azure Monitor documentation.</p>","tags":["Scraper","Resource Discovery","Data","Caching","Open Source"]},{"location":"scraping/providers/redis-enterprise-cache/#example","title":"Example","text":"<p>Here is an example configuration:</p> <pre><code>name: azure_cache_redis_enterprise_percentage_cpu\ndescription: \"Average percentage cpu usage on an Azure Cache for Redis Enterprise\"\nresourceType: RedisEnterpriseCache\nazureMetricConfiguration:\n  metricName: usedmemorypercentage\n  aggregation:\n    type: Average\nresources: # Optional, required when no resource discovery is configured\n- cacheName: promitor-redis-enterprise-cache-1\n- cacheName: promitor-redis-enterprise-cache-2\nresourceDiscoveryGroups: # Optional, requires Promitor Resource Discovery agent (https://docs.promitor.io/latest/how-it-works#using-resource-discovery)\n- name: redis-enterprise-cache-landscape\n</code></pre>","tags":["Scraper","Resource Discovery","Data","Caching","Open Source"]},{"location":"scraping/providers/service-bus-namespace/","title":"Azure Service Bus Namespace","text":"<p>You can declare to scrape an Azure Service Bus namespace via the <code>ServiceBusNamespace</code> resource type.</p> <p>When using declared resources, the following fields need to be provided:</p> <ul> <li><code>namespace</code> - The name of the Azure Service Bus namespace</li> <li><code>queueName</code> - The name of the queue (optional)</li> <li><code>topicName</code> - The name of the topic (optional)</li> </ul> <p>All supported metrics are documented in the official Azure Monitor documentation.</p> <p>The following scraper-specific metric label will be added:</p> <ul> <li><code>entity_name</code> - Name of the queue</li> </ul>","tags":["Scraper","Resource Discovery","Integration","Messaging"]},{"location":"scraping/providers/service-bus-namespace/#limitations","title":"Limitations","text":"<ul> <li>No support for <code>queueName</code> &amp; <code>topicName</code> for the same resource, for example:</li> </ul> <pre><code>resources:\n- namespace: promitor-messaging\n  queueName: orders\n  topicName: sales\n</code></pre> <ul> <li>No support for combining the <code>queueName</code> &amp; <code>EntityPath</code> dimensions</li> </ul>","tags":["Scraper","Resource Discovery","Integration","Messaging"]},{"location":"scraping/providers/service-bus-namespace/#example","title":"Example","text":"<p>Here is an example configuration:</p> <pre><code>name: azure_service_bus_queue_active_messages\ndescription: \"The number of active messages on a service bus queue\"\nresourceType: ServiceBusNamespace\nazureMetricConfiguration:\n  metricName: ActiveMessages\n  aggregation:\n    type: Total\nresources: # Optional, required when no resource discovery is configured\n- namespace: promitor-messaging\n  queueName: orders\n- namespace: promitor-messaging\n  queueName: items\nresourceDiscoveryGroups: # Optional, requires Promitor Resource Discovery agent (https://docs.promitor.io/latest/how-it-works#using-resource-discovery)\n- name: service-bus-landscape\n</code></pre>","tags":["Scraper","Resource Discovery","Integration","Messaging"]},{"location":"scraping/providers/sql-database/","title":"Azure SQL Database","text":"<p>You can scrape an Azure SQL Database via the <code>SqlDatabase</code> resource type.</p> <p>When using declared resources, the following fields need to be provided:</p> <ul> <li><code>serverName</code> - The name of the SQL Server instance.</li> <li><code>databaseName</code> - The name of the database.</li> </ul> <p>All supported metrics are documented in the official Azure Monitor documentation.</p> <p>The following scraper-specific metric labels will be added:</p> <ul> <li><code>server</code> - The name of the SQL Server instance.</li> <li><code>database</code> - The name of the database.</li> </ul>","tags":["Scraper","Resource Discovery","SQL","Data","PaaS"]},{"location":"scraping/providers/sql-database/#example","title":"Example","text":"<p>Here is an example configuration:</p> <pre><code>name: azure_sql_database_dtu_consumption_percent\ndescription: \"The DTU consumption percentage used by an Azure SQL Database.\"\nresourceType: SqlDatabase\nazureMetricConfiguration:\n  metricName: dtu_consumption_percent\n  aggregation:\n    type: Average\nresources: # Optional, required when no resource discovery is configured\n- serverName: promitor-sql-server\n  databaseName: promitor-db\nresourceDiscoveryGroups: # Optional, requires Promitor Resource Discovery agent (https://docs.promitor.io/latest/how-it-works#using-resource-discovery)\n- name: sql-database-landscape\n</code></pre>","tags":["Scraper","Resource Discovery","SQL","Data","PaaS"]},{"location":"scraping/providers/sql-elastic-pool/","title":"Azure SQL Elastic Pool","text":"<p>You can scrape an Azure SQL Elastic Pool via the <code>SqlElasticPool</code> resource type.</p> <p>When using declared resources, the following fields need to be provided:</p> <ul> <li><code>serverName</code> - The name of the SQL Server instance.</li> <li><code>poolName</code> - The name of the elastic pool.</li> </ul> <p>All supported metrics are documented in the official Azure Monitor documentation.</p> <p>The following scraper-specific metric labels will be added:</p> <ul> <li><code>server</code> - The name of the SQL Server instance.</li> <li><code>elastic_pool</code> - The name of the elastic pool.</li> </ul>","tags":["Scraper","Resource Discovery","SQL","Data","PaaS"]},{"location":"scraping/providers/sql-elastic-pool/#example","title":"Example","text":"<p>Here is an example configuration:</p> <pre><code>- name: promitor_demo_sql_elastic_pool_cpu\n  description: \"CPU percentage used for a Azure SQL Elastic Pool\"\n  resourceType: SqlElasticPool\n  labels:\n    app: promitor\n  azureMetricConfiguration:\n    metricName: cpu_percent\n    aggregation:\n      type: Average\n  resources: # Optional, required when no resource discovery is configured\n  - serverName: promitor-sql-server\n    poolName: promitor-db\n  resourceDiscoveryGroups: # Optional, requires Promitor Resource Discovery agent (https://docs.promitor.io/latest/how-it-works#using-resource-discovery)\n  - name: sql-elastic-pools\n</code></pre>","tags":["Scraper","Resource Discovery","SQL","Data","PaaS"]},{"location":"scraping/providers/sql-managed-instance/","title":"Azure SQL Managed Instance","text":"<p>You can scrape an Azure SQL Managed Instance via the <code>SqlManagedInstance</code>  resource type.</p> <p>When using declared resources, the following fields need to be provided:</p> <ul> <li><code>instanceName</code> - The name of the SQL Server instance.</li> </ul> <p>All supported metrics are documented in the official Azure Monitor documentation.</p>","tags":["Scraper","Resource Discovery","SQL","Data"]},{"location":"scraping/providers/sql-managed-instance/#example","title":"Example","text":"<p>Here is an example configuration:</p> <pre><code>name: promitor_demo_azuresqlmanagedinstance_nodes\ndescription: \"The amount of nodes for an Azure SQL Managed Instance.\"\nresourceType: SqlManagedInstance\nazureMetricConfiguration:\n  metricName: virtual_core_count\n  aggregation:\n    type: Average\nresources: # Optional, required when no resource discovery is configured\n- instanceName: promitor-sql-managed-instance\nresourceDiscoveryGroups: # Optional, requires Promitor Resource Discovery agent (https://docs.promitor.io/latest/how-it-works#using-resource-discovery)\n- name: sql-managed-instances-landscape\n</code></pre>","tags":["Scraper","Resource Discovery","SQL","Data"]},{"location":"scraping/providers/sql-server/","title":"Azure SQL Server","text":"<p>You can scrape an Azure SQL Server via the <code>SqlServer</code> resource type.</p> <p>The following fields need to be provided:</p> <ul> <li><code>serverName</code> - The name of the SQL Server instance.</li> </ul> <p>Supported metrics:</p> <ul> <li><code>dtu_consumption_percent</code> - Percentage of consumed CPU across all elastic pools.</li> <li>Requires <code>dimension.name</code> to be set to <code>ElasticPoolResourceId</code></li> <li><code>storage_used</code> - Amount of storage data across all elastic pools in bytes.</li> <li>Requires <code>dimension.name</code> to be set to <code>ElasticPoolResourceId</code></li> <li><code>dtu_used</code> - Amount of consumed DTU across all databases.</li> <li>Requires <code>dimension.name</code> to be set to <code>DatabaseResourceId</code></li> </ul> <p>The official Azure Monitor documentation lists more metrics but these are not surfaced externally. However, you can still give them a try but we don't support them for now.</p>","tags":["Scraper","Resource Discovery","SQL","Data"]},{"location":"scraping/providers/sql-server/#example","title":"Example","text":"<p>Here is an example configuration:</p> <pre><code>name: azure_sql_server_dtu_consumption_percent\ndescription: \"The DTU consumption percentage used by an Azure SQL Server.\"\nresourceType: SqlServer\nazureMetricConfiguration:\n  metricName: dtu_used\n  dimension:\n    name: DatabaseResourceId\n  aggregation:\n    type: Average\nresources:\n- serverName: promitor\n</code></pre>","tags":["Scraper","Resource Discovery","SQL","Data"]},{"location":"scraping/providers/storage-account/","title":"Azure Storage Account","text":"<p>You can declare to scrape an Azure Queue via the <code>StorageAccount</code> resource type.</p> <p>When using declared resources, the following fields need to be provided:</p> <ul> <li><code>accountName</code> - The name of the Azure Storage account</li> </ul> <p>All supported metrics are documented in the official Azure Monitor documentation.</p>","tags":["Scraper","Resource Discovery","Data","Storage"]},{"location":"scraping/providers/storage-account/#example","title":"Example","text":"<p>Here is an example configuration:</p> <pre><code>name: azure_storage_account_capacity\ndescription: \"The average capacity used in the storage account\"\nresourceType: StorageAccount\nazureMetricConfiguration:\n  metricName: UsedCapacity\n  aggregation:\n    type: Average\nresources: # Optional, required when no resource discovery is configured\n- accountName: promitor-1\n- accountName: promitor-2\nresourceDiscoveryGroups: # Optional, requires Promitor Resource Discovery agent (https://docs.promitor.io/latest/how-it-works#using-resource-discovery)\n- name: storage-account-landscape\n</code></pre>","tags":["Scraper","Resource Discovery","Data","Storage"]},{"location":"scraping/providers/storage-queue/","title":"Azure Storage Queue","text":"<p>You can declare to scrape an Azure Queue via the <code>StorageQueue</code> resource type.</p> <p>When using declared resources, the following fields need to be provided:</p> <ul> <li><code>accountName</code> - The name of the storage account</li> <li><code>queueName</code> - The name of the queue</li> <li><code>sasToken</code> - The SAS token used to access the queue/account</li> <li><code>sasToken.environmentVariable</code> - Defines the environment variable which contains     the SAS token to authenticate with</li> <li><code>sasToken.rawValue</code> - Contains the raw hardcoded SAS token (less secure)</li> </ul> <p>Supported metrics:</p> <ul> <li><code>TimeSpentInQueue</code> - Time in seconds that the oldest message has been waiting   in the queue to be processed.</li> <li><code>MessageCount</code></li> </ul> <p>The following scraper-specific metric label will be added:</p> <ul> <li><code>queue_name</code> - Name of the queue</li> </ul>","tags":["Scraper","Data","Storage"]},{"location":"scraping/providers/storage-queue/#example","title":"Example","text":"<p>Here is an example configuration:</p> <pre><code>name: azure_storage_queue_message_count\ndescription: \"The number of messages on an Azure storage queue\"\nresourceType: StorageQueue\nazureMetricConfiguration:\n  metricName: MessageCount\n  aggregation:\n    type: Total\nresources:\n- accountName: promitor\n  queueName: orders\n  sasToken:\n    environmentVariable: \"SECRETS_STORAGEQUEUE_PROMITOR_SASTOKEN\"\n- accountName: promitor\n  queueName: items\n  sasToken:\n    environmentVariable: \"SECRETS_STORAGEQUEUE_PROMITOR_SASTOKEN\"\n</code></pre>","tags":["Scraper","Data","Storage"]},{"location":"scraping/providers/synapse-apache-spark-pool/","title":"Azure Synapse (Apache Spark pool)","text":"<p>You can scrape an Azure Synapse Apache Spark pool via the <code>SynapseApacheSparkPool</code> resource type.</p> <p>When using declared resources, the following fields need to be provided:</p> <ul> <li><code>workspaceName</code> - The name of the Azure Synapse workspace.</li> <li><code>poolName</code> - The name of the Apache Spark pool.</li> </ul> <p>All supported metrics are documented in the official Azure Monitor documentation.</p> <p>The following scraper-specific metric labels will be added:</p> <ul> <li><code>workspace_name</code> - The name of the Azure Synapse workspace.</li> <li><code>pool_name</code> - The name of the Apache Spark pool.</li> </ul>","tags":["Scraper","Resource Discovery","Data","Synapse"]},{"location":"scraping/providers/synapse-apache-spark-pool/#example","title":"Example","text":"<p>Here is an example configuration:</p> <pre><code>- name: promitor_demo_synapse_apache_spark_apps_ended\n  description: \"Amount of apps ended running on Apache Spark pool in Azure Synapse\"\n  resourceType: SynapseApacheSparkPool\n  azureMetricConfiguration:\n    metricName: BigDataPoolApplicationsEnded\n    aggregation:\n      type: Total\n  resources: # Optional, required when no resource discovery is configured\n  - workspaceName: promitor-synapse\n    poolName: sparkpool\n  resourceDiscoveryGroups: # Optional, requires Promitor Resource Discovery agent (https://docs.promitor.io/latest/how-it-works#using-resource-discovery)\n  - name: synapse-apache-spark-pools\n</code></pre>","tags":["Scraper","Resource Discovery","Data","Synapse"]},{"location":"scraping/providers/synapse-sql-pool/","title":"Azure Synapse (SQL pool)","text":"<p>You can scrape an Azure Synapse SQL pool via the <code>SynapseSqlPool</code> resource type.</p> <p>When using declared resources, the following fields need to be provided:</p> <ul> <li><code>workspaceName</code> - The name of the Azure Synapse workspace.</li> <li><code>poolName</code> - The name of the SQL pool.</li> </ul> <p>All supported metrics are documented in the official Azure Monitor documentation.</p> <p>The following scraper-specific metric labels will be added:</p> <ul> <li><code>workspace_name</code> - The name of the Azure Synapse workspace.</li> <li><code>pool_name</code> - The name of the SQL pool.</li> </ul>","tags":["Scraper","Resource Discovery","Data","Synapse"]},{"location":"scraping/providers/synapse-sql-pool/#example","title":"Example","text":"<p>Here is an example configuration:</p> <pre><code>- name: promitor_demo_synapse_sql_pool_dwu_limit\n  description: \"Amount of DWUs defined as limit for SQL pool in Azure Synapse\"\n  resourceType: SynapseSqlPool\n  azureMetricConfiguration:\n    metricName: DWULimit\n    aggregation:\n      type: Maximum\n  resources: # Optional, required when no resource discovery is configured\n  - workspaceName: promitor-synapse\n    poolName: sqlpool\n  resourceDiscoveryGroups: # Optional, requires Promitor Resource Discovery agent (https://docs.promitor.io/latest/how-it-works#using-resource-discovery)\n  - name: synapse-sql-pools\n</code></pre>","tags":["Scraper","Resource Discovery","Data","Synapse"]},{"location":"scraping/providers/synapse-workspace/","title":"Azure Synapse (Workspace)","text":"<p>You can scrape an Azure Synapse workspace via the <code>SynapseWorkspace</code> resource type.</p> <p>When using declared resources, the following fields need to be provided:</p> <ul> <li><code>workspaceName</code> - The name of the Azure Synapse workspace.</li> </ul> <p>All supported metrics are documented in the official Azure Monitor documentation.</p> <p>The following scraper-specific metric labels will be added:</p> <ul> <li><code>workspace_name</code> - The name of the Azure Synapse workspace.</li> </ul>","tags":["Scraper","Resource Discovery","Data","Synapse"]},{"location":"scraping/providers/synapse-workspace/#example","title":"Example","text":"<p>Here is an example configuration:</p> <pre><code>- name: promitor_demo_synapse_workspace_builtin_sql_processed_bytes\n  description: \"Amount of bytes processed in Azure Synapse workspace\"\n  resourceType: SynapseWorkspace\n  azureMetricConfiguration:\n    metricName: BuiltinSqlPoolDataProcessedBytes\n    aggregation:\n      type: Total\n  resources: # Optional, required when no resource discovery is configured\n  - workspaceName: promitor-synapse\n    resourceGroupName: promitor-sources\n  resourceDiscoveryGroups: # Optional, requires Promitor Resource Discovery agent (https://docs.promitor.io/latest/how-it-works#using-resource-discovery)\n  - name: synapse-workspaces\n</code></pre>","tags":["Scraper","Resource Discovery","Data","Synapse"]},{"location":"scraping/providers/traffic-manager/","title":"Azure Traffic Manager Profile","text":"<p>You can declare to scrape a Traffic Manager via the <code>TrafficManager</code> resource type.</p> <p>When using declared resources, the following fields need to be provided:</p> <ul> <li><code>name</code> - The name of the Traffic Manager Profile.</li> </ul> <p>All supported metrics are documented in the official Azure Monitor documentation.</p>","tags":["Scraper","Resource Discovery","Networking"]},{"location":"scraping/providers/traffic-manager/#example","title":"Example","text":"<p>Here is an example configuration:</p> <pre><code>name: azure_traffic_manager_endpoint_qps\ndescription: \"Number of times a Traffic Manager endpoint was returned in the given time frame\"\nresourceType: TrafficManager\nazureMetricConfiguration:\n  metricName: QpsByEndpoint\n  aggregation:\n    type: Total\nresources: # Optional, required when no resource discovery is configured\n- name: promitor-traffic-manager\nresourceDiscoveryGroups: # Optional, requires Promitor Resource Discovery agent (https://docs.promitor.io/latest/how-it-works#using-resource-discovery)\n- name: traffic-managers\n</code></pre>","tags":["Scraper","Resource Discovery","Networking"]},{"location":"scraping/providers/virtual-machine-scale-set/","title":"Azure Virtual Machine Scale Set (VMSS)","text":"<p>You can declare to scrape an Azure Virtual Machine Scale Set via the <code>VirtualMachineScaleSet</code> resource type.</p> <p>When using declared resources, the following fields need to be provided:</p> <ul> <li><code>scaleSetName</code> - The name of the Virtual Machine Scale Set</li> </ul> <p>All supported metrics are documented in the official Azure Monitor documentation.</p>","tags":["Scraper","Resource Discovery","IaaS"]},{"location":"scraping/providers/virtual-machine-scale-set/#example","title":"Example","text":"<p>Here is an example configuration:</p> <pre><code>name: azure_virtual_machine_scale_set_percentage_cpu\ndescription: \"Average percentage cpu usage on an Azure virtual machine scale set\"\nresourceType: VirtualMachineScaleSet\nazureMetricConfiguration:\n  metricName: Percentage CPU\n  dimension:\n    name: VMName\n  aggregation:\n    type: Average\nresources: # Optional, required when no resource discovery is configured\n- scaleSetName: promitor-virtual-machine-scale-set-1\nresourceDiscoveryGroups: # Optional, requires Promitor Resource Discovery agent (https://docs.promitor.io/latest/how-it-works#using-resource-discovery)\n- name: virtual-machine-scale-sets-landscape\n</code></pre>","tags":["Scraper","Resource Discovery","IaaS"]},{"location":"scraping/providers/virtual-machine/","title":"Azure Virtual Machine (VM)","text":"<p>You can declare to scrape an Azure Virtual Machine via the <code>VirtualMachine</code> resource type.</p> <p>When using declared resources, the following fields need to be provided:</p> <ul> <li><code>virtualMachineName</code> - The name of the virtual machine</li> </ul> <p>All supported metrics are documented in the official Azure Monitor documentation.</p>","tags":["Scraper","Resource Discovery","IaaS"]},{"location":"scraping/providers/virtual-machine/#example","title":"Example","text":"<p>Here is an example configuration:</p> <pre><code>name: azure_virtual_machine_percentage_cpu\ndescription: \"Average percentage cpu usage on an Azure virtual machine\"\nresourceType: VirtualMachine\nazureMetricConfiguration:\n  metricName: Percentage CPU\n  aggregation:\n    type: Average\nresources: # Optional, required when no resource discovery is configured\n- virtualMachineName: promitor-virtual-machine-1\n- virtualMachineName: promitor-virtual-machine-2\nresourceDiscoveryGroups: # Optional, requires Promitor Resource Discovery agent (https://docs.promitor.io/latest/how-it-works#using-resource-discovery)\n- name: virtual-machine-landscape\n</code></pre>","tags":["Scraper","Resource Discovery","IaaS"]},{"location":"scraping/providers/virtual-network/","title":"Azure Virtual Network","text":"<p>You can declare to scrape an Azure Virtual Network via the <code>VirtualNetwork</code> resource type.</p> <p>When using declared resources, the following fields need to be provided:</p> <ul> <li><code>virtualNetworkName</code> - The name of the Azure Virtual Network resource</li> </ul> <p>All supported metrics are documented in the official Azure Monitor documentation.</p>","tags":["Scraper","Resource Discovery","Networking"]},{"location":"scraping/providers/virtual-network/#example","title":"Example","text":"<p>Here is an example configuration:</p> <pre><code>name: azure_virtual_network_ddos_attack\ndescription: \"Indication whether or not there is a DDOS attack on the Azure Virtual Network\"\nresourceType: VirtualNetwork\nazureMetricConfiguration:\n  metricName: IfUnderDDoSAttack\n  aggregation:\n    type: Maximum\nresources: # Optional, required when no resource discovery is configured\n- virtualNetworkName: promitor-virtual-network-1\n- virtualNetworkName: promitor-virtual-network-2\nresourceDiscoveryGroups: # Optional, requires Promitor Resource Discovery agent (https://docs.promitor.io/latest/how-it-works#using-resource-discovery)\n- name: virtual-network-landscape\n</code></pre>","tags":["Scraper","Resource Discovery","Networking"]},{"location":"scraping/providers/web-app/","title":"Azure Web App","text":"<p>You can declare to scrape an Azure Web App via the <code>WebApp</code> resource type.</p> <p>When using declared resources, the following fields need to be provided:</p> <ul> <li><code>webAppName</code> - The name of the Azure Web App</li> <li><code>slotName</code> - The name of the deployment slot (optional)</li> </ul> <p>All supported metrics are documented in the official Azure Monitor documentation.</p> <p>The following scraper-specific metric label will be added:</p> <ul> <li><code>slot_name</code> - Name of the deployment slot. If none is specified, <code>production</code> will be used.</li> </ul> <p>Example:</p> <pre><code>name: azure_web_app_requests\ndescription: \"Amount of requests for an Azure Web App\"\nresourceType: WebApp\nazureMetricConfiguration:\n  metricName: Requests\n  aggregation:\n    type: Total\nresources: # Optional, required when no resource discovery is configured\n- webAppName: promitor-web-app\n  slot: staging\n- webAppName: promitor-web-app\n  slot: production\nresourceDiscoveryGroups: # Optional, requires Promitor Resource Discovery agent (https://docs.promitor.io/latest/how-it-works#using-resource-discovery)\n- name: web-app-landscape\n</code></pre>","tags":["Scraper","Resource Discovery","PaaS"]},{"location":"security/azure-authentication/","title":"Authentication with Microsoft Azure","text":"<p>This document describes the various agents that Promitor provides, what Microsoft Azure services they are consuming and  what the minimal required permissions are that every entity requires to be functional.</p>"},{"location":"security/azure-authentication/#overview","title":"Overview","text":"<p>Here is an overview of our Promitor agents and their integrations:</p> Azure Integration Promitor Scraper Promitor Resource Discovery Azure Monitor \u2705 \u274c Azure Resource Graph \u274c \u2705 <p>Each agent needs an Azure AD identity to authenticate with to Microsoft Azure.</p> <p>In order to achieve this, you'll need to create an Azure AD Application,</p>"},{"location":"security/azure-authentication/#supported-authentication-mechanisms","title":"Supported Authentication Mechanisms","text":"<p>Our agents provide the following authentication mechanisms:</p> <ul> <li>Service principle - Use application id &amp; secret of the Azure AD entity that has been pre-created to authenticate with</li> <li>Managed Identity - Use zero-secret authentication by letting Microsoft handle the authentication for you (docs)</li> </ul> <p>For details how to configure the authentication, we recommend reading our agent configuration documentation.</p>"},{"location":"security/azure-authentication/#service-principle-authentication","title":"Service Principle Authentication","text":"<p>Every agent needs to be configured with the following environment variables:</p> <ul> <li>PROMITOR_AUTH_APPKEY - Secret of the Azure AD entity to authenticate with</li> </ul> <p>The app key can also be read from a file by specifying the file's location:</p> <pre><code>authentication:\n  # Options are ServicePrincipal, SystemAssignedManagedIdentity, UserAssignedManagedIdentity, SdkDefault.\n  mode: ServicePrincipal # Optional. Default: ServicePrincipal.\n  identityid: # [app id]\n  secretFilePath: # [the name of the folder containing the secret file]\n  secretFileName: # [the name of the file containing the app key]  \n</code></pre>"},{"location":"security/azure-authentication/#managed-identity-authentication","title":"Managed Identity Authentication","text":"<p>When using Managed Identity, you can use one of the following scenarios:</p> <ul> <li>System-assigned Managed Identity - Use the identity of the Azure resource on which it runs and let Azure handle  the authentication.</li> <li>User-assigned Managed Identity - Use a pre-created Azure AD identity but let Azure handle the authentication for you</li> <li>SdkDefault - Use credentials from both Azure hosting environments and local development, letting Azure manage authentication seamlessly. </li> </ul> <p>\u26a0 In order to use managed identity, your Kubernetes cluster must be hosted on Microsoft Azure to leverage this.</p>"},{"location":"security/azure-authentication/#permission-overview","title":"Permission Overview","text":""},{"location":"security/azure-authentication/#required-permissions-for-azure-monitor","title":"Required permissions for Azure Monitor","text":"<p>Identities that are used to integrate with Azure Monitor need to have <code>Monitoring Reader</code> permission on the subscription, resource group and/or resources that will be queried.</p> <p>More information can be found here.</p>"},{"location":"security/azure-authentication/#required-permissions-for-azure-resource-graph","title":"Required permissions for Azure Resource Graph","text":"<p>Identities that are used to integrate with Azure Resource Graph need to have <code>Reader</code> permission on the subscription, resource group and/or resources that will be queried.</p> <p>\u26a0 If you are re-using this identity to integrate with Azure Monitor, make sure to grant the required permissions  to reflect that as well.</p> <p>More information can be found here.</p> <p>\u2190 back</p>"},{"location":"walkthroughs/migrate-from-1.x-to-2.x/","title":"Migrate from Promitor Scraper 1.x to 2.x","text":"<p>Here is a migration guide from Promitor Scraper v1.x to v2.x.</p> <p>For a complete overview of our changelog, we recommend going to changelog.promitor.io.</p>"},{"location":"walkthroughs/migrate-from-1.x-to-2.x/#migrate-to-new-metric-sink-concept","title":"Migrate to new metric sink concept","text":"<p>As of Promitor Scraper v1.6 we have introduced the concept of metric sinks  allowing you to emit scraped Azure Monitor metrics to multiple systems.</p> <p>With Promitor v2.0, we are removing support for our legacy Prometheus configuration.</p> <p>When using the following configuration:</p> <pre><code>prometheus:\n  metricUnavailableValue: NaN\n  enableMetricTimestamps: false\n  scrapeEndpoint:\n    baseUriPath: /metrics\n</code></pre> <p>You can easily migrate it to our Prometheus Scraping endpoint sink as following:</p> <pre><code>metricSinks:\n  prometheusScrapingEndpoint:\n    metricUnavailableValue: NaN\n    enableMetricTimestamps: false\n    baseUriPath: /metrics\n</code></pre> <p>For more information, we recommend reading our  documentation concerning our Prometheus Scraping endpoint.</p>"},{"location":"walkthroughs/migrate-from-1.x-to-2.x/#migrate-from-azure-service-bus-queue-scraper-to-our-new-azure-service-bus-namespace-scraper","title":"Migrate from Azure Service Bus Queue scraper to our new Azure Service Bus Namespace scraper","text":"<p>Since Azure Service Bus Queue scraper allows you to report metrics for all entities we decided to change the resource  type from <code>ServiceBusQueue</code> to <code>ServiceBusNamespace</code> since it will also report metrics for topics, and not only queues.</p> <p>For example:</p> <pre><code>name: azure_service_bus_queue_active_messages\ndescription: \"The number of active messages on a service bus queue\"\nresourceType: ServiceBusNamespace\nazureMetricConfiguration:\n  metricName: ActiveMessages\n  aggregation:\n    type: Total\nresources:\n- namespace: promitor-messaging\n  # queueName: orders &lt;-- Optionally specify the queue name to filter on\n  # topicName: sales &lt;-- Optionally specify the queue name to filter on\nresourceDiscoveryGroups: # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery)\n- name: service-bus-landscape\n</code></pre> <p>For more information, we recommend reading our  documentation   concerning our Azure Service Bus Namespace scraper.</p>"},{"location":"walkthroughs/migrate-from-1.x-to-2.x/#migrate-to-openapi-30-ui","title":"Migrate to OpenAPI 3.0 &amp; UI","text":"<p>All Promitor APIs have been migrated from Swagger to OpenAPI 3.0 specification.</p> <p>Before, our Swagger docs were accessible via:</p> <ul> <li>Swagger UI on <code>/swagger</code></li> <li>Raw documentation on <code>/swagger/v1/swagger.json</code></li> </ul> <p>Our OpenAPI 3.0 docs are available on:</p> <ul> <li>Swagger UI on <code>/api/docs</code></li> <li>Raw documentation on <code>/api/v1/docs.json</code></li> </ul> <p>\u2190 back</p>"},{"location":"walkthroughs/scrape-promitor-with-prometheus-on-azure-kubernetes-service/","title":"Deploying Promitor, Prometheus, and Grafana on an AKS Cluster","text":""},{"location":"walkthroughs/scrape-promitor-with-prometheus-on-azure-kubernetes-service/#introduction","title":"Introduction","text":"<p>In this walkthrough, we'll set up a basic monitoring solution with Promitor, Prometheus, and Grafana.</p> <p>In order to have a resource to monitor, we'll create a Service Bus queue and add load to the queue with Service Bus Explorer.</p> <p>We'll deploy Promitor, Prometheus, and Grafana to a Kubernetes cluster using Helm, and explain how each of these services connects and how to see output.</p> <p>We'll also walk through setting up basic Grafana dashboard to visualize the metrics we're monitoring.</p>"},{"location":"walkthroughs/scrape-promitor-with-prometheus-on-azure-kubernetes-service/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Deploy Azure Infrastructure<ul> <li>Create a Resource Group</li> <li>Create a Service Principal</li> <li>Create a Service Bus Namespace and Queue</li> <li>Create an AKS Cluster</li> </ul> </li> <li>Cluster Setup<ul> <li>Get credentials</li> </ul> </li> <li>Deploy Promitor and Prometheus<ul> <li>Create a metrics declaration for Promitor</li> <li>Deploy Promitor to your cluster using Helm</li> <li>Install Prometheus</li> </ul> </li> <li>Test and check output<ul> <li>Add load to the queue</li> <li>See Promitor &amp; Prometheus output via port-forwarding</li> </ul> </li> <li>Visualization<ul> <li>Install Grafana</li> <li>Add Prometheus as a data source</li> <li>Create a Grafana dashboard for queue metrics</li> <li>Creating a Kubernetes dashboard</li> </ul> </li> <li>Delete resources</li> </ul>"},{"location":"walkthroughs/scrape-promitor-with-prometheus-on-azure-kubernetes-service/#prerequisites","title":"Prerequisites","text":"<ul> <li>The Azure CLI</li> <li>kubectl, the Kubernetes   command-line tool. It can also be installed via the Azure CLI with <code>az aks install-cli</code>.</li> <li>Helm, a Kubernetes   deployment manager</li> <li>Service Bus Explorer</li> </ul>"},{"location":"walkthroughs/scrape-promitor-with-prometheus-on-azure-kubernetes-service/#deploy-azure-infrastructure","title":"Deploy Azure Infrastructure","text":""},{"location":"walkthroughs/scrape-promitor-with-prometheus-on-azure-kubernetes-service/#create-a-resource-group","title":"Create a Resource Group","text":"<pre><code>az group create --name PromitorRG --location eastus\n</code></pre> <p>Output:</p> <pre><code>{\n  \"id\": \"/subscriptions/&lt;guid-subscription-id&gt;/resourceGroups/PromitorRG\",\n  \"...\": \"...\"\n}\n</code></pre>"},{"location":"walkthroughs/scrape-promitor-with-prometheus-on-azure-kubernetes-service/#create-a-service-principal","title":"Create a Service Principal","text":"<p>Use the resource group creation output to add a scope to your service principal:</p> <pre><code>az ad sp create-for-rbac \\\n  --role=\"Monitoring Reader\" \\\n  --scopes=\"/subscriptions/&lt;guid-subscription-id&gt;/resourceGroups/PromitorRG\"\n</code></pre> <p>Which should output something similar to</p> <pre><code>{\n  \"appId\": \"&lt;guid-sp-app-id&gt;\",\n  \"displayName\": \"azure-cli-2019-03-29-19-21-58\",\n  \"name\": \"http://azure-cli-2019-03-29-19-21-58\",\n  \"password\": \"&lt;guid-sp-generated-password&gt;\",\n  \"tenant\": \"&lt;guid-tenant-id&gt;\"\n}\n</code></pre> <p>Save this output as we will use the app ID, tenant ID, and password later on.</p>"},{"location":"walkthroughs/scrape-promitor-with-prometheus-on-azure-kubernetes-service/#create-a-service-bus-namespace-and-queue","title":"Create a Service Bus Namespace and Queue","text":"<p>First we'll need to create a namespace. Service Bus Namespaces need to be globally unique, so we won't use a default name in these commands.</p> <pre><code>az servicebus namespace create \\\n  --resource-group PromitorRG \\\n  --name &lt;service-bus-namespace&gt; \\\n  --location eastus\n</code></pre> <p>We'll then create a queue in that namespace:</p> <pre><code>az servicebus queue create \\\n  --resource-group PromitorRG \\\n  --namespace-name &lt;service-bus-namespace&gt; \\\n  --name demo_queue\n</code></pre> <p>Finally, get the connection string for this Service Bus namespace for use later.</p> <pre><code>az servicebus namespace authorization-rule keys list \\\n  --resource-group PromitorRG \\\n  --namespace-name &lt;service-bus-namespace&gt; \\\n  --name RootManageSharedAccessKey \\\n  --query primaryConnectionString \\\n  --output tsv\n</code></pre>"},{"location":"walkthroughs/scrape-promitor-with-prometheus-on-azure-kubernetes-service/#create-an-aks-cluster","title":"Create an AKS Cluster","text":"<p>Create a cluster with:</p> <pre><code>az aks create \\\n  --name PromitorCluster \\\n  --resource-group PromitorRG \\\n  --node-count 1 \\\n  --generate-ssh-keys\n</code></pre>"},{"location":"walkthroughs/scrape-promitor-with-prometheus-on-azure-kubernetes-service/#cluster-setup","title":"Cluster Setup","text":""},{"location":"walkthroughs/scrape-promitor-with-prometheus-on-azure-kubernetes-service/#get-credentials","title":"Get credentials","text":"<p>You can get your cluster's credentials with</p> <pre><code>az aks get-credentials \\\n  --name PromitorCluster \\\n  --resource-group PromitorRG\n</code></pre> <p>This will save these credentials to your kubeconfig file and set your new cluster as your current context for all <code>kubectl</code> commands.</p> <p>Verify your credentials and check that your cluster is up and running with <code>kubectl get nodes</code>.</p>"},{"location":"walkthroughs/scrape-promitor-with-prometheus-on-azure-kubernetes-service/#deploy-promitor-and-prometheus","title":"Deploy Promitor and Prometheus","text":""},{"location":"walkthroughs/scrape-promitor-with-prometheus-on-azure-kubernetes-service/#create-a-metrics-declaration-for-promitor","title":"Create a metrics declaration for Promitor","text":"<p>Before deploying Promitor, you'll need a values file with secrets &amp; a metric declaration file (these can also be the same file for ease of use). The yaml below will scrape one metric, queue length, from the queue created above.</p> <pre><code>azureAuthentication:\n  appId: &lt;guid-sp-app-id&gt;\n  appKey: &lt;guid-sp-generated-password&gt;\n\nazureMetadata:\n  tenantId: &lt;guid-tenant-id&gt;\n  subscriptionId: &lt;guid-subscription-id&gt;\n  resourceGroupName: PromitorRG\nmetricDefaults:\n  aggregation:\n    interval: 00:05:00\n  scraping:\n    schedule: \"* * * * *\"\nmetrics:\n  - name: demo_queue_size\n    description: \"Amount of active messages of the 'demo_queue' queue\"\n    resourceType: ServiceBusNamespace\n    azureMetricConfiguration:\n      metricName: ActiveMessages\n      aggregation:\n        type: Total\n    resources:\n      - namespace: &lt;service-bus-namespace&gt;\n        queueName: demo_queue\n</code></pre>"},{"location":"walkthroughs/scrape-promitor-with-prometheus-on-azure-kubernetes-service/#deploy-promitor-to-your-cluster-using-helm","title":"Deploy Promitor to your cluster using Helm","text":"<p>To deploy, we'll first add the Promitor chart repository to helm:</p> <pre><code>helm repo add promitor https://charts.promitor.io/\nhelm repo update\n</code></pre> <p>With this repository added, we can deploy Promitor:</p> <pre><code>helm install promitor-agent-scraper promitor/promitor-agent-scraper \\\n  --values your/path/to/metric-declaration.yaml\n</code></pre>"},{"location":"walkthroughs/scrape-promitor-with-prometheus-on-azure-kubernetes-service/#install-prometheus","title":"Install Prometheus","text":"<p>Note: If you're seeing errors installing Prometheus or Grafana from the Helm chart repository, make sure you run <code>helm repo update</code> before digging into the errors more. You might have an outdated copy of the chart.</p> <p>Running the deployment command from the previous section should give you an output that includes a script similar to this one:</p> <pre><code>cat &gt; promitor-scrape-config.yaml &lt;&lt;EOF\nextraScrapeConfigs: |\n  - job_name: promitor-agent-scraper\n    metrics_path: /metrics\n    static_configs:\n      - targets:\n        - promitor-agent-scraper.default.svc.cluster.local:80\nEOF\nhelm install stable/prometheus -f promitor-scrape-config.yaml\n</code></pre> <p>You can see this output again at any time by running <code>helm status promitor-agent-scraper</code>.</p> <p>Running these commands will create a Prometheus scraping configuration file in your current directory and deploy Prometheus to your cluster with that scraping configuration in addition to the default.</p>"},{"location":"walkthroughs/scrape-promitor-with-prometheus-on-azure-kubernetes-service/#test-and-check-output","title":"Test and check output","text":""},{"location":"walkthroughs/scrape-promitor-with-prometheus-on-azure-kubernetes-service/#add-load-to-the-queue","title":"Add load to the queue","text":"<p>Now we'll use Service Bus Explorer to add load to our Service Bus queue so there are meaningful metrics for Promitor to pick up.</p> <p>In Service Bus Explorer, you can connect to your namespace &amp; queue using a connection string. From there, right clicking on the queue in the side-bar should give you an option to 'Send Message' - from there, use the 'Sender' tab of that window to send bulk messages. Remember how many you send - you should see that number in the Promitor &amp; Prometheus output.</p>"},{"location":"walkthroughs/scrape-promitor-with-prometheus-on-azure-kubernetes-service/#see-promitor-prometheus-output-via-port-forwarding","title":"See Promitor &amp; Prometheus output via port-forwarding","text":"<p>Going back to your cluster, you should be able to see all Promitor &amp; Prometheus pods up and running with <code>kubectl get pods</code>.</p> <p>You can also see the services which provide a stable endpoint at which to reach the pods by running <code>kubectl get services</code>.</p> <p>This should give you a list with output similar to:</p> NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) promitor-agent-scraper ClusterIP 10.0.#.# \\&lt;none&gt; 80/TCP \\&lt;prometheus-release-name&gt;-prometheus-server ClusterIP 10.0.#.# \\&lt;none&gt; 80/TCP <p>Next to that, it should also list other services deployed by Prometheus.</p> <p>Let's first look at the Promitor output!</p> <p>Run <code>kubectl port-forward svc/promitor-agent-scraper 8080:80</code> and check http://localhost:8080/metrics. You should see some information about your queue:</p> <pre><code># HELP promitor_ratelimit_arm Indication how many calls are still available before Azure Resource Manager is going to throttle us.\n# TYPE promitor_ratelimit_arm gauge\npromitor_ratelimit_arm{tenant_id=&lt;guid-tenant-id&gt;,subscription_id=&lt;guid-subscription-id&gt;,app_id=&lt;guid-sp-app-id&gt;} 11998 1558116465529\n# HELP demo_queue_size Amount of active messages of the 'demo_queue' queue\n# TYPE demo_queue_size gauge\ndemo_queue_size 200 1558116465677\n</code></pre> <p>where 200 is the number of messages sent.</p> <p>We can also look at the Prometheus server and check that it's pulling in metrics from Promitor.</p> <p>Cancel the previous port-forward command and run <code>kubectl port-forward svc/&lt;prometheus-release-name&gt;-prometheus-server 8080:80</code>.</p> <p>Now, if you check http://localhost:8080, you should be able to enter Prometheus queries.</p> <p>Query <code>demo_queue_size</code> and as long as all your pods are up and running and both Promitor and Prometheus have scraped metrics at least once, you should see a value that matches the number of messages in your queue.</p>"},{"location":"walkthroughs/scrape-promitor-with-prometheus-on-azure-kubernetes-service/#visualization","title":"Visualization","text":""},{"location":"walkthroughs/scrape-promitor-with-prometheus-on-azure-kubernetes-service/#install-grafana","title":"Install Grafana","text":"<p>Grafana's chart has a few default values you may not want long term - persistant storage is disabled and admin username/password is randomly generated - but for our sample the out-of-the-box install will work.</p> <p>Run <code>helm install grafana stable/grafana</code> and you should see output that includes this command:</p> <pre><code>kubectl get secret --namespace default grafana -o jsonpath=\"{.data.admin-password}\" | base64 --decode ; echo\n</code></pre> <p>Run this to get your Grafana password.</p> <p>Now you can use <code>kubectl port-forward</code> again to log in to your Grafana dashboard. <code>kubectl port-forward svc/grafana 8080:80</code> will make your dashboard available at http://localhost:8080, and you can log in with username 'admin' and the password you retrieved.</p>"},{"location":"walkthroughs/scrape-promitor-with-prometheus-on-azure-kubernetes-service/#add-prometheus-as-a-data-source","title":"Add Prometheus as a data source","text":"<p>After logging in, you should see an option to \"Add a Data Source.\" Click that, and choose the Prometheus source type (if it's not immediately visible, search for it).</p> <p>The only setting you should need to edit here is the URL, under the HTTP section. Within your cluster, <code>http://&lt;prometheus-release-name&gt;-prometheus-server.default.svc.cluster.local</code> should resolve to the Prometheus server service. (Default in that URL refers to the namespace - if you installed in a namespace other than default, change that.)</p> <p>Set your service's name as the Prometheus URL in Grafana, and save the data source. It should tell you that the data source is working.</p>"},{"location":"walkthroughs/scrape-promitor-with-prometheus-on-azure-kubernetes-service/#create-a-grafana-dashboard-for-queue-metrics","title":"Create a Grafana dashboard for queue metrics","text":"<p>First, we'll make a basic dashboard with the metric we set up in Promitor. Then you can use a pre-built dashboard to show Prometheus' default Kubernetes metrics.</p> <p>Go to the + button on the sidebar, and choose \"Dashboard\". To make a simple graph showing your queue size, you can write <code>demo_queue_size</code> in the query field. Click out of that input field and the graph should update.</p> <p>To see more, you can go back to Service Bus Explorer and send or receive messages. Your Grafana graph won't update immediately, but you should see results in a few minutes.</p> <p>In order to see results without manually refreshing, find the dropdown menu in the top right corner that sets the time range of the graph. Here you can edit time range and refresh rate.</p> <p>Make sure to save your new dashboard before exiting the page.</p>"},{"location":"walkthroughs/scrape-promitor-with-prometheus-on-azure-kubernetes-service/#creating-a-kubernetes-dashboard","title":"Creating a Kubernetes dashboard","text":"<p>Now we'll import a pre-created dashboard that shows Kubernetes metrics. There are multiple available on Grafana Lab's dashboard site.</p> <p>To import a dashboard, click the + button on the sidebar and choose \"Import.\" From there, you can either load a JSON file or enter the dashbord ID: 6417.</p> <p>Click \"Load\" and you will be given some configuration options. The only one that needs to be set is the Prometheus data source. From there, you should be able to create the dashboard and view metrics about your AKS cluster.</p>"},{"location":"walkthroughs/scrape-promitor-with-prometheus-on-azure-kubernetes-service/#delete-resources","title":"Delete resources","text":"<p>To delete all the resources used in this tutorial, run <code>az group delete --name PromitorRG</code>.</p> <p>\u2190 back</p>"},{"location":"walkthroughs/use-promitor-with-managed-identity/","title":"Using Managed Identity with Promitor on Azure Kubernetes Service","text":""},{"location":"walkthroughs/use-promitor-with-managed-identity/#introduction","title":"Introduction","text":"<p>This walkthrough will allow you to deploy Promitor that uses Managed Identity  on an Azure Kubernetes Service cluster to scrape Azure Service Bus metrics, using no-password authentication.</p> <p>In order to achieve this, we will use the AAD Pod Identity project to  manage the identities and authentication.</p> <p>\u26a0 This only works with Azure Kubernetes Service - Learn more about Managed Identity in Azure Kubernetes Service in the official Microsoft documentation.</p>"},{"location":"walkthroughs/use-promitor-with-managed-identity/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Introduction</li> <li>Table of Contents</li> <li>Prerequisites</li> <li>Deploying the Azure Infrastructure<ul> <li>Preparing script</li> <li>Creating an Azure Resource Group</li> <li>Creating an Azure Service Bus Namespace &amp; Queue</li> <li>Creating an Azure Kubernetes Service Cluster</li> </ul> </li> <li>Setting up our cluster<ul> <li>Getting The Cluster Credentials</li> <li>Get Azure Kubernetes Service managed identity &amp; cluster resource group</li> </ul> </li> <li>Getting our cluster ready to use AAD Pod Identity<ul> <li>Granting our cluster's managed identity required permissions in Azure</li> <li>Installing AAD Pod Identity</li> <li>Creating a user-assigned managed identity for Promitor</li> <li>Bind your Managed Identity to our Pods, through AAD Pod Identity</li> <li>Verifying the AAD Pod Identity installation</li> </ul> </li> <li>Deploying Promitor with Managed Identity<ul> <li>Create a metrics declaration for Promitor</li> <li>Deploy Promitor to your cluster using Helm</li> <li>Verifying the scraped output in Promitor</li> </ul> </li> <li>Cleaning up</li> </ul>"},{"location":"walkthroughs/use-promitor-with-managed-identity/#prerequisites","title":"Prerequisites","text":"<ul> <li>Azure CLI, to be able to deploy resources through the command line.</li> <li>kubectl, the Kubernetes   command-line tool. It can also be installed via the Azure CLI with <code>az aks install-cli</code>.</li> <li>Helm, a Kubernetes   deployment manager.</li> <li>WSL, if you are using a Windows machine to deploy your whole solution.</li> </ul>"},{"location":"walkthroughs/use-promitor-with-managed-identity/#deploying-the-azure-infrastructure","title":"Deploying the Azure Infrastructure","text":""},{"location":"walkthroughs/use-promitor-with-managed-identity/#preparing-script","title":"Preparing script","text":"<p>Since we are going to use a lot of bash scripts with different variables values, it can be a good idea to parameterize everything.</p> <p>Let's start by exporting all the values we need:</p> <pre><code># SUBSCRIPTION_ID represents the Azure subscription id you will use to access your Azure resources\nexport SUBSCRIPTION_ID=&lt;subscription-id&gt;\n\n# RG_NAME represents the resource group name where your cluster will be deployed\nexport RG_NAME=PromitorWithManagedIdentityRG\n\n# LOCATION represents the Azure region where your cluster will be deployed\nexport LOCATION=northeurope\n\n# CLUSTER_NAME represents the name of your Azure Kubernetes Service Cluster\nexport CLUSTER_NAME=PromitorCluster\n\n# AD_POD_IDENTITY_NAME represents the name of the Azure AD identity that will be assigned to Promitor.\n# Be careful, should be lower case alphanumeric characters, '-' or '.'\nexport AD_POD_IDENTITY_NAME=promitor-identity\n\n# As an example, we are going to use a service bus from where we want to grab some metrics, through Promitor\n# SERVICE_BUS_NAMESPACE represents the name of your Azure Service Bus namespace.\n# Be careful as Azure Service Bus Namespaces need to be globally unique.\nexport SERVICE_BUS_NAMESPACE=PromitorUniqueNameServiceBus\n\n# SERVICE_BUS_QUEUE represents the name of you Azure Service Bus queue.\nexport SERVICE_BUS_QUEUE=demo_queue\n</code></pre>"},{"location":"walkthroughs/use-promitor-with-managed-identity/#creating-an-azure-resource-group","title":"Creating an Azure Resource Group","text":"<p>First, let's create an Azure resource group in which we'll group all our resources:</p> <pre><code>$ az group create --name $RG_NAME --location $LOCATION\n{\n  \"id\": \"/subscriptions/&lt;subscription-id&gt;/resourceGroups/&lt;resource-group-name&gt;\",\n  \"location\": \"&lt;location-id&gt;\",\n  \"managedBy\": null,\n  \"name\": \"&lt;resource-group-name&gt;\",\n  \"properties\": {\n    \"provisioningState\": \"Succeeded\"\n  },\n  \"tags\": null,\n  \"type\": \"Microsoft.Resources/resourceGroups\"\n}\n</code></pre>"},{"location":"walkthroughs/use-promitor-with-managed-identity/#creating-an-azure-service-bus-namespace-queue","title":"Creating an Azure Service Bus Namespace &amp; Queue","text":"<p>First we'll need to create an Azure Service Bus namespace that provides metrics in Azure Monitor.</p> <p>These metrics will be scraped by Promitor and made available to the configured metric sinks.</p> <p>\ud83d\udca1 Consider this to be an example of metrics that you'd want to use in Prometheus, StatsD, ...</p> <p>Let's create the Azure Service Bus namespace:</p> <pre><code>$ az servicebus namespace create \\\n  --resource-group $RG_NAME \\\n  --name $SERVICE_BUS_NAMESPACE \\\n  --location $LOCATION\n</code></pre> <p>After that, we'll create a queue in that namespace:</p> <pre><code>$ az servicebus queue create \\\n  --resource-group $RG_NAME \\\n  --namespace-name $SERVICE_BUS_NAMESPACE \\\n  --name $SERVICE_BUS_QUEUE\n</code></pre>"},{"location":"walkthroughs/use-promitor-with-managed-identity/#creating-an-azure-kubernetes-service-cluster","title":"Creating an Azure Kubernetes Service Cluster","text":"<p>Create an Azure Kubernetes Service cluster that uses a system-assigned managed identity:</p> <pre><code>$ az aks create --resource-group $RG_NAME \\\n    --name $CLUSTER_NAME \\\n    --generate-ssh-keys \\\n    --node-count 1 \\\n    --enable-managed-identity\n\n...\n\"servicePrincipalProfile\": {\n    \"clientId\": \"msi\"\n  }\n...\n</code></pre> <p>Once created, the output will indicate that it is using managed identity.</p>"},{"location":"walkthroughs/use-promitor-with-managed-identity/#setting-up-our-cluster","title":"Setting up our cluster","text":""},{"location":"walkthroughs/use-promitor-with-managed-identity/#getting-the-cluster-credentials","title":"Getting The Cluster Credentials","text":"<p>In order to interact with the cluster by using <code>kubectl</code>, we need to be able to authenticate to it.</p> <p>You can get the credentials for your Kubernetes cluster using this command:</p> <pre><code>$ az aks get-credentials --name $CLUSTER_NAME --resource-group $RG_NAME\nMerged \"&lt;cluster-name&gt;\" as current context in /home/tom/.kube/config\n</code></pre> <p>This saves the credentials in your kubeconfig file and uses it as your current context for all <code>kubectl</code> commands.</p> <p>Verify that you can connect and your cluster is up and running :</p> <pre><code>$ kubectl get nodes\nNAME                                STATUS   ROLES   AGE   VERSION\naks-agentpool-34594731-vmss000000   Ready    agent   15d   v1.19.7\naks-agentpool-34594731-vmss000001   Ready    agent   15d   v1.19.7\naks-agentpool-34594731-vmss000002   Ready    agent   15d   v1.19.7\n</code></pre>"},{"location":"walkthroughs/use-promitor-with-managed-identity/#get-azure-kubernetes-service-managed-identity-cluster-resource-group","title":"Get Azure Kubernetes Service managed identity &amp; cluster resource group","text":"<p>To be able to configure AAD Pod Identity component, we need information from our new Azure Kubernetes Service cluster:</p> <p>First, we need to get the name of the cluster resource group where the AKS internal resources have been deployed.</p> <pre><code>echo \"Retrieving cluster resource group\"\nexport aks_rg_name=$(az aks show -g $RG_NAME -n $CLUSTER_NAME --query nodeResourceGroup -otsv)\n</code></pre> <p>This is a generated resource group that typically uses <code>MC_{resource-group}_{cluster-name}_{region}</code>, for example <code>MC_promitor-landscape_promitor_westeurope</code>.</p> <p>Second, we need the identity of our cluster. This is the system-assigned identity of our cluster that is used to  access Azure resources.</p> <pre><code>echo \"Retrieving cluster identity ID, which will be used for role assignment\"\nexport aks_mi_identity=\"$(az aks show -g ${RG_NAME} -n ${CLUSTER_NAME} --query identityProfile.kubeletidentity.clientId -otsv)\"\n</code></pre> <p>This identity is managed by Azure, since we have used the <code>--enable-managed-identity</code> option during cluster creation.</p>"},{"location":"walkthroughs/use-promitor-with-managed-identity/#getting-our-cluster-ready-to-use-aad-pod-identity","title":"Getting our cluster ready to use AAD Pod Identity","text":""},{"location":"walkthroughs/use-promitor-with-managed-identity/#granting-our-clusters-managed-identity-required-permissions-in-azure","title":"Granting our cluster's managed identity required permissions in Azure","text":"<p>In this walkthrough we are going to configure the managed identity for our cluster to allow AAD Pod Identity to access  required resources in Azure.</p> <p>Learn more about the the required role assignments for AAD Pod Identity or have a general overview in the official documentation.</p> <p>In order to be able to use AAD Pod Identity, our cluster needs to be able to:</p> <ul> <li>Manage identities in our application &amp; cluster resource group</li> <li>Manage the virtual machines that are part of the cluster, to use the assigned identity</li> </ul> <p>You can easily do this as following:</p> <pre><code>echo \"Assigning 'Managed Identity Operator' role to ${aks_mi_identity} on resource group ${aks_rg_name}\"\naz role assignment create --role \"Managed Identity Operator\" --assignee \"${aks_mi_identity}\" --scope \"/subscriptions/${SUBSCRIPTION_ID}/resourcegroups/${aks_rg_name}\"\n\necho \"Assigning 'Virtual Machine Contributor' role to ${aks_mi_identity} on resource group ${aks_rg_name}\"\naz role assignment create --role \"Virtual Machine Contributor\" --assignee \"${aks_mi_identity}\" --scope \"/subscriptions/${SUBSCRIPTION_ID}/resourcegroups/${aks_rg_name}\"\n\necho \"Assigning 'Managed Identity Operator' role to ${aks_mi_identity} on resource group ${RG_NAME}\"\naz role assignment create --role \"Managed Identity Operator\" --assignee \"${aks_mi_identity}\" --scope \"/subscriptions/${SUBSCRIPTION_ID}/resourcegroups/${RG_NAME}\"\n</code></pre>"},{"location":"walkthroughs/use-promitor-with-managed-identity/#installing-aad-pod-identity","title":"Installing AAD Pod Identity","text":"<p>To deploy AAD Pod Identity, we need to add the Helm chart repository:</p> <pre><code>$ helm repo add aad-pod-identity https://raw.githubusercontent.com/Azure/aad-pod-identity/master/charts\n\"aad-pod-identity\" has been added to your repositories\n</code></pre> <p>Update all your Helm repositories to use the latest and greatest:</p> <pre><code>$ helm repo update\nHang tight while we grab the latest from your chart repositories...\n...Successfully got an update from the \"aad-pod-identity\" chart repository\nUpdate Complete. \u2388Happy Helming!\u2388\n</code></pre> <p>Lastly, install the Helm chart into your cluster:</p> <pre><code>helm install aad-pod-identity aad-pod-identity/aad-pod-identity --set nmi.allowNetworkPluginKubenet=true\n</code></pre>"},{"location":"walkthroughs/use-promitor-with-managed-identity/#creating-a-user-assigned-managed-identity-for-promitor","title":"Creating a user-assigned managed identity for Promitor","text":"<p>In order to let Promitor to authenticate to Azure, we have two options:</p> <ol> <li>Re-ue the managed identity of our cluster, or (syste-assigned)</li> <li>Create a new identity that we will assign to our Promitor pods (user-assigned)</li> </ol> <p>In order to separate our concerns, we will create a new  identity for it:</p> <pre><code>echo \"Create identity $AD_POD_IDENTITY_NAME in resource group $RG_NAME\"\naz identity create -g ${RG_NAME} -n ${AD_POD_IDENTITY_NAME}\n</code></pre> <p>Our new identity will be used by Promitor to access Azure Monitor to get metrics by using its assigned  RBAC roles assignements:</p> <p>First, we will get the client &amp; resource id of our identity:</p> <pre><code>export AD_POD_IDENTITY_CLIENT_ID=$(az identity show -g ${RG_NAME} -n ${AD_POD_IDENTITY_NAME} --query \"clientId\" -o tsv)\nexport AD_POD_IDENTITY_RESOURCE_ID=$(az identity show -g ${RG_NAME} -n ${AD_POD_IDENTITY_NAME} --query \"id\" -o tsv)\n</code></pre> <p>Next, we will assign the <code>Monitoring Reader</code> role to our identity on our resource group to scrape our Azure Service Bus namespace:</p> <pre><code>$ az role assignment create --role \"Monitoring Reader\" --scope \"/subscriptions/$SUBSCRIPTION_ID/resourceGroups/$RG_NAME\" --assignee \"${AD_POD_IDENTITY_CLIENT_ID}\"\n{\n  \"canDelegate\": null,\n  \"condition\": null,\n  \"conditionVersion\": null,\n  \"description\": null,\n  \"id\": \"/subscriptions/&lt;subscription-id&gt;/resourceGroups/&lt;resource-group-name&gt;/providers/Microsoft.Authorization/roleAssignments/92b1566a-2346-43f7-a093-1fd5871d4de8\",\n  \"name\": \"92b1566a-2346-43f7-a093-1fd5871d4de8\",\n  \"principalId\": \"&lt;promitor-identity-id&gt;\",\n  \"principalType\": \"ServicePrincipal\",\n  \"resourceGroup\": \"&lt;resource-group-name&gt;\",\n  \"roleDefinitionId\": \"/subscriptions/&lt;subscription-id&gt;/providers/Microsoft.Authorization/roleDefinitions/43d0d8ad-25c7-4714-9337-8ba259a9fe05\",\n  \"scope\": \"/subscriptions/&lt;subscription-id&gt;/resourceGroups/&lt;resource-group-name&gt;\",\n  \"type\": \"Microsoft.Authorization/roleAssignments\"\n}\n</code></pre> <p>In order to verify our role assignement, you can use this command:</p> <pre><code>az role assignment list --assignee $AD_POD_IDENTITY_CLIENT_ID -g $RG_NAME | jq -r '.[].roleDefinitionName'\n</code></pre> <p>\ud83d\udca1 It can take some times before the identity is correctly propagated in Azure Active Directory. So far if you encountered an error where the identity is not found, please wait 60 sec and retry</p>"},{"location":"walkthroughs/use-promitor-with-managed-identity/#bind-your-managed-identity-to-our-pods-through-aad-pod-identity","title":"Bind your Managed Identity to our Pods, through AAD Pod Identity","text":"<p>Now that our identity is created, we can tell AAD Pod Identity that we want to bind our Azure AD identity to our pods:</p> <p>First, we will define the identity that we want to assign:</p> <pre><code>cat &lt;&lt;EOF | kubectl apply -f -\napiVersion: \"aadpodidentity.k8s.io/v1\"\nkind: AzureIdentity\nmetadata:\n  name: ${AD_POD_IDENTITY_NAME}\nspec:\n  type: 0 # 0 - user assigned MSI, 1 - service principal\n  resourceID: ${AD_POD_IDENTITY_RESOURCE_ID}\n  clientID: ${AD_POD_IDENTITY_CLIENT_ID}\nEOF\n</code></pre> <p>Next, we want to define to what pods we want to link it:</p> <pre><code>cat &lt;&lt;EOF | kubectl apply -f -\napiVersion: \"aadpodidentity.k8s.io/v1\"\nkind: AzureIdentityBinding\nmetadata:\n  name: ${AD_POD_IDENTITY_NAME}-binding\nspec:\n  azureIdentity: ${AD_POD_IDENTITY_NAME}\n  selector: ${AD_POD_IDENTITY_NAME}\nEOF\n</code></pre> <p>You can verify that the resources were created successfully as following:</p> <pre><code>kubectl get azureidentity\nkubectl get azureidentitybinding\n</code></pre>"},{"location":"walkthroughs/use-promitor-with-managed-identity/#verifying-the-aad-pod-identity-installation","title":"Verifying the AAD Pod Identity installation","text":"<p>Before going further, we will check if our AAD Pod Identity is deployed &amp; configured correctly.</p> <p>We will spin up a pod and use the Azure CLI to authenticate:</p> <pre><code>kubectl run azure-cli -it --image=mcr.microsoft.com/azure-cli --labels=aadpodidbinding=$AD_POD_IDENTITY_NAME /bin/bash\n</code></pre> <p>Note that we are adding <code>aadpodidbinding</code> as a label, which is linking the pod to the AAD Pod Identity binding  that we have just created.</p> <p>Warning: It can take some times to Aad Pod Identity to bind the identity to your deployed container. If you encountered an error, relaunch the <code>az login -i --debug</code> command after 60 sec.</p> <p>Next, we will run <code>az login -i --debug</code> to see the different steps it takes:</p> <pre><code># Once you are log in the container, and have the bash command line available, try to login using the Managed Identity:\n# If you don't see a command prompt, try pressing enter.\n$ bash-5.0# az login -i --debug\nmsrestazure.azure_active_directory: MSI: Retrieving a token from http://169.254.169.254/metadata/identity/oauth2/token, with payload {'resource': 'https://management.core.windows.net/', 'api-version': '2018-02-01'}\nmsrestazure.azure_active_directory: MSI: Token retrieved\ncli.azure.cli.core._profile: MSI: token was retrieved. Now trying to initialize local accounts...\n...\n[\n  {\n    \"environmentName\": \"AzureCloud\",\n    \"homeTenantId\": \"e0372f7f-a362-47fb-9631-74a5c4ba8bbf\",\n    \"id\": \"0f9d7fea-99e8-4768-8672-06a28514f77e\",\n    \"isDefault\": true,\n    \"managedByTenants\": [\n      {\n        \"tenantId\": \"2f4a9838-26b7-47ee-be60-ccc1fdec5953\"\n      }\n    ],\n    \"name\": \"Visual Studio Enterprise\",\n    \"state\": \"Enabled\",\n    \"tenantId\": \"e0372f7f-a362-47fb-9631-74a5c4ba8bbf\",\n    \"user\": {\n      \"assignedIdentityInfo\": \"MSI\",\n      \"name\": \"systemAssignedIdentity\",\n      \"type\": \"servicePrincipal\"\n    }\n  }\n]\n</code></pre> <p>If your Azure CLI container is able to retrieve some information from Azure without having to log in with your credentials, it means the CLI is using your Managed Identity, through the Pod Identity Binding.</p> <p>You may have a result indicating you are log in, using a System Assigned Identity</p> <pre><code>\"user\": {\n    \"assignedIdentityInfo\": \"MSI\",\n    \"name\": \"systemAssignedIdentity\",\n}\n</code></pre>"},{"location":"walkthroughs/use-promitor-with-managed-identity/#deploying-promitor-with-managed-identity","title":"Deploying Promitor with Managed Identity","text":""},{"location":"walkthroughs/use-promitor-with-managed-identity/#create-a-metrics-declaration-for-promitor","title":"Create a metrics declaration for Promitor","text":"<p>Before deploying Promitor, we will create a values file for our Helm deployment.</p> <p>In the configuration, we define what Azure resource that we want to scrape and that we want to use managed identity.</p> <p>Here is an example:</p> <pre><code>azureAuthentication:\n  mode: SystemAssignedManagedIdentity\n  identity:\n    binding: &lt;aad-pod-identity-name&gt;              # &lt;- This is the value of AD_POD_IDENTITY_NAME environment variable\nazureMetadata:\n  tenantId: &lt;tenant-id&gt;\n  subscriptionId: &lt;subscription-id&gt;               # &lt;- This is the value of SUBSCRIPTION_ID environment variable\n  resourceGroupName: &lt;promitor-resource-group-id&gt; # &lt;- This is the value of RG_NAME environment variable\nmetricDefaults:\n  aggregation:\n    interval: 00:05:00\n  scraping:\n    schedule: \"* * * * *\"\nmetrics:\n  - name: demo_queue_size\n    description: \"Amount of active messages of the 'demo_queue' queue\"\n    resourceType: ServiceBusNamespace\n    azureMetricConfiguration:\n      metricName: ActiveMessages\n      aggregation:\n        type: Total\n    resources:\n      - namespace: &lt;service-bus-namespace&gt;        # &lt;- This is the value of SERVICE_BUS_NAMESPACE environment variable\n        queueName: &lt;service-bus-queue&gt;            # &lt;- This is the value of SERVICE_BUS_QUEUE_NAME environment variable\n</code></pre>"},{"location":"walkthroughs/use-promitor-with-managed-identity/#deploy-promitor-to-your-cluster-using-helm","title":"Deploy Promitor to your cluster using Helm","text":"<p>To deploy, we'll first add the Promitor chart repository to helm:</p> <pre><code>helm repo add promitor https://charts.promitor.io/\nhelm repo update\n</code></pre> <p>With this repository added, we can deploy Promitor:</p> <pre><code>helm install promitor-agent-scraper promitor/promitor-agent-scraper --values your/path/to/metric-declaration.yaml\n</code></pre>"},{"location":"walkthroughs/use-promitor-with-managed-identity/#verifying-the-scraped-output-in-promitor","title":"Verifying the scraped output in Promitor","text":"<p>You can check that Promitor is getting insights from you Azure Service Bus queue, using the managed identity, with this commands.</p> <p>First, we get the name of the Promitor Scraper pod:</p> <pre><code># Get promitor pod\nexport POD_NAME=$(kubectl get pods --namespace default -l \"app.kubernetes.io/instance=promitor-agent-scraper\" -o jsonpath=\"{.items[0].metadata.name}\")\n</code></pre> <p>Next, we add port forwarding from our pod to our local machine:</p> <pre><code>kubectl port-forward --namespace default $POD_NAME 8080:88\n</code></pre> <p>Now browse to the address http://127.0.0.1:8080/metrics and check your metrics are scrapped:</p> <pre><code># HELP demo_queue_size Amount of active messages of the 'demo_queue' queue\n# TYPE demo_queue_size gauge\ndemo_queue_size{resource_group=\"ammdocs\",subscription_id=\"xxxxx-xxxxx-xxxxx-xxxxxx-xxxxx\",resource_uri=\"subscriptions/xxxxx-xxxxx-xxxxx-xxxxxx-xxxxx/resourceGroups/YOUR_RESOURCE_GROUP_NAME/providers/Microsoft.ServiceBus/namespaces/YOUR_SERVICE_BUS_NAMESPACE\",instance_name=\"INSTANCE_NAME\",entity_name=\"YOUR_SERVICE_BUS_QUEUE\"} 0 1612952581417\n</code></pre>"},{"location":"walkthroughs/use-promitor-with-managed-identity/#cleaning-up","title":"Cleaning up","text":"<p>To delete all the resources used in this tutorial, run <code>az group delete --name $RG_NAME</code>.</p> <p>\u2190 back</p>"}]}